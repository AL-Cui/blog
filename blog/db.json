{"meta":{"version":1,"warehouse":"2.2.0"},"models":{"Asset":[{"_id":"themes/yilia/source/main.0cf68a.css","path":"main.0cf68a.css","modified":0,"renderable":1},{"_id":"themes/yilia/source/slider.e37972.js","path":"slider.e37972.js","modified":0,"renderable":1},{"_id":"themes/yilia/source/main.0cf68a.js","path":"main.0cf68a.js","modified":0,"renderable":1},{"_id":"themes/yilia/source/mobile.992cbe.js","path":"mobile.992cbe.js","modified":0,"renderable":1},{"_id":"themes/yilia/source/fonts/default-skin.b257fa.svg","path":"fonts/default-skin.b257fa.svg","modified":0,"renderable":1},{"_id":"themes/yilia/source/fonts/iconfont.16acc2.ttf","path":"fonts/iconfont.16acc2.ttf","modified":0,"renderable":1},{"_id":"themes/yilia/source/fonts/iconfont.8c627f.woff","path":"fonts/iconfont.8c627f.woff","modified":0,"renderable":1},{"_id":"themes/yilia/source/fonts/iconfont.45d7ee.svg","path":"fonts/iconfont.45d7ee.svg","modified":0,"renderable":1},{"_id":"themes/yilia/source/fonts/iconfont.b322fa.eot","path":"fonts/iconfont.b322fa.eot","modified":0,"renderable":1},{"_id":"themes/yilia/source/fonts/tooltip.4004ff.svg","path":"fonts/tooltip.4004ff.svg","modified":0,"renderable":1},{"_id":"themes/yilia/source/img/default-skin.png","path":"img/default-skin.png","modified":0,"renderable":1},{"_id":"themes/yilia/source/img/head.jpg","path":"img/head.jpg","modified":0,"renderable":1},{"_id":"themes/yilia/source/img/preloader.gif","path":"img/preloader.gif","modified":0,"renderable":1},{"_id":"themes/yilia/source/img/scrollbar_arrow.png","path":"img/scrollbar_arrow.png","modified":0,"renderable":1},{"_id":"themes/yilia/source/img/wei.png","path":"img/wei.png","modified":0,"renderable":1},{"_id":"themes/yilia/source/img/alipay.jpg","path":"img/alipay.jpg","modified":0,"renderable":1}],"Cache":[{"_id":"themes/yilia/.babelrc","hash":"db600d40e93e6d8023737a65d58d3be7370e5e30","modified":1586056003216},{"_id":"themes/yilia/.editorconfig","hash":"daaa8757fac18f8735fadd0a37a42c06f421ca14","modified":1586056003217},{"_id":"themes/yilia/.eslintignore","hash":"ed9d8911ca08c3dd5072c48dd0be4d06f8897730","modified":1586056003217},{"_id":"themes/yilia/.eslintrc.js","hash":"303d25adf02ad65720e537a16a4a137d14bb755f","modified":1586056003239},{"_id":"themes/yilia/README.md","hash":"1bf755806af9d8874bd22e1abbdaaa24328ef4dc","modified":1586056003239},{"_id":"themes/yilia/_config.yml","hash":"1e11ca79a780015bf5de2eb0352a55f49cae15a3","modified":1586056003239},{"_id":"themes/yilia/package.json","hash":"ee6aa61f1cb89fd549e3e087c0232207a9c9ee30","modified":1586056003604},{"_id":"themes/yilia/webpack.config.js","hash":"da7657347109ddb4ab8602b219778117254677fe","modified":1586056003832},{"_id":"themes/yilia/languages/default.yml","hash":"f26a34a7983d4bc17c65c7f0f14da598e62ce66d","modified":1586056003240},{"_id":"themes/yilia/languages/fr.yml","hash":"b4be1c1592a72012e48df2b3ec41cc9685573e50","modified":1586056003240},{"_id":"themes/yilia/languages/nl.yml","hash":"3d82ec703d0b3287739d7cb4750a715ae83bfcb3","modified":1586056003241},{"_id":"themes/yilia/languages/no.yml","hash":"ddf2035e920a5ecb9076138c184257d9f51896a7","modified":1586056003241},{"_id":"themes/yilia/languages/ru.yml","hash":"2a476b4c6e04900914c81378941640ac5d58a1f0","modified":1586056003241},{"_id":"themes/yilia/languages/zh-CN.yml","hash":"b057f389c6713010f97d461e48ec959b0b6f3b44","modified":1586056003258},{"_id":"themes/yilia/languages/zh-tw.yml","hash":"f5f0ca88185da7a8457760d84bf221781473bd7c","modified":1586056003258},{"_id":"themes/yilia/layout/category.ejs","hash":"765426a9c8236828dc34759e604cc2c52292835a","modified":1586056003601},{"_id":"themes/yilia/layout/archive.ejs","hash":"2703b07cc8ac64ae46d1d263f4653013c7e1666b","modified":1586056003601},{"_id":"themes/yilia/layout/index.ejs","hash":"ec498c6c0606acde997ce195dad97b267418d980","modified":1586056003601},{"_id":"themes/yilia/layout/layout.ejs","hash":"b471ab706d48e0be3f783eab1c94bf5878ef5a94","modified":1586056003602},{"_id":"themes/yilia/layout/page.ejs","hash":"7d80e4e36b14d30a7cd2ac1f61376d9ebf264e8b","modified":1586056003602},{"_id":"themes/yilia/layout/post.ejs","hash":"7d80e4e36b14d30a7cd2ac1f61376d9ebf264e8b","modified":1586056003603},{"_id":"themes/yilia/layout/tag.ejs","hash":"eaa7b4ccb2ca7befb90142e4e68995fb1ea68b2e","modified":1586056003603},{"_id":"themes/yilia/source/main.0cf68a.css","hash":"ddf6e2c6b953c2c59a3c271e6070010a4cc81cf9","modified":1586056003763},{"_id":"themes/yilia/source/slider.e37972.js","hash":"ce5eac88301fe4f2fce0fb6203adfd58eb8313ac","modified":1586056003832},{"_id":"themes/yilia/source-src/css.ejs","hash":"cf7eab48d626433120d1ef9697f719a359817018","modified":1586056003604},{"_id":"themes/yilia/source-src/script.ejs","hash":"28abac2426761d7e715b38aadd86ce6549c8ae77","modified":1586056003711},{"_id":"source/_posts/Ansible-playbook 关于ssh的配置和使用.md","hash":"95287bfe9cef5f20feea091e56d966f9eb572064","modified":1586056003062},{"_id":"source/_posts/Golang 1.10 获取Windows上的硬件数据信息.md","hash":"418c04b1741ff251001f17e34dd39cf05c844935","modified":1586056003062},{"_id":"source/_posts/Istio怎么劫持了流量.md","hash":"57eb7d2610c20f2db83399348789354ead91c50d","modified":1586083899393},{"_id":"source/_posts/K8S集群日志收集方案.md","hash":"8c5737f7347dedb5833822c32792fb09711cde4c","modified":1586060351534},{"_id":"source/_posts/Kubernetes的Limits和Requests.md","hash":"7034e382f7e076829a43a013e162eb05b1f06ceb","modified":1586693577803},{"_id":"source/_posts/k8s集群中部署Calico踩坑笔记.md","hash":"aaa1a34c792834f62d37d3bce7440ba6eb560400","modified":1586056003063},{"_id":"source/_posts/山不在高.md","hash":"1949d35c5784be3c14cd8e473e7efb6484703353","modified":1586056003064},{"_id":"source/_posts/自己动手搭建Harbor镜像仓库.md","hash":"60723f4c6ad7966b998d3024ec02c1bde3c82c74","modified":1586056003064},{"_id":"source/_posts/自己动手搭建kubernetes dashboard界面.md","hash":"143b30543f5e4d17c613831cfbd67907ba8c5113","modified":1586056003064},{"_id":"source/categories/index.md","hash":"798acbb32107645210fbcb176b84c5ee75ea7deb","modified":1586056003065},{"_id":"source/tags/index.md","hash":"affa1d6d525a3b5eb551d1d22189d5ea98ade7a2","modified":1586056003065},{"_id":"themes/yilia/layout/_partial/toc.ejs","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1586056003599},{"_id":"themes/yilia/source/main.0cf68a.js","hash":"283ae27ea37ac3e0e45b2e05c2482a4c594b9c25","modified":1586056003765},{"_id":"themes/yilia/source/mobile.992cbe.js","hash":"1801ef448909ea23c0a48e9d63b80d0cfd5534ce","modified":1586056003831},{"_id":"themes/yilia/layout/_partial/after-footer.ejs","hash":"c70f367f54064a441e574c913f5e0ea121d0f899","modified":1586056003261},{"_id":"themes/yilia/layout/_partial/archive-post.ejs","hash":"edc0154b30a4127acda10297bec6aacf754b4ac4","modified":1586056003263},{"_id":"themes/yilia/layout/_partial/archive.ejs","hash":"a4eacc2bc1278095a0ef99f904b0634c78f980eb","modified":1586056003263},{"_id":"themes/yilia/layout/_partial/article.ejs","hash":"8dea8f5f93a60185439b330b0f1d1649a6ab4bd0","modified":1586056003264},{"_id":"themes/yilia/layout/_partial/aside.ejs","hash":"751e5deab5365348be5243688b419c82d337ab9a","modified":1586056003535},{"_id":"themes/yilia/layout/_partial/baidu-analytics.ejs","hash":"155327c23607f69989b58845f24d842a54e504b8","modified":1586056003536},{"_id":"themes/yilia/layout/_partial/css.ejs","hash":"236f8a377b2e4e35754319c3029bcd4a4115431d","modified":1586056003536},{"_id":"themes/yilia/layout/_partial/footer.ejs","hash":"c2d9a805d75eac515e78b3ac44c088b33ae5b404","modified":1586056003536},{"_id":"themes/yilia/layout/_partial/google-analytics.ejs","hash":"1ccc627d7697e68fddc367c73ac09920457e5b35","modified":1586056003536},{"_id":"themes/yilia/layout/_partial/head.ejs","hash":"12ca7d8dba56bc767b9309dda9526dcbaffc1614","modified":1586056003537},{"_id":"themes/yilia/layout/_partial/header.ejs","hash":"b69855e07b65117769adc515cb64b803932068c9","modified":1586056003537},{"_id":"themes/yilia/layout/_partial/left-col.ejs","hash":"fb1b8457b9eb15b55da1bf7b133e12c375dd26f8","modified":1586056003537},{"_id":"themes/yilia/layout/_partial/mathjax.ejs","hash":"11550a418921d330e6553be0569a94ab5a217967","modified":1586056003538},{"_id":"themes/yilia/layout/_partial/mobile-nav.ejs","hash":"ccec1fc70f021cb50ac85b524e7949878ab93a18","modified":1586056003538},{"_id":"themes/yilia/layout/_partial/tools.ejs","hash":"0ffcb251b79e8a920c9b4cb6bb7a96a808816165","modified":1586056003600},{"_id":"themes/yilia/layout/_partial/viewer.ejs","hash":"cc1c39903aed0a0601d104238d2bbd13ad2a36f3","modified":1586056003600},{"_id":"themes/yilia/source/fonts/default-skin.b257fa.svg","hash":"2ac727c9e092331d35cce95af209ccfac6d4c7c7","modified":1586056003713},{"_id":"themes/yilia/source/fonts/iconfont.16acc2.ttf","hash":"f342ac8bf4d937f42a7d6a0032ad267ab47eb7f2","modified":1586056003715},{"_id":"themes/yilia/source/fonts/iconfont.8c627f.woff","hash":"aa9672cb097f7fd73ae5a03bcd3d9d726935bc0a","modified":1586056003730},{"_id":"themes/yilia/source/fonts/iconfont.45d7ee.svg","hash":"75767c904d483d9b93469afb6b92bb6bdface639","modified":1586056003728},{"_id":"themes/yilia/source/fonts/iconfont.b322fa.eot","hash":"bc8c5e88f4994a852041b4d83f126d9c4d419b4a","modified":1586056003732},{"_id":"themes/yilia/source/fonts/tooltip.4004ff.svg","hash":"397fe4b1093bf9b62457dac48aa15dac06b54a3c","modified":1586056003732},{"_id":"themes/yilia/source/img/default-skin.png","hash":"ed95a8e40a2c3478c5915376acb8e5f33677f24d","modified":1586056003741},{"_id":"themes/yilia/source/img/head.jpg","hash":"5c636fdf577673d43eb2fa367133ffeb530061f7","modified":1586056003742},{"_id":"themes/yilia/source/img/preloader.gif","hash":"6342367c93c82da1b9c620e97c84a389cc43d96d","modified":1586056003743},{"_id":"themes/yilia/source/img/scrollbar_arrow.png","hash":"d64a33c4ddfbdb89deeb6f4e3d36eb84dc4777c0","modified":1586056003756},{"_id":"themes/yilia/source-src/css/_core.scss","hash":"29ba600e98ed55f7af4ade8038272c84cba21188","modified":1586056003605},{"_id":"themes/yilia/source-src/css/_function.scss","hash":"ce227b6f5a9af194fd5d455200630f32c05e151f","modified":1586056003605},{"_id":"themes/yilia/source-src/css/archive.scss","hash":"d6a7dd88404b383b5b94e4c7ec675a410c41f3cc","modified":1586056003606},{"_id":"themes/yilia/source-src/css/article-inner.scss","hash":"f7388f5c11370ef462f7cb913d8f72edf24ecaf9","modified":1586056003638},{"_id":"themes/yilia/source-src/css/article-main.scss","hash":"1577a2336b3ad122f49f60dff2bc1a97d4e7b18b","modified":1586056003639},{"_id":"themes/yilia/source-src/css/article-nav.scss","hash":"8f82fe898ba1c1bd00c24a7d8270feddc7eba3bc","modified":1586056003639},{"_id":"themes/yilia/source-src/css/article.scss","hash":"55d082fec4c6bb341725567acaa29ce37d50320a","modified":1586056003639},{"_id":"themes/yilia/source-src/css/aside.scss","hash":"07244c188f58ecfb90bb7c047b8cde977f1dc4b4","modified":1586056003640},{"_id":"themes/yilia/source-src/css/comment.scss","hash":"b85f344f2c66d43d7094746e0a9ccb21d0534201","modified":1586056003640},{"_id":"themes/yilia/source-src/css/fonts.scss","hash":"96d7eb1d42c06fdcccb8ef969f6ecd30c3194903","modified":1586056003653},{"_id":"themes/yilia/source-src/css/footer.scss","hash":"7ca837a4cc34db1c35f01baec85eb10ccc64ea86","modified":1586056003656},{"_id":"themes/yilia/source-src/css/global.scss","hash":"b4cb4f45a55d4250cd9056f76dab2a3c0dabcec4","modified":1586056003656},{"_id":"themes/yilia/source-src/css/grid.scss","hash":"f53ea8270752b5919ec5d79224d22af91f2eda12","modified":1586056003656},{"_id":"themes/yilia/source-src/css/highlight.scss","hash":"40e5aa5056dc0b3b9f51c5b387370b612e265d4e","modified":1586056003657},{"_id":"themes/yilia/source-src/css/left.scss","hash":"80dac621e43581a254d0152d5df901e4d0b01c09","modified":1586056003658},{"_id":"themes/yilia/source-src/css/main.scss","hash":"9eba1fcf4805256697528fcf3b767cf6dd8d0591","modified":1586056003658},{"_id":"themes/yilia/source-src/css/mobile-slider.scss","hash":"19f10fd2f0c3377aa4b165b3c2291ecf86dd9351","modified":1586056003659},{"_id":"themes/yilia/source-src/css/mobile.scss","hash":"d995dcd483a250fe61b426158afb61bf8923a927","modified":1586056003680},{"_id":"themes/yilia/source-src/css/page.scss","hash":"244c4d75c375978ff9edb74acc68825e63c6b235","modified":1586056003680},{"_id":"themes/yilia/source-src/css/reward.scss","hash":"a557a9ed244c82b8b71e9da9de3339d92783499f","modified":1586056003681},{"_id":"themes/yilia/source-src/css/scroll.scss","hash":"2495f7e4e3b055735c531f944b5f40a118a351ec","modified":1586056003681},{"_id":"themes/yilia/source-src/css/share.scss","hash":"9d6f6884f40c191882e56a1e1e1192400944a515","modified":1586056003682},{"_id":"themes/yilia/source-src/css/social.scss","hash":"a10a038a1dac8953cb4ffc7e04272eff9fac54e4","modified":1586056003682},{"_id":"themes/yilia/source-src/css/tags-cloud.scss","hash":"399744e98e7c67939ed9b23c2670d8baad044eda","modified":1586056003682},{"_id":"themes/yilia/source-src/css/tools.scss","hash":"2924fb6f77c4a9973cd928c2c7db0acb848ed483","modified":1586056003683},{"_id":"themes/yilia/source-src/css/tags.scss","hash":"915c93edd67c5326695cc7dc84b14c5f154dbcc8","modified":1586056003683},{"_id":"themes/yilia/source-src/css/tooltip.scss","hash":"b81cedbe31accca82e597801186911a7b5e6841c","modified":1586056003691},{"_id":"themes/yilia/source-src/js/Q.js","hash":"e56d9710afa79b31ca6b9fbd845f6d1895f5214b","modified":1586056003692},{"_id":"themes/yilia/source-src/js/anm.js","hash":"d18f6276a352b871390a4112d479b9e58b8cdbbe","modified":1586056003693},{"_id":"themes/yilia/source-src/js/aside.js","hash":"5e4c3c3d61f1e1ce2f09688d3aff25fadc851fff","modified":1586056003693},{"_id":"themes/yilia/source-src/js/browser.js","hash":"4dc04845cf27f350922b63f1813a9c82e6e33b05","modified":1586056003693},{"_id":"themes/yilia/source-src/js/fix.js","hash":"67b8819abb886c9d066fb3b0624ca15e06f63fe0","modified":1586056003693},{"_id":"themes/yilia/source-src/js/main.js","hash":"fe98bf90ce61658fe16ae057f8b6a512a845af3b","modified":1586056003694},{"_id":"themes/yilia/source-src/js/mobile.js","hash":"461c08ffcbc724d74ec7e0ff38e171eefe0f89fd","modified":1586056003704},{"_id":"themes/yilia/source-src/js/report.js","hash":"57680f9a23bd0a1eaafd64ae08cc33e20627ab15","modified":1586056003706},{"_id":"themes/yilia/source-src/js/share.js","hash":"d4ccff8266c37363b3904226f5d035b7db882c61","modified":1586056003707},{"_id":"themes/yilia/source-src/js/util.js","hash":"3bcdeb95072b85600874424e6929e3e22cfddaa0","modified":1586056003709},{"_id":"themes/yilia/source-src/js/slider.js","hash":"0beaa112657ad57c723d9e773d5b79de60c1dd74","modified":1586056003708},{"_id":"themes/yilia/source-src/js/viewer.js","hash":"c699cf3c89409ec8f044258e0715a470861b5d5d","modified":1586056003710},{"_id":"themes/yilia/layout/_partial/script.ejs","hash":"e98ec0b3b56f14d1d79af99ceb42727719a584f3","modified":1586056003599},{"_id":"themes/yilia/layout/_partial/post/category.ejs","hash":"e777cbf959b11c4dfda649c562799899b90ab4a3","modified":1586056003539},{"_id":"themes/yilia/layout/_partial/post/changyan.ejs","hash":"086c8a88fd3bcae7ec13258df58e25d6354af2fa","modified":1586056003539},{"_id":"themes/yilia/layout/_partial/post/date.ejs","hash":"aae96de18d48cd3b9b7bf6fed0100e15b53cca97","modified":1586056003539},{"_id":"themes/yilia/layout/_partial/post/duoshuo.ejs","hash":"f6b4c4eaafb5ac386273354b5f64a26139b7a3b0","modified":1586056003539},{"_id":"themes/yilia/layout/_partial/post/gitment.ejs","hash":"25655016773aa5d0774c56115ae1736a9fc9ea1f","modified":1586056003540},{"_id":"themes/yilia/layout/_partial/post/nav.ejs","hash":"b6a97043f9ec37e571aacacfedcda1d4d75e3c7c","modified":1586056003540},{"_id":"themes/yilia/layout/_partial/post/tag.ejs","hash":"2c4e4ca36c9bb4318506c38aca7127f1f44d827f","modified":1586056003596},{"_id":"themes/yilia/layout/_partial/post/share.ejs","hash":"345b262e3c3b75c0cd9a93d9ecabcf06e33e54ff","modified":1586056003595},{"_id":"themes/yilia/layout/_partial/post/title.ejs","hash":"d4a460a35e2112d0c7414fd5e19b3a16093f1caf","modified":1586056003597},{"_id":"themes/yilia/layout/_partial/post/wangyiyun.ejs","hash":"fb022502c741b4a26bad6b2ad37245c10ede3f1a","modified":1586056003597},{"_id":"themes/yilia/source-src/css/core/_animation.scss","hash":"1834c3ed8560716e63bb3a50be94cac87fbbeaf3","modified":1586056003641},{"_id":"themes/yilia/source-src/css/core/_media-queries.scss","hash":"262ffcd88775080b7f511db37f58d2bcb1b2bfc7","modified":1586056003641},{"_id":"themes/yilia/source-src/css/core/_mixin.scss","hash":"91db061c9c17628291a005e5bd4936cf9d35a6c4","modified":1586056003642},{"_id":"themes/yilia/source-src/css/core/_reset.scss","hash":"398a49913b4a47d928103562b1ce94520be4026a","modified":1586056003652},{"_id":"themes/yilia/source-src/css/core/_variables.scss","hash":"6e75bdaa46de83094ba0873099c6e7d656a22453","modified":1586056003653},{"_id":"themes/yilia/source-src/css/fonts/iconfont.eot","hash":"bc8c5e88f4994a852041b4d83f126d9c4d419b4a","modified":1586056003654},{"_id":"themes/yilia/source-src/css/fonts/iconfont.svg","hash":"75767c904d483d9b93469afb6b92bb6bdface639","modified":1586056003654},{"_id":"themes/yilia/source-src/css/fonts/iconfont.woff","hash":"aa9672cb097f7fd73ae5a03bcd3d9d726935bc0a","modified":1586056003655},{"_id":"themes/yilia/source-src/css/img/checkered-pattern.png","hash":"049262fa0886989d750637b264bed34ab51c23c8","modified":1586056003657},{"_id":"themes/yilia/source-src/css/img/scrollbar_arrow.png","hash":"d64a33c4ddfbdb89deeb6f4e3d36eb84dc4777c0","modified":1586056003657},{"_id":"themes/yilia/source-src/css/img/tooltip.svg","hash":"397fe4b1093bf9b62457dac48aa15dac06b54a3c","modified":1586056003658},{"_id":"themes/yilia/source/img/wei.png","hash":"58f46c249d3710ba81ce3a24ae198b9a4cdb1c2c","modified":1586056003762},{"_id":"themes/yilia/source-src/css/fonts/iconfont.ttf","hash":"f342ac8bf4d937f42a7d6a0032ad267ab47eb7f2","modified":1586056003655},{"_id":"themes/yilia/source/img/alipay.jpg","hash":"8667669fe684bd8c6795f6e68f09a754c6f91860","modified":1586056003740},{"_id":"public/content.json","hash":"2a3ce0e4ba3b7e0d63f6ddd10f2c14ccc037cc2a","modified":1586694062555},{"_id":"public/tags/index.html","hash":"66cddc9daacf748f0ae4a89c33869264f1797cd5","modified":1586694062972},{"_id":"public/categories/index.html","hash":"e1fb649ec3c882dfc2d648db3016a205d5b78604","modified":1586694062973},{"_id":"public/2020/04/05/Istio怎么劫持了流量/index.html","hash":"b1fd7cba56b5fa0e3eb295bbf569312242164756","modified":1586694063001},{"_id":"public/2020/04/05/K8S集群日志收集方案/index.html","hash":"b84859b1c0f39922da309a3591f0fa38e45482bb","modified":1586694063001},{"_id":"public/2020/04/05/自己动手搭建kubernetes dashboard界面/index.html","hash":"e1c347a3d40f3f2ff5cfcb7870bc8f01548bed5d","modified":1586694063002},{"_id":"public/2020/04/05/自己动手搭建Harbor镜像仓库/index.html","hash":"40c4920e845dd8a59fad1b644d1c13bb4ad8714f","modified":1586694063003},{"_id":"public/2020/04/05/k8s集群中部署Calico踩坑笔记/index.html","hash":"fa393f1c17929a2d4d2a8314a65724ec398658f1","modified":1586694063003},{"_id":"public/2020/04/05/山不在高/index.html","hash":"fd5f6dafa653e37f444e35a1ca62296aabcb7264","modified":1586694063004},{"_id":"public/2020/04/05/Golang 1.10 获取Windows上的硬件数据信息/index.html","hash":"d1727173bf04617f0edf1f1d6825228a520096c7","modified":1586694063004},{"_id":"public/2020/04/05/Ansible-playbook 关于ssh的配置和使用/index.html","hash":"1f0e460b5cf33671df708bb37a03e34fb65d627f","modified":1586694063004},{"_id":"public/archives/index.html","hash":"0179fc04a028b2bcddd8933be2ceecc8f59de9d4","modified":1586694063004},{"_id":"public/archives/2020/index.html","hash":"f82bc68de4371a24d911b2932f418a21a95f1b12","modified":1586694063004},{"_id":"public/archives/2020/04/index.html","hash":"588859bfe9f5609a7068b3546d8e497c5155a0ac","modified":1586694063004},{"_id":"public/categories/Golang/index.html","hash":"e72b8503269a0e8b7a6c77634a8335b7b89a6d0d","modified":1586694063004},{"_id":"public/categories/Ansible/index.html","hash":"63f493901da2bbbc2056926bf6d90cddbd44b827","modified":1586694063004},{"_id":"public/categories/Kubernetes/index.html","hash":"2c0cebe6ee7280995d031843e3b96c814f47fb80","modified":1586694063005},{"_id":"public/index.html","hash":"26f0c4d604d2bbc6ea74c5de3656bf0f2b77ebef","modified":1586694063005},{"_id":"public/2020/04/12/Kubernetes的Limits和Requests/index.html","hash":"3a97b50230b35e620a2d04de0dc42af7c006137d","modified":1586694063005},{"_id":"public/tags/山不在高/index.html","hash":"eaf2d6ef47bb37ef1b1140536450f3820ab25ec7","modified":1586694063005},{"_id":"public/tags/随笔/index.html","hash":"854c0b845f51fe07efaecb54d0e4eb6bb24be8a2","modified":1586694063006}],"Category":[{"name":"Golang","_id":"ck8x0luv900042otv1nd6c9hj"},{"name":"Ansible","_id":"ck8x0luve00082otvqqnbhra4"},{"name":"Kubernetes","_id":"ck8x0luvi000c2otvhni32lzd"}],"Data":[],"Page":[{"title":"tags","type":"tags","comments":0,"date":"2019-10-11T06:23:45.000Z","_content":"","source":"tags/index.md","raw":"---\ntitle: tags\ntype: tags\ncomments: false\ndate: 2019-10-11 14:23:45\n---\n","updated":"2020-04-05T03:06:43.065Z","path":"tags/index.html","layout":"page","_id":"ck8x0luv500012otvern9qwi1","content":"","site":{"data":{}},"excerpt":"","more":""},{"title":"categories","type":"categories","comments":0,"date":"2019-10-11T06:32:39.000Z","_content":"","source":"categories/index.md","raw":"---\ntitle: categories\ntype: \"categories\"\ncomments: false\ndate: 2019-10-11 14:32:39\n---\n","updated":"2020-04-05T03:06:43.065Z","path":"categories/index.html","layout":"page","_id":"ck8x0luv700032otvx93wemuk","content":"","site":{"data":{}},"excerpt":"","more":""}],"Post":[{"title":"Golang获取windows硬件数据","_content":"\n# Golang1.10获取windows硬件数据\n   **嗯，工作原因需要使用go语言抓取windows下的硬件信息，包括CPU，GPU，内存，网卡信息，物理硬盘，系统信息等。做Golang语言开发的应该都知道，一手资料都在国外，国内的博客都是千篇一律互相Copy。所以，自己写个博客给大家分享一下，也记录一下。这里，我的golang版本是最新的1.10.1。不多说了，直接上干货**。\n   \n<!--more-->\n获取CPU信息\n-------\n\n```\nimport \t（\n    \"github.com/StackExchange/wmi\"\n    \"fmt\"\n)\ntype cpuInfo struct {\n\tName          string\n\tNumberOfCores uint32\n\tThreadCount   uint32\n}\nfunc getCPUInfo() {\n\n\tvar cpuinfo []cpuInfo\n\n\terr := wmi.Query(\"Select * from Win32_Processor\", &cpuinfo)\n\tif err != nil {\n\t\treturn\n\t}\n\tfmt.Printf(\"Cpu info =\",cpuinfo)\n}\n\n```\n这里使用的是wmi库，关于Query方法中传入的string是通过WQL语句书写的。wmi的文档点击[这里](https://godoc.org/github.com/StackExchange/wmi#CreateQuery)，另外关于Query传入的struct里的参数也是多样的，具体可参考windows官方文档，点击[这里](https://msdn.microsoft.com/en-us/library/aa394373%28v=vs.85%29.aspx)。这个文档我们后续查询其他硬件资料要常用，我这里贴一次后续就不贴了，这里可以查询的参数多种多样，具体如下：\n\n```\n[Dynamic, Provider(\"CIMWin32\"), UUID(\"{8502C4BB-5FBB-11D2-AAC1-006008C78BC7}\"), AMENDMENT]\nclass Win32_Processor : CIM_Processor\n{\n  uint16   AddressWidth;\n  uint16   Architecture;\n  string   AssetTag;\n  uint16   Availability;\n  string   Caption;\n  uint32   Characteristics;\n  uint32   ConfigManagerErrorCode;\n  boolean  ConfigManagerUserConfig;\n  uint16   CpuStatus;\n  string   CreationClassName;\n  uint32   CurrentClockSpeed;\n  uint16   CurrentVoltage;\n  uint16   DataWidth;\n  string   Description;\n  string   DeviceID;\n  boolean  ErrorCleared;\n  string   ErrorDescription;\n  uint32   ExtClock;\n  uint16   Family;\n  datetime InstallDate;\n  uint32   L2CacheSize;\n  uint32   L2CacheSpeed;\n  uint32   L3CacheSize;\n  uint32   L3CacheSpeed;\n  uint32   LastErrorCode;\n  uint16   Level;\n  uint16   LoadPercentage;\n  string   Manufacturer;\n  uint32   MaxClockSpeed;\n  string   Name;\n  uint32   NumberOfCores;\n  uint32   NumberOfEnabledCore;\n  uint32   NumberOfLogicalProcessors;\n  string   OtherFamilyDescription;\n  string   PartNumber;\n  string   PNPDeviceID;\n  uint16   PowerManagementCapabilities[];\n  boolean  PowerManagementSupported;\n  string   ProcessorId;\n  uint16   ProcessorType;\n  uint16   Revision;\n  string   Role;\n  boolean  SecondLevelAddressTranslationExtensions;\n  string   SerialNumber;\n  string   SocketDesignation;\n  string   Status;\n  uint16   StatusInfo;\n  string   Stepping;\n  string   SystemCreationClassName;\n  string   SystemName;\n  uint32   ThreadCount;\n  string   UniqueId;\n  uint16   UpgradeMethod;\n  string   Version;\n  boolean  VirtualizationFirmwareEnabled;\n  boolean  VMMonitorModeExtensions;\n  uint32   VoltageCaps;\n};\n```\n## 查询操作系统信息 ##\n\n```\nimport (\n\t\"runtime\"\n\t\"github.com/StackExchange/wmi\"\n\t\"fmt\"\n)\n\ntype operatingSystem struct {\n\tName    string\n\tVersion string\n}\n\nfunc getOSInfo() {\n\tvar operatingsystem []operatingSystem\n\terr := wmi.Query(\"Select * from Win32_OperatingSystem\", &operatingsystem)\n\tif err != nil {\n\t\treturn\n\t}\n\tfmt.Printf(\"OS info =\",operatingsystem)\n}\n```\n同理，此处的operatingSystem struct中的变量和参数也可以增加，具体信息可查此[链接](https://msdn.microsoft.com/en-us/library/aa394239%28v=vs.85%29.aspx)\n## 查询内存 ##\n\n```\nimport (\n\t\"syscall\"\n\t\"unsafe\"\n\t\"fmt\"\n)\n\nvar kernel = syscall.NewLazyDLL(\"Kernel32.dll\")\n\ntype memoryStatusEx struct {\n\tcbSize                  uint32\n\tdwMemoryLoad            uint32\n\tullTotalPhys            uint64 // in bytes\n\tullAvailPhys            uint64\n\tullTotalPageFile        uint64\n\tullAvailPageFile        uint64\n\tullTotalVirtual         uint64\n\tullAvailVirtual         uint64\n\tullAvailExtendedVirtual uint64\n}\n\nfunc getMemoryInfo() {\n\n\tGlobalMemoryStatusEx := kernel.NewProc(\"GlobalMemoryStatusEx\")\n\tvar memInfo memoryStatusEx\n\tmemInfo.cbSize = uint32(unsafe.Sizeof(memInfo))\n\tmem, _, _ := GlobalMemoryStatusEx.Call(uintptr(unsafe.Pointer(&memInfo)))\n\tif mem == 0 {\n\t\treturn\n\t}\n\tfmt.printf(\"total=:\",memInfo.ullTotalPhys)\n\tfmt.printf(\"free=:\",memInfo.ullAvailPhys)\n}\n\n```\n这里我获取内存信息用的是syscall，使用wmi库应该也可以，具体大家可以看一下Windows的文档\n## 网卡信息 ##\n\n```\nimport (\n\t\"hpc-backend/utils/logs\"\n\t\"net\"\n\t\"strings\"\n\t\"fmt\"\n)\n\ntype Network struct {\n\tName       string\n\tIP         string\n\tMACAddress string\n}\n\ntype intfInfo struct {\n\tName       string\n\tMacAddress string\n\tIpv4       []string\n}\n\nfunc getNetworkInfo() error {\n\tintf, err := net.Interfaces()\n\tif err != nil {\n\t\tlogs.Error(\"get network info failed: %v\", err)\n\t\treturn err\n\t}\n\tvar is = make([]intfInfo, len(intf))\n\tfor i, v := range intf {\n\t\tips, err := v.Addrs()\n\t\tif err != nil {\n\t\t\tlogs.Error(\"get network addr failed: %v\", err)\n\t\t\treturn err\n\t\t}\n\t\t//此处过滤loopback（本地回环）和isatap（isatap隧道）\n\t\tif !strings.Contains(v.Name, \"Loopback\") && !strings.Contains(v.Name, \"isatap\") {\n\t\t\tvar network Network\n\t\t\tis[i].Name = v.Name\n\t\t\tis[i].MacAddress = v.HardwareAddr.String()\n\t\t\tfor _, ip := range ips {\n\t\t\t\tif strings.Contains(ip.String(), \".\") {\n\t\t\t\t\tis[i].Ipv4 = append(is[i].Ipv4, ip.String())\n\t\t\t\t}\n\t\t\t}\n\t\t\tnetwork.Name = is[i].Name\n\t\t\tnetwork.MACAddress = is[i].MacAddress\n\t\t\tif len(is[i].Ipv4) > 0 {\n\t\t\t\tnetwork.IP = is[i].Ipv4[0]\n\t\t\t}\n\n\t\t\tfmt.Printf(\"network:=\",network)\n\t\t}\n\n\t}\n\n\treturn nil\n}\n```\n## 磁盘 ##\n\n```\nimport (\n\t\"github.com/StackExchange/wmi\"\n\t\"fmt\"\n)\n\ntype Storage struct {\n\tName       string\n\tFileSystem string\n\tTotal      uint64\n\tFree       uint64\n}\n\ntype storageInfo struct {\n\tName       string\n\tSize       uint64\n\tFreeSpace  uint64\n\tFileSystem string\n}\n\nfunc getStorageInfo() {\n\tvar storageinfo []storageInfo\n\tvar loaclStorages []Storage\n\terr := wmi.Query(\"Select * from Win32_LogicalDisk\", &storageinfo)\n\tif err != nil {\n\t\treturn\n\t}\n\n\tfor _, storage := range storageinfo {\n\t\tinfo := Storage{\n\t\t\tName:       storage.Name,\n\t\t\tFileSystem: storage.FileSystem,\n\t\t\tTotal:      storage.Size,\n\t\t\tFree:       storage.FreeSpace,\n\t\t}\n\t\tlocalStorages = append(loaclStorages, info)\n\t}\n\tfmt.Printf(\"localStorages:=\",localStorages)\n}\n\n```\n此处使用的也是wmi库，关于磁盘空间的更多参数，请参考[这里](https://msdn.microsoft.com/en-us/library/aa394173%28v=vs.85%29.aspx)\n## GPU ##\n\n```\nimport (\n\t\"github.com/StackExchange/wmi\"\n\t\"fmt\"\n)\n\ntype gpuInfo struct {\n\tName string\n}\n\nfunc getGPUInfo() {\n\n\tvar gpuinfo []gpuInfo\n\terr := wmi.Query(\"Select * from Win32_VideoController\", &gpuinfo)\n\tif err != nil {\n\t\treturn\n\t}\n\tfmt.Printf(\"GPU:=\",gpuinfo[0].Name)\n}\n```\n此处使用的也是wmi库，更多关于GPU的参数请参考Windows官方提供的[文档](https://msdn.microsoft.com/en-us/library/aa394512%28v=vs.85%29.aspx)\n\n### 希望对大家有所帮助吧，包括关于主板的信息等等，大家都可以通过wmi这个库，参考Windows给出的官方文档，使用WQL语句进行查找 ##\n\n---------\n\n[1]: http://math.stackexchange.com/\n[2]: https://github.com/jmcmanus/pagedown-extra \"Pagedown Extra\"\n[3]: http://meta.math.stackexchange.com/questions/5020/mathjax-basic-tutorial-and-quick-reference\n[4]: http://bramp.github.io/js-sequence-diagrams/\n[5]: http://adrai.github.io/flowchart.js/\n[6]: https://github.com/benweet/stackedit\n","source":"_posts/Golang 1.10 获取Windows上的硬件数据信息.md","raw":"---\ntitle: Golang获取windows硬件数据\ncategories: Golang\n---\n\n# Golang1.10获取windows硬件数据\n   **嗯，工作原因需要使用go语言抓取windows下的硬件信息，包括CPU，GPU，内存，网卡信息，物理硬盘，系统信息等。做Golang语言开发的应该都知道，一手资料都在国外，国内的博客都是千篇一律互相Copy。所以，自己写个博客给大家分享一下，也记录一下。这里，我的golang版本是最新的1.10.1。不多说了，直接上干货**。\n   \n<!--more-->\n获取CPU信息\n-------\n\n```\nimport \t（\n    \"github.com/StackExchange/wmi\"\n    \"fmt\"\n)\ntype cpuInfo struct {\n\tName          string\n\tNumberOfCores uint32\n\tThreadCount   uint32\n}\nfunc getCPUInfo() {\n\n\tvar cpuinfo []cpuInfo\n\n\terr := wmi.Query(\"Select * from Win32_Processor\", &cpuinfo)\n\tif err != nil {\n\t\treturn\n\t}\n\tfmt.Printf(\"Cpu info =\",cpuinfo)\n}\n\n```\n这里使用的是wmi库，关于Query方法中传入的string是通过WQL语句书写的。wmi的文档点击[这里](https://godoc.org/github.com/StackExchange/wmi#CreateQuery)，另外关于Query传入的struct里的参数也是多样的，具体可参考windows官方文档，点击[这里](https://msdn.microsoft.com/en-us/library/aa394373%28v=vs.85%29.aspx)。这个文档我们后续查询其他硬件资料要常用，我这里贴一次后续就不贴了，这里可以查询的参数多种多样，具体如下：\n\n```\n[Dynamic, Provider(\"CIMWin32\"), UUID(\"{8502C4BB-5FBB-11D2-AAC1-006008C78BC7}\"), AMENDMENT]\nclass Win32_Processor : CIM_Processor\n{\n  uint16   AddressWidth;\n  uint16   Architecture;\n  string   AssetTag;\n  uint16   Availability;\n  string   Caption;\n  uint32   Characteristics;\n  uint32   ConfigManagerErrorCode;\n  boolean  ConfigManagerUserConfig;\n  uint16   CpuStatus;\n  string   CreationClassName;\n  uint32   CurrentClockSpeed;\n  uint16   CurrentVoltage;\n  uint16   DataWidth;\n  string   Description;\n  string   DeviceID;\n  boolean  ErrorCleared;\n  string   ErrorDescription;\n  uint32   ExtClock;\n  uint16   Family;\n  datetime InstallDate;\n  uint32   L2CacheSize;\n  uint32   L2CacheSpeed;\n  uint32   L3CacheSize;\n  uint32   L3CacheSpeed;\n  uint32   LastErrorCode;\n  uint16   Level;\n  uint16   LoadPercentage;\n  string   Manufacturer;\n  uint32   MaxClockSpeed;\n  string   Name;\n  uint32   NumberOfCores;\n  uint32   NumberOfEnabledCore;\n  uint32   NumberOfLogicalProcessors;\n  string   OtherFamilyDescription;\n  string   PartNumber;\n  string   PNPDeviceID;\n  uint16   PowerManagementCapabilities[];\n  boolean  PowerManagementSupported;\n  string   ProcessorId;\n  uint16   ProcessorType;\n  uint16   Revision;\n  string   Role;\n  boolean  SecondLevelAddressTranslationExtensions;\n  string   SerialNumber;\n  string   SocketDesignation;\n  string   Status;\n  uint16   StatusInfo;\n  string   Stepping;\n  string   SystemCreationClassName;\n  string   SystemName;\n  uint32   ThreadCount;\n  string   UniqueId;\n  uint16   UpgradeMethod;\n  string   Version;\n  boolean  VirtualizationFirmwareEnabled;\n  boolean  VMMonitorModeExtensions;\n  uint32   VoltageCaps;\n};\n```\n## 查询操作系统信息 ##\n\n```\nimport (\n\t\"runtime\"\n\t\"github.com/StackExchange/wmi\"\n\t\"fmt\"\n)\n\ntype operatingSystem struct {\n\tName    string\n\tVersion string\n}\n\nfunc getOSInfo() {\n\tvar operatingsystem []operatingSystem\n\terr := wmi.Query(\"Select * from Win32_OperatingSystem\", &operatingsystem)\n\tif err != nil {\n\t\treturn\n\t}\n\tfmt.Printf(\"OS info =\",operatingsystem)\n}\n```\n同理，此处的operatingSystem struct中的变量和参数也可以增加，具体信息可查此[链接](https://msdn.microsoft.com/en-us/library/aa394239%28v=vs.85%29.aspx)\n## 查询内存 ##\n\n```\nimport (\n\t\"syscall\"\n\t\"unsafe\"\n\t\"fmt\"\n)\n\nvar kernel = syscall.NewLazyDLL(\"Kernel32.dll\")\n\ntype memoryStatusEx struct {\n\tcbSize                  uint32\n\tdwMemoryLoad            uint32\n\tullTotalPhys            uint64 // in bytes\n\tullAvailPhys            uint64\n\tullTotalPageFile        uint64\n\tullAvailPageFile        uint64\n\tullTotalVirtual         uint64\n\tullAvailVirtual         uint64\n\tullAvailExtendedVirtual uint64\n}\n\nfunc getMemoryInfo() {\n\n\tGlobalMemoryStatusEx := kernel.NewProc(\"GlobalMemoryStatusEx\")\n\tvar memInfo memoryStatusEx\n\tmemInfo.cbSize = uint32(unsafe.Sizeof(memInfo))\n\tmem, _, _ := GlobalMemoryStatusEx.Call(uintptr(unsafe.Pointer(&memInfo)))\n\tif mem == 0 {\n\t\treturn\n\t}\n\tfmt.printf(\"total=:\",memInfo.ullTotalPhys)\n\tfmt.printf(\"free=:\",memInfo.ullAvailPhys)\n}\n\n```\n这里我获取内存信息用的是syscall，使用wmi库应该也可以，具体大家可以看一下Windows的文档\n## 网卡信息 ##\n\n```\nimport (\n\t\"hpc-backend/utils/logs\"\n\t\"net\"\n\t\"strings\"\n\t\"fmt\"\n)\n\ntype Network struct {\n\tName       string\n\tIP         string\n\tMACAddress string\n}\n\ntype intfInfo struct {\n\tName       string\n\tMacAddress string\n\tIpv4       []string\n}\n\nfunc getNetworkInfo() error {\n\tintf, err := net.Interfaces()\n\tif err != nil {\n\t\tlogs.Error(\"get network info failed: %v\", err)\n\t\treturn err\n\t}\n\tvar is = make([]intfInfo, len(intf))\n\tfor i, v := range intf {\n\t\tips, err := v.Addrs()\n\t\tif err != nil {\n\t\t\tlogs.Error(\"get network addr failed: %v\", err)\n\t\t\treturn err\n\t\t}\n\t\t//此处过滤loopback（本地回环）和isatap（isatap隧道）\n\t\tif !strings.Contains(v.Name, \"Loopback\") && !strings.Contains(v.Name, \"isatap\") {\n\t\t\tvar network Network\n\t\t\tis[i].Name = v.Name\n\t\t\tis[i].MacAddress = v.HardwareAddr.String()\n\t\t\tfor _, ip := range ips {\n\t\t\t\tif strings.Contains(ip.String(), \".\") {\n\t\t\t\t\tis[i].Ipv4 = append(is[i].Ipv4, ip.String())\n\t\t\t\t}\n\t\t\t}\n\t\t\tnetwork.Name = is[i].Name\n\t\t\tnetwork.MACAddress = is[i].MacAddress\n\t\t\tif len(is[i].Ipv4) > 0 {\n\t\t\t\tnetwork.IP = is[i].Ipv4[0]\n\t\t\t}\n\n\t\t\tfmt.Printf(\"network:=\",network)\n\t\t}\n\n\t}\n\n\treturn nil\n}\n```\n## 磁盘 ##\n\n```\nimport (\n\t\"github.com/StackExchange/wmi\"\n\t\"fmt\"\n)\n\ntype Storage struct {\n\tName       string\n\tFileSystem string\n\tTotal      uint64\n\tFree       uint64\n}\n\ntype storageInfo struct {\n\tName       string\n\tSize       uint64\n\tFreeSpace  uint64\n\tFileSystem string\n}\n\nfunc getStorageInfo() {\n\tvar storageinfo []storageInfo\n\tvar loaclStorages []Storage\n\terr := wmi.Query(\"Select * from Win32_LogicalDisk\", &storageinfo)\n\tif err != nil {\n\t\treturn\n\t}\n\n\tfor _, storage := range storageinfo {\n\t\tinfo := Storage{\n\t\t\tName:       storage.Name,\n\t\t\tFileSystem: storage.FileSystem,\n\t\t\tTotal:      storage.Size,\n\t\t\tFree:       storage.FreeSpace,\n\t\t}\n\t\tlocalStorages = append(loaclStorages, info)\n\t}\n\tfmt.Printf(\"localStorages:=\",localStorages)\n}\n\n```\n此处使用的也是wmi库，关于磁盘空间的更多参数，请参考[这里](https://msdn.microsoft.com/en-us/library/aa394173%28v=vs.85%29.aspx)\n## GPU ##\n\n```\nimport (\n\t\"github.com/StackExchange/wmi\"\n\t\"fmt\"\n)\n\ntype gpuInfo struct {\n\tName string\n}\n\nfunc getGPUInfo() {\n\n\tvar gpuinfo []gpuInfo\n\terr := wmi.Query(\"Select * from Win32_VideoController\", &gpuinfo)\n\tif err != nil {\n\t\treturn\n\t}\n\tfmt.Printf(\"GPU:=\",gpuinfo[0].Name)\n}\n```\n此处使用的也是wmi库，更多关于GPU的参数请参考Windows官方提供的[文档](https://msdn.microsoft.com/en-us/library/aa394512%28v=vs.85%29.aspx)\n\n### 希望对大家有所帮助吧，包括关于主板的信息等等，大家都可以通过wmi这个库，参考Windows给出的官方文档，使用WQL语句进行查找 ##\n\n---------\n\n[1]: http://math.stackexchange.com/\n[2]: https://github.com/jmcmanus/pagedown-extra \"Pagedown Extra\"\n[3]: http://meta.math.stackexchange.com/questions/5020/mathjax-basic-tutorial-and-quick-reference\n[4]: http://bramp.github.io/js-sequence-diagrams/\n[5]: http://adrai.github.io/flowchart.js/\n[6]: https://github.com/benweet/stackedit\n","slug":"Golang 1.10 获取Windows上的硬件数据信息","published":1,"date":"2020-04-05T03:06:43.062Z","updated":"2020-04-05T03:06:43.062Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck8x0luv000002otvzp5lsh3x","content":"<h1 id=\"Golang1-10获取windows硬件数据\"><a href=\"#Golang1-10获取windows硬件数据\" class=\"headerlink\" title=\"Golang1.10获取windows硬件数据\"></a>Golang1.10获取windows硬件数据</h1><p>   <strong>嗯，工作原因需要使用go语言抓取windows下的硬件信息，包括CPU，GPU，内存，网卡信息，物理硬盘，系统信息等。做Golang语言开发的应该都知道，一手资料都在国外，国内的博客都是千篇一律互相Copy。所以，自己写个博客给大家分享一下，也记录一下。这里，我的golang版本是最新的1.10.1。不多说了，直接上干货</strong>。</p>\n<a id=\"more\"></a>\n<h2 id=\"获取CPU信息\"><a href=\"#获取CPU信息\" class=\"headerlink\" title=\"获取CPU信息\"></a>获取CPU信息</h2><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">import \t（</span><br><span class=\"line\">    &quot;github.com/StackExchange/wmi&quot;</span><br><span class=\"line\">    &quot;fmt&quot;</span><br><span class=\"line\">)</span><br><span class=\"line\">type cpuInfo struct &#123;</span><br><span class=\"line\">\tName          string</span><br><span class=\"line\">\tNumberOfCores uint32</span><br><span class=\"line\">\tThreadCount   uint32</span><br><span class=\"line\">&#125;</span><br><span class=\"line\">func getCPUInfo() &#123;</span><br><span class=\"line\"></span><br><span class=\"line\">\tvar cpuinfo []cpuInfo</span><br><span class=\"line\"></span><br><span class=\"line\">\terr := wmi.Query(&quot;Select * from Win32_Processor&quot;, &amp;cpuinfo)</span><br><span class=\"line\">\tif err != nil &#123;</span><br><span class=\"line\">\t\treturn</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">\tfmt.Printf(&quot;Cpu info =&quot;,cpuinfo)</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>这里使用的是wmi库，关于Query方法中传入的string是通过WQL语句书写的。wmi的文档点击<a href=\"https://godoc.org/github.com/StackExchange/wmi#CreateQuery\" target=\"_blank\" rel=\"noopener\">这里</a>，另外关于Query传入的struct里的参数也是多样的，具体可参考windows官方文档，点击<a href=\"https://msdn.microsoft.com/en-us/library/aa394373%28v=vs.85%29.aspx\" target=\"_blank\" rel=\"noopener\">这里</a>。这个文档我们后续查询其他硬件资料要常用，我这里贴一次后续就不贴了，这里可以查询的参数多种多样，具体如下：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[Dynamic, Provider(&quot;CIMWin32&quot;), UUID(&quot;&#123;8502C4BB-5FBB-11D2-AAC1-006008C78BC7&#125;&quot;), AMENDMENT]</span><br><span class=\"line\">class Win32_Processor : CIM_Processor</span><br><span class=\"line\">&#123;</span><br><span class=\"line\">  uint16   AddressWidth;</span><br><span class=\"line\">  uint16   Architecture;</span><br><span class=\"line\">  string   AssetTag;</span><br><span class=\"line\">  uint16   Availability;</span><br><span class=\"line\">  string   Caption;</span><br><span class=\"line\">  uint32   Characteristics;</span><br><span class=\"line\">  uint32   ConfigManagerErrorCode;</span><br><span class=\"line\">  boolean  ConfigManagerUserConfig;</span><br><span class=\"line\">  uint16   CpuStatus;</span><br><span class=\"line\">  string   CreationClassName;</span><br><span class=\"line\">  uint32   CurrentClockSpeed;</span><br><span class=\"line\">  uint16   CurrentVoltage;</span><br><span class=\"line\">  uint16   DataWidth;</span><br><span class=\"line\">  string   Description;</span><br><span class=\"line\">  string   DeviceID;</span><br><span class=\"line\">  boolean  ErrorCleared;</span><br><span class=\"line\">  string   ErrorDescription;</span><br><span class=\"line\">  uint32   ExtClock;</span><br><span class=\"line\">  uint16   Family;</span><br><span class=\"line\">  datetime InstallDate;</span><br><span class=\"line\">  uint32   L2CacheSize;</span><br><span class=\"line\">  uint32   L2CacheSpeed;</span><br><span class=\"line\">  uint32   L3CacheSize;</span><br><span class=\"line\">  uint32   L3CacheSpeed;</span><br><span class=\"line\">  uint32   LastErrorCode;</span><br><span class=\"line\">  uint16   Level;</span><br><span class=\"line\">  uint16   LoadPercentage;</span><br><span class=\"line\">  string   Manufacturer;</span><br><span class=\"line\">  uint32   MaxClockSpeed;</span><br><span class=\"line\">  string   Name;</span><br><span class=\"line\">  uint32   NumberOfCores;</span><br><span class=\"line\">  uint32   NumberOfEnabledCore;</span><br><span class=\"line\">  uint32   NumberOfLogicalProcessors;</span><br><span class=\"line\">  string   OtherFamilyDescription;</span><br><span class=\"line\">  string   PartNumber;</span><br><span class=\"line\">  string   PNPDeviceID;</span><br><span class=\"line\">  uint16   PowerManagementCapabilities[];</span><br><span class=\"line\">  boolean  PowerManagementSupported;</span><br><span class=\"line\">  string   ProcessorId;</span><br><span class=\"line\">  uint16   ProcessorType;</span><br><span class=\"line\">  uint16   Revision;</span><br><span class=\"line\">  string   Role;</span><br><span class=\"line\">  boolean  SecondLevelAddressTranslationExtensions;</span><br><span class=\"line\">  string   SerialNumber;</span><br><span class=\"line\">  string   SocketDesignation;</span><br><span class=\"line\">  string   Status;</span><br><span class=\"line\">  uint16   StatusInfo;</span><br><span class=\"line\">  string   Stepping;</span><br><span class=\"line\">  string   SystemCreationClassName;</span><br><span class=\"line\">  string   SystemName;</span><br><span class=\"line\">  uint32   ThreadCount;</span><br><span class=\"line\">  string   UniqueId;</span><br><span class=\"line\">  uint16   UpgradeMethod;</span><br><span class=\"line\">  string   Version;</span><br><span class=\"line\">  boolean  VirtualizationFirmwareEnabled;</span><br><span class=\"line\">  boolean  VMMonitorModeExtensions;</span><br><span class=\"line\">  uint32   VoltageCaps;</span><br><span class=\"line\">&#125;;</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"查询操作系统信息\"><a href=\"#查询操作系统信息\" class=\"headerlink\" title=\"查询操作系统信息\"></a>查询操作系统信息</h2><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">import (</span><br><span class=\"line\">\t&quot;runtime&quot;</span><br><span class=\"line\">\t&quot;github.com/StackExchange/wmi&quot;</span><br><span class=\"line\">\t&quot;fmt&quot;</span><br><span class=\"line\">)</span><br><span class=\"line\"></span><br><span class=\"line\">type operatingSystem struct &#123;</span><br><span class=\"line\">\tName    string</span><br><span class=\"line\">\tVersion string</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">func getOSInfo() &#123;</span><br><span class=\"line\">\tvar operatingsystem []operatingSystem</span><br><span class=\"line\">\terr := wmi.Query(&quot;Select * from Win32_OperatingSystem&quot;, &amp;operatingsystem)</span><br><span class=\"line\">\tif err != nil &#123;</span><br><span class=\"line\">\t\treturn</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">\tfmt.Printf(&quot;OS info =&quot;,operatingsystem)</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>同理，此处的operatingSystem struct中的变量和参数也可以增加，具体信息可查此<a href=\"https://msdn.microsoft.com/en-us/library/aa394239%28v=vs.85%29.aspx\" target=\"_blank\" rel=\"noopener\">链接</a></p>\n<h2 id=\"查询内存\"><a href=\"#查询内存\" class=\"headerlink\" title=\"查询内存\"></a>查询内存</h2><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">import (</span><br><span class=\"line\">\t&quot;syscall&quot;</span><br><span class=\"line\">\t&quot;unsafe&quot;</span><br><span class=\"line\">\t&quot;fmt&quot;</span><br><span class=\"line\">)</span><br><span class=\"line\"></span><br><span class=\"line\">var kernel = syscall.NewLazyDLL(&quot;Kernel32.dll&quot;)</span><br><span class=\"line\"></span><br><span class=\"line\">type memoryStatusEx struct &#123;</span><br><span class=\"line\">\tcbSize                  uint32</span><br><span class=\"line\">\tdwMemoryLoad            uint32</span><br><span class=\"line\">\tullTotalPhys            uint64 // in bytes</span><br><span class=\"line\">\tullAvailPhys            uint64</span><br><span class=\"line\">\tullTotalPageFile        uint64</span><br><span class=\"line\">\tullAvailPageFile        uint64</span><br><span class=\"line\">\tullTotalVirtual         uint64</span><br><span class=\"line\">\tullAvailVirtual         uint64</span><br><span class=\"line\">\tullAvailExtendedVirtual uint64</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">func getMemoryInfo() &#123;</span><br><span class=\"line\"></span><br><span class=\"line\">\tGlobalMemoryStatusEx := kernel.NewProc(&quot;GlobalMemoryStatusEx&quot;)</span><br><span class=\"line\">\tvar memInfo memoryStatusEx</span><br><span class=\"line\">\tmemInfo.cbSize = uint32(unsafe.Sizeof(memInfo))</span><br><span class=\"line\">\tmem, _, _ := GlobalMemoryStatusEx.Call(uintptr(unsafe.Pointer(&amp;memInfo)))</span><br><span class=\"line\">\tif mem == 0 &#123;</span><br><span class=\"line\">\t\treturn</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">\tfmt.printf(&quot;total=:&quot;,memInfo.ullTotalPhys)</span><br><span class=\"line\">\tfmt.printf(&quot;free=:&quot;,memInfo.ullAvailPhys)</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>这里我获取内存信息用的是syscall，使用wmi库应该也可以，具体大家可以看一下Windows的文档</p>\n<h2 id=\"网卡信息\"><a href=\"#网卡信息\" class=\"headerlink\" title=\"网卡信息\"></a>网卡信息</h2><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">import (</span><br><span class=\"line\">\t&quot;hpc-backend/utils/logs&quot;</span><br><span class=\"line\">\t&quot;net&quot;</span><br><span class=\"line\">\t&quot;strings&quot;</span><br><span class=\"line\">\t&quot;fmt&quot;</span><br><span class=\"line\">)</span><br><span class=\"line\"></span><br><span class=\"line\">type Network struct &#123;</span><br><span class=\"line\">\tName       string</span><br><span class=\"line\">\tIP         string</span><br><span class=\"line\">\tMACAddress string</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">type intfInfo struct &#123;</span><br><span class=\"line\">\tName       string</span><br><span class=\"line\">\tMacAddress string</span><br><span class=\"line\">\tIpv4       []string</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">func getNetworkInfo() error &#123;</span><br><span class=\"line\">\tintf, err := net.Interfaces()</span><br><span class=\"line\">\tif err != nil &#123;</span><br><span class=\"line\">\t\tlogs.Error(&quot;get network info failed: %v&quot;, err)</span><br><span class=\"line\">\t\treturn err</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">\tvar is = make([]intfInfo, len(intf))</span><br><span class=\"line\">\tfor i, v := range intf &#123;</span><br><span class=\"line\">\t\tips, err := v.Addrs()</span><br><span class=\"line\">\t\tif err != nil &#123;</span><br><span class=\"line\">\t\t\tlogs.Error(&quot;get network addr failed: %v&quot;, err)</span><br><span class=\"line\">\t\t\treturn err</span><br><span class=\"line\">\t\t&#125;</span><br><span class=\"line\">\t\t//此处过滤loopback（本地回环）和isatap（isatap隧道）</span><br><span class=\"line\">\t\tif !strings.Contains(v.Name, &quot;Loopback&quot;) &amp;&amp; !strings.Contains(v.Name, &quot;isatap&quot;) &#123;</span><br><span class=\"line\">\t\t\tvar network Network</span><br><span class=\"line\">\t\t\tis[i].Name = v.Name</span><br><span class=\"line\">\t\t\tis[i].MacAddress = v.HardwareAddr.String()</span><br><span class=\"line\">\t\t\tfor _, ip := range ips &#123;</span><br><span class=\"line\">\t\t\t\tif strings.Contains(ip.String(), &quot;.&quot;) &#123;</span><br><span class=\"line\">\t\t\t\t\tis[i].Ipv4 = append(is[i].Ipv4, ip.String())</span><br><span class=\"line\">\t\t\t\t&#125;</span><br><span class=\"line\">\t\t\t&#125;</span><br><span class=\"line\">\t\t\tnetwork.Name = is[i].Name</span><br><span class=\"line\">\t\t\tnetwork.MACAddress = is[i].MacAddress</span><br><span class=\"line\">\t\t\tif len(is[i].Ipv4) &gt; 0 &#123;</span><br><span class=\"line\">\t\t\t\tnetwork.IP = is[i].Ipv4[0]</span><br><span class=\"line\">\t\t\t&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">\t\t\tfmt.Printf(&quot;network:=&quot;,network)</span><br><span class=\"line\">\t\t&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">\treturn nil</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"磁盘\"><a href=\"#磁盘\" class=\"headerlink\" title=\"磁盘\"></a>磁盘</h2><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">import (</span><br><span class=\"line\">\t&quot;github.com/StackExchange/wmi&quot;</span><br><span class=\"line\">\t&quot;fmt&quot;</span><br><span class=\"line\">)</span><br><span class=\"line\"></span><br><span class=\"line\">type Storage struct &#123;</span><br><span class=\"line\">\tName       string</span><br><span class=\"line\">\tFileSystem string</span><br><span class=\"line\">\tTotal      uint64</span><br><span class=\"line\">\tFree       uint64</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">type storageInfo struct &#123;</span><br><span class=\"line\">\tName       string</span><br><span class=\"line\">\tSize       uint64</span><br><span class=\"line\">\tFreeSpace  uint64</span><br><span class=\"line\">\tFileSystem string</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">func getStorageInfo() &#123;</span><br><span class=\"line\">\tvar storageinfo []storageInfo</span><br><span class=\"line\">\tvar loaclStorages []Storage</span><br><span class=\"line\">\terr := wmi.Query(&quot;Select * from Win32_LogicalDisk&quot;, &amp;storageinfo)</span><br><span class=\"line\">\tif err != nil &#123;</span><br><span class=\"line\">\t\treturn</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">\tfor _, storage := range storageinfo &#123;</span><br><span class=\"line\">\t\tinfo := Storage&#123;</span><br><span class=\"line\">\t\t\tName:       storage.Name,</span><br><span class=\"line\">\t\t\tFileSystem: storage.FileSystem,</span><br><span class=\"line\">\t\t\tTotal:      storage.Size,</span><br><span class=\"line\">\t\t\tFree:       storage.FreeSpace,</span><br><span class=\"line\">\t\t&#125;</span><br><span class=\"line\">\t\tlocalStorages = append(loaclStorages, info)</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">\tfmt.Printf(&quot;localStorages:=&quot;,localStorages)</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>此处使用的也是wmi库，关于磁盘空间的更多参数，请参考<a href=\"https://msdn.microsoft.com/en-us/library/aa394173%28v=vs.85%29.aspx\" target=\"_blank\" rel=\"noopener\">这里</a></p>\n<h2 id=\"GPU\"><a href=\"#GPU\" class=\"headerlink\" title=\"GPU\"></a>GPU</h2><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">import (</span><br><span class=\"line\">\t&quot;github.com/StackExchange/wmi&quot;</span><br><span class=\"line\">\t&quot;fmt&quot;</span><br><span class=\"line\">)</span><br><span class=\"line\"></span><br><span class=\"line\">type gpuInfo struct &#123;</span><br><span class=\"line\">\tName string</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">func getGPUInfo() &#123;</span><br><span class=\"line\"></span><br><span class=\"line\">\tvar gpuinfo []gpuInfo</span><br><span class=\"line\">\terr := wmi.Query(&quot;Select * from Win32_VideoController&quot;, &amp;gpuinfo)</span><br><span class=\"line\">\tif err != nil &#123;</span><br><span class=\"line\">\t\treturn</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">\tfmt.Printf(&quot;GPU:=&quot;,gpuinfo[0].Name)</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>此处使用的也是wmi库，更多关于GPU的参数请参考Windows官方提供的<a href=\"https://msdn.microsoft.com/en-us/library/aa394512%28v=vs.85%29.aspx\" target=\"_blank\" rel=\"noopener\">文档</a></p>\n<h3 id=\"希望对大家有所帮助吧，包括关于主板的信息等等，大家都可以通过wmi这个库，参考Windows给出的官方文档，使用WQL语句进行查找\"><a href=\"#希望对大家有所帮助吧，包括关于主板的信息等等，大家都可以通过wmi这个库，参考Windows给出的官方文档，使用WQL语句进行查找\" class=\"headerlink\" title=\"希望对大家有所帮助吧，包括关于主板的信息等等，大家都可以通过wmi这个库，参考Windows给出的官方文档，使用WQL语句进行查找\"></a>希望对大家有所帮助吧，包括关于主板的信息等等，大家都可以通过wmi这个库，参考Windows给出的官方文档，使用WQL语句进行查找</h3><hr>\n","site":{"data":{}},"excerpt":"<h1 id=\"Golang1-10获取windows硬件数据\"><a href=\"#Golang1-10获取windows硬件数据\" class=\"headerlink\" title=\"Golang1.10获取windows硬件数据\"></a>Golang1.10获取windows硬件数据</h1><p>   <strong>嗯，工作原因需要使用go语言抓取windows下的硬件信息，包括CPU，GPU，内存，网卡信息，物理硬盘，系统信息等。做Golang语言开发的应该都知道，一手资料都在国外，国内的博客都是千篇一律互相Copy。所以，自己写个博客给大家分享一下，也记录一下。这里，我的golang版本是最新的1.10.1。不多说了，直接上干货</strong>。</p>","more":"<h2 id=\"获取CPU信息\"><a href=\"#获取CPU信息\" class=\"headerlink\" title=\"获取CPU信息\"></a>获取CPU信息</h2><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">import \t（</span><br><span class=\"line\">    &quot;github.com/StackExchange/wmi&quot;</span><br><span class=\"line\">    &quot;fmt&quot;</span><br><span class=\"line\">)</span><br><span class=\"line\">type cpuInfo struct &#123;</span><br><span class=\"line\">\tName          string</span><br><span class=\"line\">\tNumberOfCores uint32</span><br><span class=\"line\">\tThreadCount   uint32</span><br><span class=\"line\">&#125;</span><br><span class=\"line\">func getCPUInfo() &#123;</span><br><span class=\"line\"></span><br><span class=\"line\">\tvar cpuinfo []cpuInfo</span><br><span class=\"line\"></span><br><span class=\"line\">\terr := wmi.Query(&quot;Select * from Win32_Processor&quot;, &amp;cpuinfo)</span><br><span class=\"line\">\tif err != nil &#123;</span><br><span class=\"line\">\t\treturn</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">\tfmt.Printf(&quot;Cpu info =&quot;,cpuinfo)</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>这里使用的是wmi库，关于Query方法中传入的string是通过WQL语句书写的。wmi的文档点击<a href=\"https://godoc.org/github.com/StackExchange/wmi#CreateQuery\" target=\"_blank\" rel=\"noopener\">这里</a>，另外关于Query传入的struct里的参数也是多样的，具体可参考windows官方文档，点击<a href=\"https://msdn.microsoft.com/en-us/library/aa394373%28v=vs.85%29.aspx\" target=\"_blank\" rel=\"noopener\">这里</a>。这个文档我们后续查询其他硬件资料要常用，我这里贴一次后续就不贴了，这里可以查询的参数多种多样，具体如下：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[Dynamic, Provider(&quot;CIMWin32&quot;), UUID(&quot;&#123;8502C4BB-5FBB-11D2-AAC1-006008C78BC7&#125;&quot;), AMENDMENT]</span><br><span class=\"line\">class Win32_Processor : CIM_Processor</span><br><span class=\"line\">&#123;</span><br><span class=\"line\">  uint16   AddressWidth;</span><br><span class=\"line\">  uint16   Architecture;</span><br><span class=\"line\">  string   AssetTag;</span><br><span class=\"line\">  uint16   Availability;</span><br><span class=\"line\">  string   Caption;</span><br><span class=\"line\">  uint32   Characteristics;</span><br><span class=\"line\">  uint32   ConfigManagerErrorCode;</span><br><span class=\"line\">  boolean  ConfigManagerUserConfig;</span><br><span class=\"line\">  uint16   CpuStatus;</span><br><span class=\"line\">  string   CreationClassName;</span><br><span class=\"line\">  uint32   CurrentClockSpeed;</span><br><span class=\"line\">  uint16   CurrentVoltage;</span><br><span class=\"line\">  uint16   DataWidth;</span><br><span class=\"line\">  string   Description;</span><br><span class=\"line\">  string   DeviceID;</span><br><span class=\"line\">  boolean  ErrorCleared;</span><br><span class=\"line\">  string   ErrorDescription;</span><br><span class=\"line\">  uint32   ExtClock;</span><br><span class=\"line\">  uint16   Family;</span><br><span class=\"line\">  datetime InstallDate;</span><br><span class=\"line\">  uint32   L2CacheSize;</span><br><span class=\"line\">  uint32   L2CacheSpeed;</span><br><span class=\"line\">  uint32   L3CacheSize;</span><br><span class=\"line\">  uint32   L3CacheSpeed;</span><br><span class=\"line\">  uint32   LastErrorCode;</span><br><span class=\"line\">  uint16   Level;</span><br><span class=\"line\">  uint16   LoadPercentage;</span><br><span class=\"line\">  string   Manufacturer;</span><br><span class=\"line\">  uint32   MaxClockSpeed;</span><br><span class=\"line\">  string   Name;</span><br><span class=\"line\">  uint32   NumberOfCores;</span><br><span class=\"line\">  uint32   NumberOfEnabledCore;</span><br><span class=\"line\">  uint32   NumberOfLogicalProcessors;</span><br><span class=\"line\">  string   OtherFamilyDescription;</span><br><span class=\"line\">  string   PartNumber;</span><br><span class=\"line\">  string   PNPDeviceID;</span><br><span class=\"line\">  uint16   PowerManagementCapabilities[];</span><br><span class=\"line\">  boolean  PowerManagementSupported;</span><br><span class=\"line\">  string   ProcessorId;</span><br><span class=\"line\">  uint16   ProcessorType;</span><br><span class=\"line\">  uint16   Revision;</span><br><span class=\"line\">  string   Role;</span><br><span class=\"line\">  boolean  SecondLevelAddressTranslationExtensions;</span><br><span class=\"line\">  string   SerialNumber;</span><br><span class=\"line\">  string   SocketDesignation;</span><br><span class=\"line\">  string   Status;</span><br><span class=\"line\">  uint16   StatusInfo;</span><br><span class=\"line\">  string   Stepping;</span><br><span class=\"line\">  string   SystemCreationClassName;</span><br><span class=\"line\">  string   SystemName;</span><br><span class=\"line\">  uint32   ThreadCount;</span><br><span class=\"line\">  string   UniqueId;</span><br><span class=\"line\">  uint16   UpgradeMethod;</span><br><span class=\"line\">  string   Version;</span><br><span class=\"line\">  boolean  VirtualizationFirmwareEnabled;</span><br><span class=\"line\">  boolean  VMMonitorModeExtensions;</span><br><span class=\"line\">  uint32   VoltageCaps;</span><br><span class=\"line\">&#125;;</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"查询操作系统信息\"><a href=\"#查询操作系统信息\" class=\"headerlink\" title=\"查询操作系统信息\"></a>查询操作系统信息</h2><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">import (</span><br><span class=\"line\">\t&quot;runtime&quot;</span><br><span class=\"line\">\t&quot;github.com/StackExchange/wmi&quot;</span><br><span class=\"line\">\t&quot;fmt&quot;</span><br><span class=\"line\">)</span><br><span class=\"line\"></span><br><span class=\"line\">type operatingSystem struct &#123;</span><br><span class=\"line\">\tName    string</span><br><span class=\"line\">\tVersion string</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">func getOSInfo() &#123;</span><br><span class=\"line\">\tvar operatingsystem []operatingSystem</span><br><span class=\"line\">\terr := wmi.Query(&quot;Select * from Win32_OperatingSystem&quot;, &amp;operatingsystem)</span><br><span class=\"line\">\tif err != nil &#123;</span><br><span class=\"line\">\t\treturn</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">\tfmt.Printf(&quot;OS info =&quot;,operatingsystem)</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>同理，此处的operatingSystem struct中的变量和参数也可以增加，具体信息可查此<a href=\"https://msdn.microsoft.com/en-us/library/aa394239%28v=vs.85%29.aspx\" target=\"_blank\" rel=\"noopener\">链接</a></p>\n<h2 id=\"查询内存\"><a href=\"#查询内存\" class=\"headerlink\" title=\"查询内存\"></a>查询内存</h2><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">import (</span><br><span class=\"line\">\t&quot;syscall&quot;</span><br><span class=\"line\">\t&quot;unsafe&quot;</span><br><span class=\"line\">\t&quot;fmt&quot;</span><br><span class=\"line\">)</span><br><span class=\"line\"></span><br><span class=\"line\">var kernel = syscall.NewLazyDLL(&quot;Kernel32.dll&quot;)</span><br><span class=\"line\"></span><br><span class=\"line\">type memoryStatusEx struct &#123;</span><br><span class=\"line\">\tcbSize                  uint32</span><br><span class=\"line\">\tdwMemoryLoad            uint32</span><br><span class=\"line\">\tullTotalPhys            uint64 // in bytes</span><br><span class=\"line\">\tullAvailPhys            uint64</span><br><span class=\"line\">\tullTotalPageFile        uint64</span><br><span class=\"line\">\tullAvailPageFile        uint64</span><br><span class=\"line\">\tullTotalVirtual         uint64</span><br><span class=\"line\">\tullAvailVirtual         uint64</span><br><span class=\"line\">\tullAvailExtendedVirtual uint64</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">func getMemoryInfo() &#123;</span><br><span class=\"line\"></span><br><span class=\"line\">\tGlobalMemoryStatusEx := kernel.NewProc(&quot;GlobalMemoryStatusEx&quot;)</span><br><span class=\"line\">\tvar memInfo memoryStatusEx</span><br><span class=\"line\">\tmemInfo.cbSize = uint32(unsafe.Sizeof(memInfo))</span><br><span class=\"line\">\tmem, _, _ := GlobalMemoryStatusEx.Call(uintptr(unsafe.Pointer(&amp;memInfo)))</span><br><span class=\"line\">\tif mem == 0 &#123;</span><br><span class=\"line\">\t\treturn</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">\tfmt.printf(&quot;total=:&quot;,memInfo.ullTotalPhys)</span><br><span class=\"line\">\tfmt.printf(&quot;free=:&quot;,memInfo.ullAvailPhys)</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>这里我获取内存信息用的是syscall，使用wmi库应该也可以，具体大家可以看一下Windows的文档</p>\n<h2 id=\"网卡信息\"><a href=\"#网卡信息\" class=\"headerlink\" title=\"网卡信息\"></a>网卡信息</h2><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">import (</span><br><span class=\"line\">\t&quot;hpc-backend/utils/logs&quot;</span><br><span class=\"line\">\t&quot;net&quot;</span><br><span class=\"line\">\t&quot;strings&quot;</span><br><span class=\"line\">\t&quot;fmt&quot;</span><br><span class=\"line\">)</span><br><span class=\"line\"></span><br><span class=\"line\">type Network struct &#123;</span><br><span class=\"line\">\tName       string</span><br><span class=\"line\">\tIP         string</span><br><span class=\"line\">\tMACAddress string</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">type intfInfo struct &#123;</span><br><span class=\"line\">\tName       string</span><br><span class=\"line\">\tMacAddress string</span><br><span class=\"line\">\tIpv4       []string</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">func getNetworkInfo() error &#123;</span><br><span class=\"line\">\tintf, err := net.Interfaces()</span><br><span class=\"line\">\tif err != nil &#123;</span><br><span class=\"line\">\t\tlogs.Error(&quot;get network info failed: %v&quot;, err)</span><br><span class=\"line\">\t\treturn err</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">\tvar is = make([]intfInfo, len(intf))</span><br><span class=\"line\">\tfor i, v := range intf &#123;</span><br><span class=\"line\">\t\tips, err := v.Addrs()</span><br><span class=\"line\">\t\tif err != nil &#123;</span><br><span class=\"line\">\t\t\tlogs.Error(&quot;get network addr failed: %v&quot;, err)</span><br><span class=\"line\">\t\t\treturn err</span><br><span class=\"line\">\t\t&#125;</span><br><span class=\"line\">\t\t//此处过滤loopback（本地回环）和isatap（isatap隧道）</span><br><span class=\"line\">\t\tif !strings.Contains(v.Name, &quot;Loopback&quot;) &amp;&amp; !strings.Contains(v.Name, &quot;isatap&quot;) &#123;</span><br><span class=\"line\">\t\t\tvar network Network</span><br><span class=\"line\">\t\t\tis[i].Name = v.Name</span><br><span class=\"line\">\t\t\tis[i].MacAddress = v.HardwareAddr.String()</span><br><span class=\"line\">\t\t\tfor _, ip := range ips &#123;</span><br><span class=\"line\">\t\t\t\tif strings.Contains(ip.String(), &quot;.&quot;) &#123;</span><br><span class=\"line\">\t\t\t\t\tis[i].Ipv4 = append(is[i].Ipv4, ip.String())</span><br><span class=\"line\">\t\t\t\t&#125;</span><br><span class=\"line\">\t\t\t&#125;</span><br><span class=\"line\">\t\t\tnetwork.Name = is[i].Name</span><br><span class=\"line\">\t\t\tnetwork.MACAddress = is[i].MacAddress</span><br><span class=\"line\">\t\t\tif len(is[i].Ipv4) &gt; 0 &#123;</span><br><span class=\"line\">\t\t\t\tnetwork.IP = is[i].Ipv4[0]</span><br><span class=\"line\">\t\t\t&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">\t\t\tfmt.Printf(&quot;network:=&quot;,network)</span><br><span class=\"line\">\t\t&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">\treturn nil</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"磁盘\"><a href=\"#磁盘\" class=\"headerlink\" title=\"磁盘\"></a>磁盘</h2><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">import (</span><br><span class=\"line\">\t&quot;github.com/StackExchange/wmi&quot;</span><br><span class=\"line\">\t&quot;fmt&quot;</span><br><span class=\"line\">)</span><br><span class=\"line\"></span><br><span class=\"line\">type Storage struct &#123;</span><br><span class=\"line\">\tName       string</span><br><span class=\"line\">\tFileSystem string</span><br><span class=\"line\">\tTotal      uint64</span><br><span class=\"line\">\tFree       uint64</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">type storageInfo struct &#123;</span><br><span class=\"line\">\tName       string</span><br><span class=\"line\">\tSize       uint64</span><br><span class=\"line\">\tFreeSpace  uint64</span><br><span class=\"line\">\tFileSystem string</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">func getStorageInfo() &#123;</span><br><span class=\"line\">\tvar storageinfo []storageInfo</span><br><span class=\"line\">\tvar loaclStorages []Storage</span><br><span class=\"line\">\terr := wmi.Query(&quot;Select * from Win32_LogicalDisk&quot;, &amp;storageinfo)</span><br><span class=\"line\">\tif err != nil &#123;</span><br><span class=\"line\">\t\treturn</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">\tfor _, storage := range storageinfo &#123;</span><br><span class=\"line\">\t\tinfo := Storage&#123;</span><br><span class=\"line\">\t\t\tName:       storage.Name,</span><br><span class=\"line\">\t\t\tFileSystem: storage.FileSystem,</span><br><span class=\"line\">\t\t\tTotal:      storage.Size,</span><br><span class=\"line\">\t\t\tFree:       storage.FreeSpace,</span><br><span class=\"line\">\t\t&#125;</span><br><span class=\"line\">\t\tlocalStorages = append(loaclStorages, info)</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">\tfmt.Printf(&quot;localStorages:=&quot;,localStorages)</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>此处使用的也是wmi库，关于磁盘空间的更多参数，请参考<a href=\"https://msdn.microsoft.com/en-us/library/aa394173%28v=vs.85%29.aspx\" target=\"_blank\" rel=\"noopener\">这里</a></p>\n<h2 id=\"GPU\"><a href=\"#GPU\" class=\"headerlink\" title=\"GPU\"></a>GPU</h2><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">import (</span><br><span class=\"line\">\t&quot;github.com/StackExchange/wmi&quot;</span><br><span class=\"line\">\t&quot;fmt&quot;</span><br><span class=\"line\">)</span><br><span class=\"line\"></span><br><span class=\"line\">type gpuInfo struct &#123;</span><br><span class=\"line\">\tName string</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">func getGPUInfo() &#123;</span><br><span class=\"line\"></span><br><span class=\"line\">\tvar gpuinfo []gpuInfo</span><br><span class=\"line\">\terr := wmi.Query(&quot;Select * from Win32_VideoController&quot;, &amp;gpuinfo)</span><br><span class=\"line\">\tif err != nil &#123;</span><br><span class=\"line\">\t\treturn</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">\tfmt.Printf(&quot;GPU:=&quot;,gpuinfo[0].Name)</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>此处使用的也是wmi库，更多关于GPU的参数请参考Windows官方提供的<a href=\"https://msdn.microsoft.com/en-us/library/aa394512%28v=vs.85%29.aspx\" target=\"_blank\" rel=\"noopener\">文档</a></p>\n<h3 id=\"希望对大家有所帮助吧，包括关于主板的信息等等，大家都可以通过wmi这个库，参考Windows给出的官方文档，使用WQL语句进行查找\"><a href=\"#希望对大家有所帮助吧，包括关于主板的信息等等，大家都可以通过wmi这个库，参考Windows给出的官方文档，使用WQL语句进行查找\" class=\"headerlink\" title=\"希望对大家有所帮助吧，包括关于主板的信息等等，大家都可以通过wmi这个库，参考Windows给出的官方文档，使用WQL语句进行查找\"></a>希望对大家有所帮助吧，包括关于主板的信息等等，大家都可以通过wmi这个库，参考Windows给出的官方文档，使用WQL语句进行查找</h3><hr>"},{"title":"ansible中配置ssh","_content":"\n## 使用ansible时关于ssh的配置和使用\n   ansible是基于SSH开发的一款用于远程（批量）地管理服务器资源的工具，这就表示其无需安装客户端，在一台全新的服务器上线之后（只要其有sshd服务在运行）就可以直接加入被管理的集群了。\n\n  关于ansible的配置在/etc/ansible/ansible.cfg文件中，所以关于ansible运行时所使用的ssh配置也可以在此文件中配置。在目前的ansible中，运行ansible时会依次加载 环境变量ANSIBLE_CONFIG，当前目录的ansible.cfg，~/.ansible.cfg，/etc/ansible/ansible.cfg，针对同一个配置项以最先加载到的为准。所以，我们可以单独编写自己的ansible.cfg文件放在当前目录下。\n\n<!--more-->\n\n在使用过程中我遇到了两个问题。一、在调用ansible-playbook 指令时如何很快检验所管理的主机节点ssh连接是否正常？二、当在执行过程如果某个主机节点ssh连接断开时，如何很快获取异常并中断playbook的执行？\n## 在调用ansible-playbook 指令时如何很快检验所管理的主机节点ssh连接是否正常？\n 通过ansible-playbook我们可以看到--timeout可以设置ssh连接的超时时间，默认是10s。我们可以通过设置改参数灵活判断目标主机节点ssh连接是否已经断开。\n ![在这里插入图片描述](https://img-blog.csdnimg.cn/2019100914182765.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0N1aV9DdWlfNjY2,size_16,color_FFFFFF,t_70)\n\n## 当在执行过程如果某个主机节点ssh连接断开时，如何很快获取异常并中断playbook的执行？\n我们开始已经提到，通过ansible.cfg文件我们可以配置有关ssh的一些参数。![在这里插入图片描述](https://img-blog.csdnimg.cn/20191009143037904.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0N1aV9DdWlfNjY2,size_16,color_FFFFFF,t_70)\n\nssh_args就是配置有关ssh连接的参数。默认情况下，playbook运行过程中某节点ssh连接断开后，要过很长一段时间ansible才会返回错误，期间一直hold在那，严重影响运行效率。\n\n```\nssh_args = -o ControlMaster=auto -o ControlPersist=600s -o ServerAliveInterval=30 -o ServerAliveCountMax=2\n```\n我们可以通过设置ssh的心跳时间间隔和超时次数解决此问题。\n\n","source":"_posts/Ansible-playbook 关于ssh的配置和使用.md","raw":"---\ntitle: ansible中配置ssh\ncategories: Ansible\n---\n\n## 使用ansible时关于ssh的配置和使用\n   ansible是基于SSH开发的一款用于远程（批量）地管理服务器资源的工具，这就表示其无需安装客户端，在一台全新的服务器上线之后（只要其有sshd服务在运行）就可以直接加入被管理的集群了。\n\n  关于ansible的配置在/etc/ansible/ansible.cfg文件中，所以关于ansible运行时所使用的ssh配置也可以在此文件中配置。在目前的ansible中，运行ansible时会依次加载 环境变量ANSIBLE_CONFIG，当前目录的ansible.cfg，~/.ansible.cfg，/etc/ansible/ansible.cfg，针对同一个配置项以最先加载到的为准。所以，我们可以单独编写自己的ansible.cfg文件放在当前目录下。\n\n<!--more-->\n\n在使用过程中我遇到了两个问题。一、在调用ansible-playbook 指令时如何很快检验所管理的主机节点ssh连接是否正常？二、当在执行过程如果某个主机节点ssh连接断开时，如何很快获取异常并中断playbook的执行？\n## 在调用ansible-playbook 指令时如何很快检验所管理的主机节点ssh连接是否正常？\n 通过ansible-playbook我们可以看到--timeout可以设置ssh连接的超时时间，默认是10s。我们可以通过设置改参数灵活判断目标主机节点ssh连接是否已经断开。\n ![在这里插入图片描述](https://img-blog.csdnimg.cn/2019100914182765.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0N1aV9DdWlfNjY2,size_16,color_FFFFFF,t_70)\n\n## 当在执行过程如果某个主机节点ssh连接断开时，如何很快获取异常并中断playbook的执行？\n我们开始已经提到，通过ansible.cfg文件我们可以配置有关ssh的一些参数。![在这里插入图片描述](https://img-blog.csdnimg.cn/20191009143037904.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0N1aV9DdWlfNjY2,size_16,color_FFFFFF,t_70)\n\nssh_args就是配置有关ssh连接的参数。默认情况下，playbook运行过程中某节点ssh连接断开后，要过很长一段时间ansible才会返回错误，期间一直hold在那，严重影响运行效率。\n\n```\nssh_args = -o ControlMaster=auto -o ControlPersist=600s -o ServerAliveInterval=30 -o ServerAliveCountMax=2\n```\n我们可以通过设置ssh的心跳时间间隔和超时次数解决此问题。\n\n","slug":"Ansible-playbook 关于ssh的配置和使用","published":1,"date":"2020-04-05T03:06:43.062Z","updated":"2020-04-05T03:06:43.062Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck8x0luv600022otvo347yzg8","content":"<h2 id=\"使用ansible时关于ssh的配置和使用\"><a href=\"#使用ansible时关于ssh的配置和使用\" class=\"headerlink\" title=\"使用ansible时关于ssh的配置和使用\"></a>使用ansible时关于ssh的配置和使用</h2><p>   ansible是基于SSH开发的一款用于远程（批量）地管理服务器资源的工具，这就表示其无需安装客户端，在一台全新的服务器上线之后（只要其有sshd服务在运行）就可以直接加入被管理的集群了。</p>\n<p>  关于ansible的配置在/etc/ansible/ansible.cfg文件中，所以关于ansible运行时所使用的ssh配置也可以在此文件中配置。在目前的ansible中，运行ansible时会依次加载 环境变量ANSIBLE_CONFIG，当前目录的ansible.cfg，~/.ansible.cfg，/etc/ansible/ansible.cfg，针对同一个配置项以最先加载到的为准。所以，我们可以单独编写自己的ansible.cfg文件放在当前目录下。</p>\n<a id=\"more\"></a>\n\n<p>在使用过程中我遇到了两个问题。一、在调用ansible-playbook 指令时如何很快检验所管理的主机节点ssh连接是否正常？二、当在执行过程如果某个主机节点ssh连接断开时，如何很快获取异常并中断playbook的执行？</p>\n<h2 id=\"在调用ansible-playbook-指令时如何很快检验所管理的主机节点ssh连接是否正常？\"><a href=\"#在调用ansible-playbook-指令时如何很快检验所管理的主机节点ssh连接是否正常？\" class=\"headerlink\" title=\"在调用ansible-playbook 指令时如何很快检验所管理的主机节点ssh连接是否正常？\"></a>在调用ansible-playbook 指令时如何很快检验所管理的主机节点ssh连接是否正常？</h2><p> 通过ansible-playbook我们可以看到–timeout可以设置ssh连接的超时时间，默认是10s。我们可以通过设置改参数灵活判断目标主机节点ssh连接是否已经断开。<br> <img src=\"https://img-blog.csdnimg.cn/2019100914182765.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0N1aV9DdWlfNjY2,size_16,color_FFFFFF,t_70\" alt=\"在这里插入图片描述\"></p>\n<h2 id=\"当在执行过程如果某个主机节点ssh连接断开时，如何很快获取异常并中断playbook的执行？\"><a href=\"#当在执行过程如果某个主机节点ssh连接断开时，如何很快获取异常并中断playbook的执行？\" class=\"headerlink\" title=\"当在执行过程如果某个主机节点ssh连接断开时，如何很快获取异常并中断playbook的执行？\"></a>当在执行过程如果某个主机节点ssh连接断开时，如何很快获取异常并中断playbook的执行？</h2><p>我们开始已经提到，通过ansible.cfg文件我们可以配置有关ssh的一些参数。<img src=\"https://img-blog.csdnimg.cn/20191009143037904.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0N1aV9DdWlfNjY2,size_16,color_FFFFFF,t_70\" alt=\"在这里插入图片描述\"></p>\n<p>ssh_args就是配置有关ssh连接的参数。默认情况下，playbook运行过程中某节点ssh连接断开后，要过很长一段时间ansible才会返回错误，期间一直hold在那，严重影响运行效率。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">ssh_args = -o ControlMaster=auto -o ControlPersist=600s -o ServerAliveInterval=30 -o ServerAliveCountMax=2</span><br></pre></td></tr></table></figure>\n\n<p>我们可以通过设置ssh的心跳时间间隔和超时次数解决此问题。</p>\n","site":{"data":{}},"excerpt":"<h2 id=\"使用ansible时关于ssh的配置和使用\"><a href=\"#使用ansible时关于ssh的配置和使用\" class=\"headerlink\" title=\"使用ansible时关于ssh的配置和使用\"></a>使用ansible时关于ssh的配置和使用</h2><p>   ansible是基于SSH开发的一款用于远程（批量）地管理服务器资源的工具，这就表示其无需安装客户端，在一台全新的服务器上线之后（只要其有sshd服务在运行）就可以直接加入被管理的集群了。</p>\n<p>  关于ansible的配置在/etc/ansible/ansible.cfg文件中，所以关于ansible运行时所使用的ssh配置也可以在此文件中配置。在目前的ansible中，运行ansible时会依次加载 环境变量ANSIBLE_CONFIG，当前目录的ansible.cfg，~/.ansible.cfg，/etc/ansible/ansible.cfg，针对同一个配置项以最先加载到的为准。所以，我们可以单独编写自己的ansible.cfg文件放在当前目录下。</p>","more":"<p>在使用过程中我遇到了两个问题。一、在调用ansible-playbook 指令时如何很快检验所管理的主机节点ssh连接是否正常？二、当在执行过程如果某个主机节点ssh连接断开时，如何很快获取异常并中断playbook的执行？</p>\n<h2 id=\"在调用ansible-playbook-指令时如何很快检验所管理的主机节点ssh连接是否正常？\"><a href=\"#在调用ansible-playbook-指令时如何很快检验所管理的主机节点ssh连接是否正常？\" class=\"headerlink\" title=\"在调用ansible-playbook 指令时如何很快检验所管理的主机节点ssh连接是否正常？\"></a>在调用ansible-playbook 指令时如何很快检验所管理的主机节点ssh连接是否正常？</h2><p> 通过ansible-playbook我们可以看到–timeout可以设置ssh连接的超时时间，默认是10s。我们可以通过设置改参数灵活判断目标主机节点ssh连接是否已经断开。<br> <img src=\"https://img-blog.csdnimg.cn/2019100914182765.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0N1aV9DdWlfNjY2,size_16,color_FFFFFF,t_70\" alt=\"在这里插入图片描述\"></p>\n<h2 id=\"当在执行过程如果某个主机节点ssh连接断开时，如何很快获取异常并中断playbook的执行？\"><a href=\"#当在执行过程如果某个主机节点ssh连接断开时，如何很快获取异常并中断playbook的执行？\" class=\"headerlink\" title=\"当在执行过程如果某个主机节点ssh连接断开时，如何很快获取异常并中断playbook的执行？\"></a>当在执行过程如果某个主机节点ssh连接断开时，如何很快获取异常并中断playbook的执行？</h2><p>我们开始已经提到，通过ansible.cfg文件我们可以配置有关ssh的一些参数。<img src=\"https://img-blog.csdnimg.cn/20191009143037904.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0N1aV9DdWlfNjY2,size_16,color_FFFFFF,t_70\" alt=\"在这里插入图片描述\"></p>\n<p>ssh_args就是配置有关ssh连接的参数。默认情况下，playbook运行过程中某节点ssh连接断开后，要过很长一段时间ansible才会返回错误，期间一直hold在那，严重影响运行效率。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">ssh_args = -o ControlMaster=auto -o ControlPersist=600s -o ServerAliveInterval=30 -o ServerAliveCountMax=2</span><br></pre></td></tr></table></figure>\n\n<p>我们可以通过设置ssh的心跳时间间隔和超时次数解决此问题。</p>"},{"title":"Istio怎么劫持了流量","_content":"\n# Istio怎么劫持了流量\n当我们使用istio的时候，有时候会思考Istio到底是怎么劫持了k8s集群的流量呢？\n首先我们要明白k8s本身的流量是怎么流转的。举个例子，服务A通过服务B部署时注册的Service名称来填写调用地址，这个地址被翻译成一个域名，通过k8s中的私有DNS系统翻译成一个虚拟的ClusterIP，再通过部署在每一个节点上的Kube-proxy服务负载给Service对应的Pod。那使用Istio的部署会对k8s\n原有的服务网格结构造成哪些影响呢？\n# Sidecar\nSidecar是与应用一起部署的，它代理一切出入应用的请求，并将其转发到正确的目的地。这样一来，复杂的分布式调用网络本身就对应用透明了。也许会有人对单独部署一个Sidecar进程的稳定性产生疑问，Sidecar的独特之处就在于每个应用本身都独立部署了一套进程，即使出问题也只影响一个或几个服务。\n## Sidecar的注入方式\nSidecar的部署支持自动注入与手动配置两种方式，手动注入需要对部署的yaml文件进行简单的修改即可。\n\n```bash\nistioctl kube-inject -f book-info.yml | kubectl apply -f -\n```\n自动注入目前需要k8s配合使用，只需将应用对应的Namespace设置一个label即可\n\n```bash\nkubectl label namespace default istio-injection=enabled\n```\n这样一来，服务一旦启动，Sidecar就会使用Kubernetes的Mutating Webhook Admission Controller扩展自动注入。\n那么，Mutating Webhook Admission Controller是怎么自动注入的呢？为什么配置了自动注入的namespace就会在创建pod的时候创建Sidecar容器呢？\n# 动态准入控制\nAdmission webhook是一种用于接收准入请求并对其进行处理的HTTP回调机制。可以定义两种类型的admission webhook，即 validating admission webhook 和 mutating admission webhook。 Mutating admission webhook 会先被调用。**它们可以更改发送到 API 服务器的对象以执行自定义的设置默认值操作**。在完成了所有对象修改并且 API 服务器也验证了所传入的对象之后，validating admission webhook 会被调用，并通过拒绝请求的方式来强制实施自定义的策略。这样，就回答了为什么配置自动注入后创建的pod就能自动创建Sidecar容器。\n那么，Istio中的mutating admission webhook是怎么定义的呢？其实，要想使用admission webhook首先要定义 ValidatingWebhookConfiguration 或者 MutatingWebhookConfiguration 动态配置哪些资源要被哪些 admission webhook 处理。Istio中定义的MutatingWebhookConfiguration如下：\n\n```yaml\n# Source: istio/charts/sidecarInjectorWebhook/templates/mutatingwebhook.yaml\n\napiVersion: admissionregistration.k8s.io/v1beta1\nkind: MutatingWebhookConfiguration\nmetadata:\n  name: istio-sidecar-injector\n  labels:\n    app: sidecarInjectorWebhook\n    chart: sidecarInjectorWebhook\n    heritage: Tiller\n    release: istio\nwebhooks:\n  - name: sidecar-injector.istio.io\n    clientConfig:\n      service:\n        name: istio-sidecar-injector\n        namespace: istio-system\n        path: \"/inject\"\n      caBundle: \"\"\n    rules:\n      - operations: [ \"CREATE\" ]\n        apiGroups: [\"\"]\n        apiVersions: [\"v1\"]\n        resources: [\"pods\"]\n    failurePolicy: Fail\n    namespaceSelector:\n      matchLabels:\n        istio-injection: enabled\n```\n创建一个 service 作为 webhook 服务器的前端，这里就是istio-sidecar-injector service。这个MutatingWebhookConfiguration很清晰，就是匹配带有istio-injection标签的namespace中的 CREATE POD 请求，匹配到之后按照clientConfig中制定的方向发送请求给istio-sidecar-injector service。\nistio-sidecar-injector指定的是一个deployment，内容如下：\n\n```yaml\n# Source: istio/charts/sidecarInjectorWebhook/templates/deployment.yaml\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: istio-sidecar-injector\n  namespace: istio-system\n  labels:\n    app: sidecarInjectorWebhook\n    chart: sidecarInjectorWebhook\n    heritage: Tiller\n    release: istio\n    istio: sidecar-injector\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      istio: sidecar-injector\n  strategy:\n    rollingUpdate:\n      maxSurge: 100%\n      maxUnavailable: 25%\n  template:\n    metadata:\n      labels:\n        app: sidecarInjectorWebhook\n        chart: sidecarInjectorWebhook\n        heritage: Tiller\n        release: istio\n        istio: sidecar-injector\n      annotations:\n        sidecar.istio.io/inject: \"false\"\n    spec:\n      serviceAccountName: istio-sidecar-injector-service-account\n      containers:\n        - name: sidecar-injector-webhook\n          image: \"docker.io/istio/sidecar_injector:1.5.1\"\n          imagePullPolicy: IfNotPresent\n          args:\n            - --caCertFile=/etc/istio/certs/root-cert.pem\n            - --tlsCertFile=/etc/istio/certs/cert-chain.pem\n            - --tlsKeyFile=/etc/istio/certs/key.pem\n            - --injectConfig=/etc/istio/inject/config\n            - --meshConfig=/etc/istio/config/mesh\n            - --healthCheckInterval=2s\n            - --healthCheckFile=/tmp/health\n            - --reconcileWebhookConfig=true\n          volumeMounts:\n          - name: config-volume\n            mountPath: /etc/istio/config\n            readOnly: true\n          - name: certs\n            mountPath: /etc/istio/certs\n            readOnly: true\n          - name: inject-config\n            mountPath: /etc/istio/inject\n            readOnly: true\n          livenessProbe:\n            exec:\n              command:\n                - /usr/local/bin/sidecar-injector\n                - probe\n                - --probe-path=/tmp/health\n                - --interval=4s\n            initialDelaySeconds: 4\n            periodSeconds: 4\n          readinessProbe:\n            exec:\n              command:\n                - /usr/local/bin/sidecar-injector\n                - probe\n                - --probe-path=/tmp/health\n                - --interval=4s\n            initialDelaySeconds: 4\n            periodSeconds: 4\n          resources:\n            requests:\n              cpu: 10m\n            \n      volumes:\n      - name: config-volume\n        configMap:\n          name: istio\n      - name: certs\n        secret:\n          secretName: istio.istio-sidecar-injector-service-account\n      - name: inject-config\n        configMap:\n          name: istio-sidecar-injector\n          items:\n          - key: config\n            path: config\n          - key: values\n            path: values\n      affinity:      \n        nodeAffinity:\n          requiredDuringSchedulingIgnoredDuringExecution:\n            nodeSelectorTerms:\n            - matchExpressions:\n              - key: beta.kubernetes.io/arch\n                operator: In\n                values:\n                - \"amd64\"\n                - \"ppc64le\"\n                - \"s390x\"\n          preferredDuringSchedulingIgnoredDuringExecution:\n          - weight: 2\n            preference:\n              matchExpressions:\n              - key: beta.kubernetes.io/arch\n                operator: In\n                values:\n                - \"amd64\"\n          - weight: 2\n            preference:\n              matchExpressions:\n              - key: beta.kubernetes.io/arch\n                operator: In\n                values:\n                - \"ppc64le\"\n          - weight: 2\n            preference:\n              matchExpressions:\n              - key: beta.kubernetes.io/arch\n                operator: In\n                values:\n                - \"s390x\"   \n```\n这个Pod主要做的事我们通过现象来分析。\n# Pod中的三个容器\n我们通过istio官方的demo我们可以发现，开启了自动注入后创建的review Pod中有三个容器，分别是：\n\n - k8s_reviews_revierws-v3\n - k8s_istio_proxy_reviews-v3\n - k8s_POD_reviews\n通过分析，第一个就是应用本身，第三个是kubernetes的pause容器，第二个容器就是istio系统中的Sidecar，并且进入容器我们也能看到里边运行的就是Envoy。这个容器是和Pod一一对应的，**所以Sidecar是部署在Pod这个层级的**，这一点很重要。\n## Sidecar是如何劫持流量的呢\n我们发现了istio会给我们的每个Pod创建一个Sidecar容器，那么他是如何劫持流量的呢？\n我们进入到这个容器后，执行ifconfig会惊奇发现，应用容器使用的IP地址与istio-proxy竟然是一样的。这说明应用容器与istio-proxy两个容器共享了网络。也就是说，istio在pod启动的时候使用自己的特殊pause容器istio-proxy替换掉了Kubernetes官方的pause，使得应用与istio-proxy处于同一个网络栈下。那最后的问题就是istio如何将应用的进出流量都重新定向到istio-proxy容器监听的端口。为了搞明白这个问题，我们可以手动注入Sidecar，来对比yaml文件的变化。主要变化是init container中多了一个proxy_init容器，查看它的Dockerfile文件可以发现，这个容器主要就是运行了一个脚本：\n\n```powershell\nFROM ubuntu:xenial\nRUN apt-get update && apt-get install -y \\\n    iproute2 \\\n    iptables \\\n && rm -rf /var/lib/apt/lists/*\nADD istio-iptables.sh /usr/local/bin/\nENTRYPOINT [\"/usr/local/bin/istio-iptables.sh\"]\n```\n该脚本源码就不具体分析了，不过也能猜出大概。istio正是通过iptables以及iproute2这个工具对Linux网络流量配置了过滤规则来实现Sidecar的流量劫持，其执行的脚本正是istio-iptables这个脚本文件。\n\n","source":"_posts/Istio怎么劫持了流量.md","raw":"---\ntitle: Istio怎么劫持了流量\ncategories: Kubernetes\n---\n\n# Istio怎么劫持了流量\n当我们使用istio的时候，有时候会思考Istio到底是怎么劫持了k8s集群的流量呢？\n首先我们要明白k8s本身的流量是怎么流转的。举个例子，服务A通过服务B部署时注册的Service名称来填写调用地址，这个地址被翻译成一个域名，通过k8s中的私有DNS系统翻译成一个虚拟的ClusterIP，再通过部署在每一个节点上的Kube-proxy服务负载给Service对应的Pod。那使用Istio的部署会对k8s\n原有的服务网格结构造成哪些影响呢？\n# Sidecar\nSidecar是与应用一起部署的，它代理一切出入应用的请求，并将其转发到正确的目的地。这样一来，复杂的分布式调用网络本身就对应用透明了。也许会有人对单独部署一个Sidecar进程的稳定性产生疑问，Sidecar的独特之处就在于每个应用本身都独立部署了一套进程，即使出问题也只影响一个或几个服务。\n## Sidecar的注入方式\nSidecar的部署支持自动注入与手动配置两种方式，手动注入需要对部署的yaml文件进行简单的修改即可。\n\n```bash\nistioctl kube-inject -f book-info.yml | kubectl apply -f -\n```\n自动注入目前需要k8s配合使用，只需将应用对应的Namespace设置一个label即可\n\n```bash\nkubectl label namespace default istio-injection=enabled\n```\n这样一来，服务一旦启动，Sidecar就会使用Kubernetes的Mutating Webhook Admission Controller扩展自动注入。\n那么，Mutating Webhook Admission Controller是怎么自动注入的呢？为什么配置了自动注入的namespace就会在创建pod的时候创建Sidecar容器呢？\n# 动态准入控制\nAdmission webhook是一种用于接收准入请求并对其进行处理的HTTP回调机制。可以定义两种类型的admission webhook，即 validating admission webhook 和 mutating admission webhook。 Mutating admission webhook 会先被调用。**它们可以更改发送到 API 服务器的对象以执行自定义的设置默认值操作**。在完成了所有对象修改并且 API 服务器也验证了所传入的对象之后，validating admission webhook 会被调用，并通过拒绝请求的方式来强制实施自定义的策略。这样，就回答了为什么配置自动注入后创建的pod就能自动创建Sidecar容器。\n那么，Istio中的mutating admission webhook是怎么定义的呢？其实，要想使用admission webhook首先要定义 ValidatingWebhookConfiguration 或者 MutatingWebhookConfiguration 动态配置哪些资源要被哪些 admission webhook 处理。Istio中定义的MutatingWebhookConfiguration如下：\n\n```yaml\n# Source: istio/charts/sidecarInjectorWebhook/templates/mutatingwebhook.yaml\n\napiVersion: admissionregistration.k8s.io/v1beta1\nkind: MutatingWebhookConfiguration\nmetadata:\n  name: istio-sidecar-injector\n  labels:\n    app: sidecarInjectorWebhook\n    chart: sidecarInjectorWebhook\n    heritage: Tiller\n    release: istio\nwebhooks:\n  - name: sidecar-injector.istio.io\n    clientConfig:\n      service:\n        name: istio-sidecar-injector\n        namespace: istio-system\n        path: \"/inject\"\n      caBundle: \"\"\n    rules:\n      - operations: [ \"CREATE\" ]\n        apiGroups: [\"\"]\n        apiVersions: [\"v1\"]\n        resources: [\"pods\"]\n    failurePolicy: Fail\n    namespaceSelector:\n      matchLabels:\n        istio-injection: enabled\n```\n创建一个 service 作为 webhook 服务器的前端，这里就是istio-sidecar-injector service。这个MutatingWebhookConfiguration很清晰，就是匹配带有istio-injection标签的namespace中的 CREATE POD 请求，匹配到之后按照clientConfig中制定的方向发送请求给istio-sidecar-injector service。\nistio-sidecar-injector指定的是一个deployment，内容如下：\n\n```yaml\n# Source: istio/charts/sidecarInjectorWebhook/templates/deployment.yaml\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: istio-sidecar-injector\n  namespace: istio-system\n  labels:\n    app: sidecarInjectorWebhook\n    chart: sidecarInjectorWebhook\n    heritage: Tiller\n    release: istio\n    istio: sidecar-injector\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      istio: sidecar-injector\n  strategy:\n    rollingUpdate:\n      maxSurge: 100%\n      maxUnavailable: 25%\n  template:\n    metadata:\n      labels:\n        app: sidecarInjectorWebhook\n        chart: sidecarInjectorWebhook\n        heritage: Tiller\n        release: istio\n        istio: sidecar-injector\n      annotations:\n        sidecar.istio.io/inject: \"false\"\n    spec:\n      serviceAccountName: istio-sidecar-injector-service-account\n      containers:\n        - name: sidecar-injector-webhook\n          image: \"docker.io/istio/sidecar_injector:1.5.1\"\n          imagePullPolicy: IfNotPresent\n          args:\n            - --caCertFile=/etc/istio/certs/root-cert.pem\n            - --tlsCertFile=/etc/istio/certs/cert-chain.pem\n            - --tlsKeyFile=/etc/istio/certs/key.pem\n            - --injectConfig=/etc/istio/inject/config\n            - --meshConfig=/etc/istio/config/mesh\n            - --healthCheckInterval=2s\n            - --healthCheckFile=/tmp/health\n            - --reconcileWebhookConfig=true\n          volumeMounts:\n          - name: config-volume\n            mountPath: /etc/istio/config\n            readOnly: true\n          - name: certs\n            mountPath: /etc/istio/certs\n            readOnly: true\n          - name: inject-config\n            mountPath: /etc/istio/inject\n            readOnly: true\n          livenessProbe:\n            exec:\n              command:\n                - /usr/local/bin/sidecar-injector\n                - probe\n                - --probe-path=/tmp/health\n                - --interval=4s\n            initialDelaySeconds: 4\n            periodSeconds: 4\n          readinessProbe:\n            exec:\n              command:\n                - /usr/local/bin/sidecar-injector\n                - probe\n                - --probe-path=/tmp/health\n                - --interval=4s\n            initialDelaySeconds: 4\n            periodSeconds: 4\n          resources:\n            requests:\n              cpu: 10m\n            \n      volumes:\n      - name: config-volume\n        configMap:\n          name: istio\n      - name: certs\n        secret:\n          secretName: istio.istio-sidecar-injector-service-account\n      - name: inject-config\n        configMap:\n          name: istio-sidecar-injector\n          items:\n          - key: config\n            path: config\n          - key: values\n            path: values\n      affinity:      \n        nodeAffinity:\n          requiredDuringSchedulingIgnoredDuringExecution:\n            nodeSelectorTerms:\n            - matchExpressions:\n              - key: beta.kubernetes.io/arch\n                operator: In\n                values:\n                - \"amd64\"\n                - \"ppc64le\"\n                - \"s390x\"\n          preferredDuringSchedulingIgnoredDuringExecution:\n          - weight: 2\n            preference:\n              matchExpressions:\n              - key: beta.kubernetes.io/arch\n                operator: In\n                values:\n                - \"amd64\"\n          - weight: 2\n            preference:\n              matchExpressions:\n              - key: beta.kubernetes.io/arch\n                operator: In\n                values:\n                - \"ppc64le\"\n          - weight: 2\n            preference:\n              matchExpressions:\n              - key: beta.kubernetes.io/arch\n                operator: In\n                values:\n                - \"s390x\"   \n```\n这个Pod主要做的事我们通过现象来分析。\n# Pod中的三个容器\n我们通过istio官方的demo我们可以发现，开启了自动注入后创建的review Pod中有三个容器，分别是：\n\n - k8s_reviews_revierws-v3\n - k8s_istio_proxy_reviews-v3\n - k8s_POD_reviews\n通过分析，第一个就是应用本身，第三个是kubernetes的pause容器，第二个容器就是istio系统中的Sidecar，并且进入容器我们也能看到里边运行的就是Envoy。这个容器是和Pod一一对应的，**所以Sidecar是部署在Pod这个层级的**，这一点很重要。\n## Sidecar是如何劫持流量的呢\n我们发现了istio会给我们的每个Pod创建一个Sidecar容器，那么他是如何劫持流量的呢？\n我们进入到这个容器后，执行ifconfig会惊奇发现，应用容器使用的IP地址与istio-proxy竟然是一样的。这说明应用容器与istio-proxy两个容器共享了网络。也就是说，istio在pod启动的时候使用自己的特殊pause容器istio-proxy替换掉了Kubernetes官方的pause，使得应用与istio-proxy处于同一个网络栈下。那最后的问题就是istio如何将应用的进出流量都重新定向到istio-proxy容器监听的端口。为了搞明白这个问题，我们可以手动注入Sidecar，来对比yaml文件的变化。主要变化是init container中多了一个proxy_init容器，查看它的Dockerfile文件可以发现，这个容器主要就是运行了一个脚本：\n\n```powershell\nFROM ubuntu:xenial\nRUN apt-get update && apt-get install -y \\\n    iproute2 \\\n    iptables \\\n && rm -rf /var/lib/apt/lists/*\nADD istio-iptables.sh /usr/local/bin/\nENTRYPOINT [\"/usr/local/bin/istio-iptables.sh\"]\n```\n该脚本源码就不具体分析了，不过也能猜出大概。istio正是通过iptables以及iproute2这个工具对Linux网络流量配置了过滤规则来实现Sidecar的流量劫持，其执行的脚本正是istio-iptables这个脚本文件。\n\n","slug":"Istio怎么劫持了流量","published":1,"date":"2020-04-05T10:43:51.816Z","updated":"2020-04-05T10:51:39.393Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck8x0luvb00052otvndj0q6ke","content":"<h1 id=\"Istio怎么劫持了流量\"><a href=\"#Istio怎么劫持了流量\" class=\"headerlink\" title=\"Istio怎么劫持了流量\"></a>Istio怎么劫持了流量</h1><p>当我们使用istio的时候，有时候会思考Istio到底是怎么劫持了k8s集群的流量呢？<br>首先我们要明白k8s本身的流量是怎么流转的。举个例子，服务A通过服务B部署时注册的Service名称来填写调用地址，这个地址被翻译成一个域名，通过k8s中的私有DNS系统翻译成一个虚拟的ClusterIP，再通过部署在每一个节点上的Kube-proxy服务负载给Service对应的Pod。那使用Istio的部署会对k8s<br>原有的服务网格结构造成哪些影响呢？</p>\n<h1 id=\"Sidecar\"><a href=\"#Sidecar\" class=\"headerlink\" title=\"Sidecar\"></a>Sidecar</h1><p>Sidecar是与应用一起部署的，它代理一切出入应用的请求，并将其转发到正确的目的地。这样一来，复杂的分布式调用网络本身就对应用透明了。也许会有人对单独部署一个Sidecar进程的稳定性产生疑问，Sidecar的独特之处就在于每个应用本身都独立部署了一套进程，即使出问题也只影响一个或几个服务。</p>\n<h2 id=\"Sidecar的注入方式\"><a href=\"#Sidecar的注入方式\" class=\"headerlink\" title=\"Sidecar的注入方式\"></a>Sidecar的注入方式</h2><p>Sidecar的部署支持自动注入与手动配置两种方式，手动注入需要对部署的yaml文件进行简单的修改即可。</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">istioctl kube-inject -f book-info.yml | kubectl apply -f -</span><br></pre></td></tr></table></figure>\n\n<p>自动注入目前需要k8s配合使用，只需将应用对应的Namespace设置一个label即可</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">kubectl label namespace default istio-injection=enabled</span><br></pre></td></tr></table></figure>\n\n<p>这样一来，服务一旦启动，Sidecar就会使用Kubernetes的Mutating Webhook Admission Controller扩展自动注入。<br>那么，Mutating Webhook Admission Controller是怎么自动注入的呢？为什么配置了自动注入的namespace就会在创建pod的时候创建Sidecar容器呢？</p>\n<h1 id=\"动态准入控制\"><a href=\"#动态准入控制\" class=\"headerlink\" title=\"动态准入控制\"></a>动态准入控制</h1><p>Admission webhook是一种用于接收准入请求并对其进行处理的HTTP回调机制。可以定义两种类型的admission webhook，即 validating admission webhook 和 mutating admission webhook。 Mutating admission webhook 会先被调用。<strong>它们可以更改发送到 API 服务器的对象以执行自定义的设置默认值操作</strong>。在完成了所有对象修改并且 API 服务器也验证了所传入的对象之后，validating admission webhook 会被调用，并通过拒绝请求的方式来强制实施自定义的策略。这样，就回答了为什么配置自动注入后创建的pod就能自动创建Sidecar容器。<br>那么，Istio中的mutating admission webhook是怎么定义的呢？其实，要想使用admission webhook首先要定义 ValidatingWebhookConfiguration 或者 MutatingWebhookConfiguration 动态配置哪些资源要被哪些 admission webhook 处理。Istio中定义的MutatingWebhookConfiguration如下：</p>\n<figure class=\"highlight yaml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># Source: istio/charts/sidecarInjectorWebhook/templates/mutatingwebhook.yaml</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"attr\">apiVersion:</span> <span class=\"string\">admissionregistration.k8s.io/v1beta1</span></span><br><span class=\"line\"><span class=\"attr\">kind:</span> <span class=\"string\">MutatingWebhookConfiguration</span></span><br><span class=\"line\"><span class=\"attr\">metadata:</span></span><br><span class=\"line\"><span class=\"attr\">  name:</span> <span class=\"string\">istio-sidecar-injector</span></span><br><span class=\"line\"><span class=\"attr\">  labels:</span></span><br><span class=\"line\"><span class=\"attr\">    app:</span> <span class=\"string\">sidecarInjectorWebhook</span></span><br><span class=\"line\"><span class=\"attr\">    chart:</span> <span class=\"string\">sidecarInjectorWebhook</span></span><br><span class=\"line\"><span class=\"attr\">    heritage:</span> <span class=\"string\">Tiller</span></span><br><span class=\"line\"><span class=\"attr\">    release:</span> <span class=\"string\">istio</span></span><br><span class=\"line\"><span class=\"attr\">webhooks:</span></span><br><span class=\"line\"><span class=\"attr\">  - name:</span> <span class=\"string\">sidecar-injector.istio.io</span></span><br><span class=\"line\"><span class=\"attr\">    clientConfig:</span></span><br><span class=\"line\"><span class=\"attr\">      service:</span></span><br><span class=\"line\"><span class=\"attr\">        name:</span> <span class=\"string\">istio-sidecar-injector</span></span><br><span class=\"line\"><span class=\"attr\">        namespace:</span> <span class=\"string\">istio-system</span></span><br><span class=\"line\"><span class=\"attr\">        path:</span> <span class=\"string\">\"/inject\"</span></span><br><span class=\"line\"><span class=\"attr\">      caBundle:</span> <span class=\"string\">\"\"</span></span><br><span class=\"line\"><span class=\"attr\">    rules:</span></span><br><span class=\"line\"><span class=\"attr\">      - operations:</span> <span class=\"string\">[</span> <span class=\"string\">\"CREATE\"</span> <span class=\"string\">]</span></span><br><span class=\"line\"><span class=\"attr\">        apiGroups:</span> <span class=\"string\">[\"\"]</span></span><br><span class=\"line\"><span class=\"attr\">        apiVersions:</span> <span class=\"string\">[\"v1\"]</span></span><br><span class=\"line\"><span class=\"attr\">        resources:</span> <span class=\"string\">[\"pods\"]</span></span><br><span class=\"line\"><span class=\"attr\">    failurePolicy:</span> <span class=\"string\">Fail</span></span><br><span class=\"line\"><span class=\"attr\">    namespaceSelector:</span></span><br><span class=\"line\"><span class=\"attr\">      matchLabels:</span></span><br><span class=\"line\"><span class=\"attr\">        istio-injection:</span> <span class=\"string\">enabled</span></span><br></pre></td></tr></table></figure>\n\n<p>创建一个 service 作为 webhook 服务器的前端，这里就是istio-sidecar-injector service。这个MutatingWebhookConfiguration很清晰，就是匹配带有istio-injection标签的namespace中的 CREATE POD 请求，匹配到之后按照clientConfig中制定的方向发送请求给istio-sidecar-injector service。<br>istio-sidecar-injector指定的是一个deployment，内容如下：</p>\n<figure class=\"highlight yaml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br><span class=\"line\">78</span><br><span class=\"line\">79</span><br><span class=\"line\">80</span><br><span class=\"line\">81</span><br><span class=\"line\">82</span><br><span class=\"line\">83</span><br><span class=\"line\">84</span><br><span class=\"line\">85</span><br><span class=\"line\">86</span><br><span class=\"line\">87</span><br><span class=\"line\">88</span><br><span class=\"line\">89</span><br><span class=\"line\">90</span><br><span class=\"line\">91</span><br><span class=\"line\">92</span><br><span class=\"line\">93</span><br><span class=\"line\">94</span><br><span class=\"line\">95</span><br><span class=\"line\">96</span><br><span class=\"line\">97</span><br><span class=\"line\">98</span><br><span class=\"line\">99</span><br><span class=\"line\">100</span><br><span class=\"line\">101</span><br><span class=\"line\">102</span><br><span class=\"line\">103</span><br><span class=\"line\">104</span><br><span class=\"line\">105</span><br><span class=\"line\">106</span><br><span class=\"line\">107</span><br><span class=\"line\">108</span><br><span class=\"line\">109</span><br><span class=\"line\">110</span><br><span class=\"line\">111</span><br><span class=\"line\">112</span><br><span class=\"line\">113</span><br><span class=\"line\">114</span><br><span class=\"line\">115</span><br><span class=\"line\">116</span><br><span class=\"line\">117</span><br><span class=\"line\">118</span><br><span class=\"line\">119</span><br><span class=\"line\">120</span><br><span class=\"line\">121</span><br><span class=\"line\">122</span><br><span class=\"line\">123</span><br><span class=\"line\">124</span><br><span class=\"line\">125</span><br><span class=\"line\">126</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># Source: istio/charts/sidecarInjectorWebhook/templates/deployment.yaml</span></span><br><span class=\"line\"><span class=\"attr\">apiVersion:</span> <span class=\"string\">apps/v1</span></span><br><span class=\"line\"><span class=\"attr\">kind:</span> <span class=\"string\">Deployment</span></span><br><span class=\"line\"><span class=\"attr\">metadata:</span></span><br><span class=\"line\"><span class=\"attr\">  name:</span> <span class=\"string\">istio-sidecar-injector</span></span><br><span class=\"line\"><span class=\"attr\">  namespace:</span> <span class=\"string\">istio-system</span></span><br><span class=\"line\"><span class=\"attr\">  labels:</span></span><br><span class=\"line\"><span class=\"attr\">    app:</span> <span class=\"string\">sidecarInjectorWebhook</span></span><br><span class=\"line\"><span class=\"attr\">    chart:</span> <span class=\"string\">sidecarInjectorWebhook</span></span><br><span class=\"line\"><span class=\"attr\">    heritage:</span> <span class=\"string\">Tiller</span></span><br><span class=\"line\"><span class=\"attr\">    release:</span> <span class=\"string\">istio</span></span><br><span class=\"line\"><span class=\"attr\">    istio:</span> <span class=\"string\">sidecar-injector</span></span><br><span class=\"line\"><span class=\"attr\">spec:</span></span><br><span class=\"line\"><span class=\"attr\">  replicas:</span> <span class=\"number\">1</span></span><br><span class=\"line\"><span class=\"attr\">  selector:</span></span><br><span class=\"line\"><span class=\"attr\">    matchLabels:</span></span><br><span class=\"line\"><span class=\"attr\">      istio:</span> <span class=\"string\">sidecar-injector</span></span><br><span class=\"line\"><span class=\"attr\">  strategy:</span></span><br><span class=\"line\"><span class=\"attr\">    rollingUpdate:</span></span><br><span class=\"line\"><span class=\"attr\">      maxSurge:</span> <span class=\"number\">100</span><span class=\"string\">%</span></span><br><span class=\"line\"><span class=\"attr\">      maxUnavailable:</span> <span class=\"number\">25</span><span class=\"string\">%</span></span><br><span class=\"line\"><span class=\"attr\">  template:</span></span><br><span class=\"line\"><span class=\"attr\">    metadata:</span></span><br><span class=\"line\"><span class=\"attr\">      labels:</span></span><br><span class=\"line\"><span class=\"attr\">        app:</span> <span class=\"string\">sidecarInjectorWebhook</span></span><br><span class=\"line\"><span class=\"attr\">        chart:</span> <span class=\"string\">sidecarInjectorWebhook</span></span><br><span class=\"line\"><span class=\"attr\">        heritage:</span> <span class=\"string\">Tiller</span></span><br><span class=\"line\"><span class=\"attr\">        release:</span> <span class=\"string\">istio</span></span><br><span class=\"line\"><span class=\"attr\">        istio:</span> <span class=\"string\">sidecar-injector</span></span><br><span class=\"line\"><span class=\"attr\">      annotations:</span></span><br><span class=\"line\">        <span class=\"string\">sidecar.istio.io/inject:</span> <span class=\"string\">\"false\"</span></span><br><span class=\"line\"><span class=\"attr\">    spec:</span></span><br><span class=\"line\"><span class=\"attr\">      serviceAccountName:</span> <span class=\"string\">istio-sidecar-injector-service-account</span></span><br><span class=\"line\"><span class=\"attr\">      containers:</span></span><br><span class=\"line\"><span class=\"attr\">        - name:</span> <span class=\"string\">sidecar-injector-webhook</span></span><br><span class=\"line\"><span class=\"attr\">          image:</span> <span class=\"string\">\"docker.io/istio/sidecar_injector:1.5.1\"</span></span><br><span class=\"line\"><span class=\"attr\">          imagePullPolicy:</span> <span class=\"string\">IfNotPresent</span></span><br><span class=\"line\"><span class=\"attr\">          args:</span></span><br><span class=\"line\"><span class=\"bullet\">            -</span> <span class=\"bullet\">--caCertFile=/etc/istio/certs/root-cert.pem</span></span><br><span class=\"line\"><span class=\"bullet\">            -</span> <span class=\"bullet\">--tlsCertFile=/etc/istio/certs/cert-chain.pem</span></span><br><span class=\"line\"><span class=\"bullet\">            -</span> <span class=\"bullet\">--tlsKeyFile=/etc/istio/certs/key.pem</span></span><br><span class=\"line\"><span class=\"bullet\">            -</span> <span class=\"bullet\">--injectConfig=/etc/istio/inject/config</span></span><br><span class=\"line\"><span class=\"bullet\">            -</span> <span class=\"bullet\">--meshConfig=/etc/istio/config/mesh</span></span><br><span class=\"line\"><span class=\"bullet\">            -</span> <span class=\"bullet\">--healthCheckInterval=2s</span></span><br><span class=\"line\"><span class=\"bullet\">            -</span> <span class=\"bullet\">--healthCheckFile=/tmp/health</span></span><br><span class=\"line\"><span class=\"bullet\">            -</span> <span class=\"bullet\">--reconcileWebhookConfig=true</span></span><br><span class=\"line\"><span class=\"attr\">          volumeMounts:</span></span><br><span class=\"line\"><span class=\"attr\">          - name:</span> <span class=\"string\">config-volume</span></span><br><span class=\"line\"><span class=\"attr\">            mountPath:</span> <span class=\"string\">/etc/istio/config</span></span><br><span class=\"line\"><span class=\"attr\">            readOnly:</span> <span class=\"literal\">true</span></span><br><span class=\"line\"><span class=\"attr\">          - name:</span> <span class=\"string\">certs</span></span><br><span class=\"line\"><span class=\"attr\">            mountPath:</span> <span class=\"string\">/etc/istio/certs</span></span><br><span class=\"line\"><span class=\"attr\">            readOnly:</span> <span class=\"literal\">true</span></span><br><span class=\"line\"><span class=\"attr\">          - name:</span> <span class=\"string\">inject-config</span></span><br><span class=\"line\"><span class=\"attr\">            mountPath:</span> <span class=\"string\">/etc/istio/inject</span></span><br><span class=\"line\"><span class=\"attr\">            readOnly:</span> <span class=\"literal\">true</span></span><br><span class=\"line\"><span class=\"attr\">          livenessProbe:</span></span><br><span class=\"line\"><span class=\"attr\">            exec:</span></span><br><span class=\"line\"><span class=\"attr\">              command:</span></span><br><span class=\"line\"><span class=\"bullet\">                -</span> <span class=\"string\">/usr/local/bin/sidecar-injector</span></span><br><span class=\"line\"><span class=\"bullet\">                -</span> <span class=\"string\">probe</span></span><br><span class=\"line\"><span class=\"bullet\">                -</span> <span class=\"bullet\">--probe-path=/tmp/health</span></span><br><span class=\"line\"><span class=\"bullet\">                -</span> <span class=\"bullet\">--interval=4s</span></span><br><span class=\"line\"><span class=\"attr\">            initialDelaySeconds:</span> <span class=\"number\">4</span></span><br><span class=\"line\"><span class=\"attr\">            periodSeconds:</span> <span class=\"number\">4</span></span><br><span class=\"line\"><span class=\"attr\">          readinessProbe:</span></span><br><span class=\"line\"><span class=\"attr\">            exec:</span></span><br><span class=\"line\"><span class=\"attr\">              command:</span></span><br><span class=\"line\"><span class=\"bullet\">                -</span> <span class=\"string\">/usr/local/bin/sidecar-injector</span></span><br><span class=\"line\"><span class=\"bullet\">                -</span> <span class=\"string\">probe</span></span><br><span class=\"line\"><span class=\"bullet\">                -</span> <span class=\"bullet\">--probe-path=/tmp/health</span></span><br><span class=\"line\"><span class=\"bullet\">                -</span> <span class=\"bullet\">--interval=4s</span></span><br><span class=\"line\"><span class=\"attr\">            initialDelaySeconds:</span> <span class=\"number\">4</span></span><br><span class=\"line\"><span class=\"attr\">            periodSeconds:</span> <span class=\"number\">4</span></span><br><span class=\"line\"><span class=\"attr\">          resources:</span></span><br><span class=\"line\"><span class=\"attr\">            requests:</span></span><br><span class=\"line\"><span class=\"attr\">              cpu:</span> <span class=\"number\">10</span><span class=\"string\">m</span></span><br><span class=\"line\">            </span><br><span class=\"line\"><span class=\"attr\">      volumes:</span></span><br><span class=\"line\"><span class=\"attr\">      - name:</span> <span class=\"string\">config-volume</span></span><br><span class=\"line\"><span class=\"attr\">        configMap:</span></span><br><span class=\"line\"><span class=\"attr\">          name:</span> <span class=\"string\">istio</span></span><br><span class=\"line\"><span class=\"attr\">      - name:</span> <span class=\"string\">certs</span></span><br><span class=\"line\"><span class=\"attr\">        secret:</span></span><br><span class=\"line\"><span class=\"attr\">          secretName:</span> <span class=\"string\">istio.istio-sidecar-injector-service-account</span></span><br><span class=\"line\"><span class=\"attr\">      - name:</span> <span class=\"string\">inject-config</span></span><br><span class=\"line\"><span class=\"attr\">        configMap:</span></span><br><span class=\"line\"><span class=\"attr\">          name:</span> <span class=\"string\">istio-sidecar-injector</span></span><br><span class=\"line\"><span class=\"attr\">          items:</span></span><br><span class=\"line\"><span class=\"attr\">          - key:</span> <span class=\"string\">config</span></span><br><span class=\"line\"><span class=\"attr\">            path:</span> <span class=\"string\">config</span></span><br><span class=\"line\"><span class=\"attr\">          - key:</span> <span class=\"string\">values</span></span><br><span class=\"line\"><span class=\"attr\">            path:</span> <span class=\"string\">values</span></span><br><span class=\"line\"><span class=\"attr\">      affinity:</span>      </span><br><span class=\"line\"><span class=\"attr\">        nodeAffinity:</span></span><br><span class=\"line\"><span class=\"attr\">          requiredDuringSchedulingIgnoredDuringExecution:</span></span><br><span class=\"line\"><span class=\"attr\">            nodeSelectorTerms:</span></span><br><span class=\"line\"><span class=\"attr\">            - matchExpressions:</span></span><br><span class=\"line\"><span class=\"attr\">              - key:</span> <span class=\"string\">beta.kubernetes.io/arch</span></span><br><span class=\"line\"><span class=\"attr\">                operator:</span> <span class=\"string\">In</span></span><br><span class=\"line\"><span class=\"attr\">                values:</span></span><br><span class=\"line\"><span class=\"bullet\">                -</span> <span class=\"string\">\"amd64\"</span></span><br><span class=\"line\"><span class=\"bullet\">                -</span> <span class=\"string\">\"ppc64le\"</span></span><br><span class=\"line\"><span class=\"bullet\">                -</span> <span class=\"string\">\"s390x\"</span></span><br><span class=\"line\"><span class=\"attr\">          preferredDuringSchedulingIgnoredDuringExecution:</span></span><br><span class=\"line\"><span class=\"attr\">          - weight:</span> <span class=\"number\">2</span></span><br><span class=\"line\"><span class=\"attr\">            preference:</span></span><br><span class=\"line\"><span class=\"attr\">              matchExpressions:</span></span><br><span class=\"line\"><span class=\"attr\">              - key:</span> <span class=\"string\">beta.kubernetes.io/arch</span></span><br><span class=\"line\"><span class=\"attr\">                operator:</span> <span class=\"string\">In</span></span><br><span class=\"line\"><span class=\"attr\">                values:</span></span><br><span class=\"line\"><span class=\"bullet\">                -</span> <span class=\"string\">\"amd64\"</span></span><br><span class=\"line\"><span class=\"attr\">          - weight:</span> <span class=\"number\">2</span></span><br><span class=\"line\"><span class=\"attr\">            preference:</span></span><br><span class=\"line\"><span class=\"attr\">              matchExpressions:</span></span><br><span class=\"line\"><span class=\"attr\">              - key:</span> <span class=\"string\">beta.kubernetes.io/arch</span></span><br><span class=\"line\"><span class=\"attr\">                operator:</span> <span class=\"string\">In</span></span><br><span class=\"line\"><span class=\"attr\">                values:</span></span><br><span class=\"line\"><span class=\"bullet\">                -</span> <span class=\"string\">\"ppc64le\"</span></span><br><span class=\"line\"><span class=\"attr\">          - weight:</span> <span class=\"number\">2</span></span><br><span class=\"line\"><span class=\"attr\">            preference:</span></span><br><span class=\"line\"><span class=\"attr\">              matchExpressions:</span></span><br><span class=\"line\"><span class=\"attr\">              - key:</span> <span class=\"string\">beta.kubernetes.io/arch</span></span><br><span class=\"line\"><span class=\"attr\">                operator:</span> <span class=\"string\">In</span></span><br><span class=\"line\"><span class=\"attr\">                values:</span></span><br><span class=\"line\"><span class=\"bullet\">                -</span> <span class=\"string\">\"s390x\"</span></span><br></pre></td></tr></table></figure>\n\n<p>这个Pod主要做的事我们通过现象来分析。</p>\n<h1 id=\"Pod中的三个容器\"><a href=\"#Pod中的三个容器\" class=\"headerlink\" title=\"Pod中的三个容器\"></a>Pod中的三个容器</h1><p>我们通过istio官方的demo我们可以发现，开启了自动注入后创建的review Pod中有三个容器，分别是：</p>\n<ul>\n<li>k8s_reviews_revierws-v3</li>\n<li>k8s_istio_proxy_reviews-v3</li>\n<li>k8s_POD_reviews<br>通过分析，第一个就是应用本身，第三个是kubernetes的pause容器，第二个容器就是istio系统中的Sidecar，并且进入容器我们也能看到里边运行的就是Envoy。这个容器是和Pod一一对应的，<strong>所以Sidecar是部署在Pod这个层级的</strong>，这一点很重要。<h2 id=\"Sidecar是如何劫持流量的呢\"><a href=\"#Sidecar是如何劫持流量的呢\" class=\"headerlink\" title=\"Sidecar是如何劫持流量的呢\"></a>Sidecar是如何劫持流量的呢</h2>我们发现了istio会给我们的每个Pod创建一个Sidecar容器，那么他是如何劫持流量的呢？<br>我们进入到这个容器后，执行ifconfig会惊奇发现，应用容器使用的IP地址与istio-proxy竟然是一样的。这说明应用容器与istio-proxy两个容器共享了网络。也就是说，istio在pod启动的时候使用自己的特殊pause容器istio-proxy替换掉了Kubernetes官方的pause，使得应用与istio-proxy处于同一个网络栈下。那最后的问题就是istio如何将应用的进出流量都重新定向到istio-proxy容器监听的端口。为了搞明白这个问题，我们可以手动注入Sidecar，来对比yaml文件的变化。主要变化是init container中多了一个proxy_init容器，查看它的Dockerfile文件可以发现，这个容器主要就是运行了一个脚本：</li>\n</ul>\n<figure class=\"highlight powershell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">FROM ubuntu:xenial</span><br><span class=\"line\">RUN apt-get update &amp;&amp; apt-get install -y \\</span><br><span class=\"line\">    iproute2 \\</span><br><span class=\"line\">    iptables \\</span><br><span class=\"line\"> &amp;&amp; rm -rf /var/lib/apt/lists/*</span><br><span class=\"line\">ADD istio-iptables.sh /usr/local/bin/</span><br><span class=\"line\">ENTRYPOINT [<span class=\"string\">\"/usr/local/bin/istio-iptables.sh\"</span>]</span><br></pre></td></tr></table></figure>\n\n<p>该脚本源码就不具体分析了，不过也能猜出大概。istio正是通过iptables以及iproute2这个工具对Linux网络流量配置了过滤规则来实现Sidecar的流量劫持，其执行的脚本正是istio-iptables这个脚本文件。</p>\n","site":{"data":{}},"excerpt":"","more":"<h1 id=\"Istio怎么劫持了流量\"><a href=\"#Istio怎么劫持了流量\" class=\"headerlink\" title=\"Istio怎么劫持了流量\"></a>Istio怎么劫持了流量</h1><p>当我们使用istio的时候，有时候会思考Istio到底是怎么劫持了k8s集群的流量呢？<br>首先我们要明白k8s本身的流量是怎么流转的。举个例子，服务A通过服务B部署时注册的Service名称来填写调用地址，这个地址被翻译成一个域名，通过k8s中的私有DNS系统翻译成一个虚拟的ClusterIP，再通过部署在每一个节点上的Kube-proxy服务负载给Service对应的Pod。那使用Istio的部署会对k8s<br>原有的服务网格结构造成哪些影响呢？</p>\n<h1 id=\"Sidecar\"><a href=\"#Sidecar\" class=\"headerlink\" title=\"Sidecar\"></a>Sidecar</h1><p>Sidecar是与应用一起部署的，它代理一切出入应用的请求，并将其转发到正确的目的地。这样一来，复杂的分布式调用网络本身就对应用透明了。也许会有人对单独部署一个Sidecar进程的稳定性产生疑问，Sidecar的独特之处就在于每个应用本身都独立部署了一套进程，即使出问题也只影响一个或几个服务。</p>\n<h2 id=\"Sidecar的注入方式\"><a href=\"#Sidecar的注入方式\" class=\"headerlink\" title=\"Sidecar的注入方式\"></a>Sidecar的注入方式</h2><p>Sidecar的部署支持自动注入与手动配置两种方式，手动注入需要对部署的yaml文件进行简单的修改即可。</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">istioctl kube-inject -f book-info.yml | kubectl apply -f -</span><br></pre></td></tr></table></figure>\n\n<p>自动注入目前需要k8s配合使用，只需将应用对应的Namespace设置一个label即可</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">kubectl label namespace default istio-injection=enabled</span><br></pre></td></tr></table></figure>\n\n<p>这样一来，服务一旦启动，Sidecar就会使用Kubernetes的Mutating Webhook Admission Controller扩展自动注入。<br>那么，Mutating Webhook Admission Controller是怎么自动注入的呢？为什么配置了自动注入的namespace就会在创建pod的时候创建Sidecar容器呢？</p>\n<h1 id=\"动态准入控制\"><a href=\"#动态准入控制\" class=\"headerlink\" title=\"动态准入控制\"></a>动态准入控制</h1><p>Admission webhook是一种用于接收准入请求并对其进行处理的HTTP回调机制。可以定义两种类型的admission webhook，即 validating admission webhook 和 mutating admission webhook。 Mutating admission webhook 会先被调用。<strong>它们可以更改发送到 API 服务器的对象以执行自定义的设置默认值操作</strong>。在完成了所有对象修改并且 API 服务器也验证了所传入的对象之后，validating admission webhook 会被调用，并通过拒绝请求的方式来强制实施自定义的策略。这样，就回答了为什么配置自动注入后创建的pod就能自动创建Sidecar容器。<br>那么，Istio中的mutating admission webhook是怎么定义的呢？其实，要想使用admission webhook首先要定义 ValidatingWebhookConfiguration 或者 MutatingWebhookConfiguration 动态配置哪些资源要被哪些 admission webhook 处理。Istio中定义的MutatingWebhookConfiguration如下：</p>\n<figure class=\"highlight yaml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># Source: istio/charts/sidecarInjectorWebhook/templates/mutatingwebhook.yaml</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"attr\">apiVersion:</span> <span class=\"string\">admissionregistration.k8s.io/v1beta1</span></span><br><span class=\"line\"><span class=\"attr\">kind:</span> <span class=\"string\">MutatingWebhookConfiguration</span></span><br><span class=\"line\"><span class=\"attr\">metadata:</span></span><br><span class=\"line\"><span class=\"attr\">  name:</span> <span class=\"string\">istio-sidecar-injector</span></span><br><span class=\"line\"><span class=\"attr\">  labels:</span></span><br><span class=\"line\"><span class=\"attr\">    app:</span> <span class=\"string\">sidecarInjectorWebhook</span></span><br><span class=\"line\"><span class=\"attr\">    chart:</span> <span class=\"string\">sidecarInjectorWebhook</span></span><br><span class=\"line\"><span class=\"attr\">    heritage:</span> <span class=\"string\">Tiller</span></span><br><span class=\"line\"><span class=\"attr\">    release:</span> <span class=\"string\">istio</span></span><br><span class=\"line\"><span class=\"attr\">webhooks:</span></span><br><span class=\"line\"><span class=\"attr\">  - name:</span> <span class=\"string\">sidecar-injector.istio.io</span></span><br><span class=\"line\"><span class=\"attr\">    clientConfig:</span></span><br><span class=\"line\"><span class=\"attr\">      service:</span></span><br><span class=\"line\"><span class=\"attr\">        name:</span> <span class=\"string\">istio-sidecar-injector</span></span><br><span class=\"line\"><span class=\"attr\">        namespace:</span> <span class=\"string\">istio-system</span></span><br><span class=\"line\"><span class=\"attr\">        path:</span> <span class=\"string\">\"/inject\"</span></span><br><span class=\"line\"><span class=\"attr\">      caBundle:</span> <span class=\"string\">\"\"</span></span><br><span class=\"line\"><span class=\"attr\">    rules:</span></span><br><span class=\"line\"><span class=\"attr\">      - operations:</span> <span class=\"string\">[</span> <span class=\"string\">\"CREATE\"</span> <span class=\"string\">]</span></span><br><span class=\"line\"><span class=\"attr\">        apiGroups:</span> <span class=\"string\">[\"\"]</span></span><br><span class=\"line\"><span class=\"attr\">        apiVersions:</span> <span class=\"string\">[\"v1\"]</span></span><br><span class=\"line\"><span class=\"attr\">        resources:</span> <span class=\"string\">[\"pods\"]</span></span><br><span class=\"line\"><span class=\"attr\">    failurePolicy:</span> <span class=\"string\">Fail</span></span><br><span class=\"line\"><span class=\"attr\">    namespaceSelector:</span></span><br><span class=\"line\"><span class=\"attr\">      matchLabels:</span></span><br><span class=\"line\"><span class=\"attr\">        istio-injection:</span> <span class=\"string\">enabled</span></span><br></pre></td></tr></table></figure>\n\n<p>创建一个 service 作为 webhook 服务器的前端，这里就是istio-sidecar-injector service。这个MutatingWebhookConfiguration很清晰，就是匹配带有istio-injection标签的namespace中的 CREATE POD 请求，匹配到之后按照clientConfig中制定的方向发送请求给istio-sidecar-injector service。<br>istio-sidecar-injector指定的是一个deployment，内容如下：</p>\n<figure class=\"highlight yaml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br><span class=\"line\">78</span><br><span class=\"line\">79</span><br><span class=\"line\">80</span><br><span class=\"line\">81</span><br><span class=\"line\">82</span><br><span class=\"line\">83</span><br><span class=\"line\">84</span><br><span class=\"line\">85</span><br><span class=\"line\">86</span><br><span class=\"line\">87</span><br><span class=\"line\">88</span><br><span class=\"line\">89</span><br><span class=\"line\">90</span><br><span class=\"line\">91</span><br><span class=\"line\">92</span><br><span class=\"line\">93</span><br><span class=\"line\">94</span><br><span class=\"line\">95</span><br><span class=\"line\">96</span><br><span class=\"line\">97</span><br><span class=\"line\">98</span><br><span class=\"line\">99</span><br><span class=\"line\">100</span><br><span class=\"line\">101</span><br><span class=\"line\">102</span><br><span class=\"line\">103</span><br><span class=\"line\">104</span><br><span class=\"line\">105</span><br><span class=\"line\">106</span><br><span class=\"line\">107</span><br><span class=\"line\">108</span><br><span class=\"line\">109</span><br><span class=\"line\">110</span><br><span class=\"line\">111</span><br><span class=\"line\">112</span><br><span class=\"line\">113</span><br><span class=\"line\">114</span><br><span class=\"line\">115</span><br><span class=\"line\">116</span><br><span class=\"line\">117</span><br><span class=\"line\">118</span><br><span class=\"line\">119</span><br><span class=\"line\">120</span><br><span class=\"line\">121</span><br><span class=\"line\">122</span><br><span class=\"line\">123</span><br><span class=\"line\">124</span><br><span class=\"line\">125</span><br><span class=\"line\">126</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># Source: istio/charts/sidecarInjectorWebhook/templates/deployment.yaml</span></span><br><span class=\"line\"><span class=\"attr\">apiVersion:</span> <span class=\"string\">apps/v1</span></span><br><span class=\"line\"><span class=\"attr\">kind:</span> <span class=\"string\">Deployment</span></span><br><span class=\"line\"><span class=\"attr\">metadata:</span></span><br><span class=\"line\"><span class=\"attr\">  name:</span> <span class=\"string\">istio-sidecar-injector</span></span><br><span class=\"line\"><span class=\"attr\">  namespace:</span> <span class=\"string\">istio-system</span></span><br><span class=\"line\"><span class=\"attr\">  labels:</span></span><br><span class=\"line\"><span class=\"attr\">    app:</span> <span class=\"string\">sidecarInjectorWebhook</span></span><br><span class=\"line\"><span class=\"attr\">    chart:</span> <span class=\"string\">sidecarInjectorWebhook</span></span><br><span class=\"line\"><span class=\"attr\">    heritage:</span> <span class=\"string\">Tiller</span></span><br><span class=\"line\"><span class=\"attr\">    release:</span> <span class=\"string\">istio</span></span><br><span class=\"line\"><span class=\"attr\">    istio:</span> <span class=\"string\">sidecar-injector</span></span><br><span class=\"line\"><span class=\"attr\">spec:</span></span><br><span class=\"line\"><span class=\"attr\">  replicas:</span> <span class=\"number\">1</span></span><br><span class=\"line\"><span class=\"attr\">  selector:</span></span><br><span class=\"line\"><span class=\"attr\">    matchLabels:</span></span><br><span class=\"line\"><span class=\"attr\">      istio:</span> <span class=\"string\">sidecar-injector</span></span><br><span class=\"line\"><span class=\"attr\">  strategy:</span></span><br><span class=\"line\"><span class=\"attr\">    rollingUpdate:</span></span><br><span class=\"line\"><span class=\"attr\">      maxSurge:</span> <span class=\"number\">100</span><span class=\"string\">%</span></span><br><span class=\"line\"><span class=\"attr\">      maxUnavailable:</span> <span class=\"number\">25</span><span class=\"string\">%</span></span><br><span class=\"line\"><span class=\"attr\">  template:</span></span><br><span class=\"line\"><span class=\"attr\">    metadata:</span></span><br><span class=\"line\"><span class=\"attr\">      labels:</span></span><br><span class=\"line\"><span class=\"attr\">        app:</span> <span class=\"string\">sidecarInjectorWebhook</span></span><br><span class=\"line\"><span class=\"attr\">        chart:</span> <span class=\"string\">sidecarInjectorWebhook</span></span><br><span class=\"line\"><span class=\"attr\">        heritage:</span> <span class=\"string\">Tiller</span></span><br><span class=\"line\"><span class=\"attr\">        release:</span> <span class=\"string\">istio</span></span><br><span class=\"line\"><span class=\"attr\">        istio:</span> <span class=\"string\">sidecar-injector</span></span><br><span class=\"line\"><span class=\"attr\">      annotations:</span></span><br><span class=\"line\">        <span class=\"string\">sidecar.istio.io/inject:</span> <span class=\"string\">\"false\"</span></span><br><span class=\"line\"><span class=\"attr\">    spec:</span></span><br><span class=\"line\"><span class=\"attr\">      serviceAccountName:</span> <span class=\"string\">istio-sidecar-injector-service-account</span></span><br><span class=\"line\"><span class=\"attr\">      containers:</span></span><br><span class=\"line\"><span class=\"attr\">        - name:</span> <span class=\"string\">sidecar-injector-webhook</span></span><br><span class=\"line\"><span class=\"attr\">          image:</span> <span class=\"string\">\"docker.io/istio/sidecar_injector:1.5.1\"</span></span><br><span class=\"line\"><span class=\"attr\">          imagePullPolicy:</span> <span class=\"string\">IfNotPresent</span></span><br><span class=\"line\"><span class=\"attr\">          args:</span></span><br><span class=\"line\"><span class=\"bullet\">            -</span> <span class=\"bullet\">--caCertFile=/etc/istio/certs/root-cert.pem</span></span><br><span class=\"line\"><span class=\"bullet\">            -</span> <span class=\"bullet\">--tlsCertFile=/etc/istio/certs/cert-chain.pem</span></span><br><span class=\"line\"><span class=\"bullet\">            -</span> <span class=\"bullet\">--tlsKeyFile=/etc/istio/certs/key.pem</span></span><br><span class=\"line\"><span class=\"bullet\">            -</span> <span class=\"bullet\">--injectConfig=/etc/istio/inject/config</span></span><br><span class=\"line\"><span class=\"bullet\">            -</span> <span class=\"bullet\">--meshConfig=/etc/istio/config/mesh</span></span><br><span class=\"line\"><span class=\"bullet\">            -</span> <span class=\"bullet\">--healthCheckInterval=2s</span></span><br><span class=\"line\"><span class=\"bullet\">            -</span> <span class=\"bullet\">--healthCheckFile=/tmp/health</span></span><br><span class=\"line\"><span class=\"bullet\">            -</span> <span class=\"bullet\">--reconcileWebhookConfig=true</span></span><br><span class=\"line\"><span class=\"attr\">          volumeMounts:</span></span><br><span class=\"line\"><span class=\"attr\">          - name:</span> <span class=\"string\">config-volume</span></span><br><span class=\"line\"><span class=\"attr\">            mountPath:</span> <span class=\"string\">/etc/istio/config</span></span><br><span class=\"line\"><span class=\"attr\">            readOnly:</span> <span class=\"literal\">true</span></span><br><span class=\"line\"><span class=\"attr\">          - name:</span> <span class=\"string\">certs</span></span><br><span class=\"line\"><span class=\"attr\">            mountPath:</span> <span class=\"string\">/etc/istio/certs</span></span><br><span class=\"line\"><span class=\"attr\">            readOnly:</span> <span class=\"literal\">true</span></span><br><span class=\"line\"><span class=\"attr\">          - name:</span> <span class=\"string\">inject-config</span></span><br><span class=\"line\"><span class=\"attr\">            mountPath:</span> <span class=\"string\">/etc/istio/inject</span></span><br><span class=\"line\"><span class=\"attr\">            readOnly:</span> <span class=\"literal\">true</span></span><br><span class=\"line\"><span class=\"attr\">          livenessProbe:</span></span><br><span class=\"line\"><span class=\"attr\">            exec:</span></span><br><span class=\"line\"><span class=\"attr\">              command:</span></span><br><span class=\"line\"><span class=\"bullet\">                -</span> <span class=\"string\">/usr/local/bin/sidecar-injector</span></span><br><span class=\"line\"><span class=\"bullet\">                -</span> <span class=\"string\">probe</span></span><br><span class=\"line\"><span class=\"bullet\">                -</span> <span class=\"bullet\">--probe-path=/tmp/health</span></span><br><span class=\"line\"><span class=\"bullet\">                -</span> <span class=\"bullet\">--interval=4s</span></span><br><span class=\"line\"><span class=\"attr\">            initialDelaySeconds:</span> <span class=\"number\">4</span></span><br><span class=\"line\"><span class=\"attr\">            periodSeconds:</span> <span class=\"number\">4</span></span><br><span class=\"line\"><span class=\"attr\">          readinessProbe:</span></span><br><span class=\"line\"><span class=\"attr\">            exec:</span></span><br><span class=\"line\"><span class=\"attr\">              command:</span></span><br><span class=\"line\"><span class=\"bullet\">                -</span> <span class=\"string\">/usr/local/bin/sidecar-injector</span></span><br><span class=\"line\"><span class=\"bullet\">                -</span> <span class=\"string\">probe</span></span><br><span class=\"line\"><span class=\"bullet\">                -</span> <span class=\"bullet\">--probe-path=/tmp/health</span></span><br><span class=\"line\"><span class=\"bullet\">                -</span> <span class=\"bullet\">--interval=4s</span></span><br><span class=\"line\"><span class=\"attr\">            initialDelaySeconds:</span> <span class=\"number\">4</span></span><br><span class=\"line\"><span class=\"attr\">            periodSeconds:</span> <span class=\"number\">4</span></span><br><span class=\"line\"><span class=\"attr\">          resources:</span></span><br><span class=\"line\"><span class=\"attr\">            requests:</span></span><br><span class=\"line\"><span class=\"attr\">              cpu:</span> <span class=\"number\">10</span><span class=\"string\">m</span></span><br><span class=\"line\">            </span><br><span class=\"line\"><span class=\"attr\">      volumes:</span></span><br><span class=\"line\"><span class=\"attr\">      - name:</span> <span class=\"string\">config-volume</span></span><br><span class=\"line\"><span class=\"attr\">        configMap:</span></span><br><span class=\"line\"><span class=\"attr\">          name:</span> <span class=\"string\">istio</span></span><br><span class=\"line\"><span class=\"attr\">      - name:</span> <span class=\"string\">certs</span></span><br><span class=\"line\"><span class=\"attr\">        secret:</span></span><br><span class=\"line\"><span class=\"attr\">          secretName:</span> <span class=\"string\">istio.istio-sidecar-injector-service-account</span></span><br><span class=\"line\"><span class=\"attr\">      - name:</span> <span class=\"string\">inject-config</span></span><br><span class=\"line\"><span class=\"attr\">        configMap:</span></span><br><span class=\"line\"><span class=\"attr\">          name:</span> <span class=\"string\">istio-sidecar-injector</span></span><br><span class=\"line\"><span class=\"attr\">          items:</span></span><br><span class=\"line\"><span class=\"attr\">          - key:</span> <span class=\"string\">config</span></span><br><span class=\"line\"><span class=\"attr\">            path:</span> <span class=\"string\">config</span></span><br><span class=\"line\"><span class=\"attr\">          - key:</span> <span class=\"string\">values</span></span><br><span class=\"line\"><span class=\"attr\">            path:</span> <span class=\"string\">values</span></span><br><span class=\"line\"><span class=\"attr\">      affinity:</span>      </span><br><span class=\"line\"><span class=\"attr\">        nodeAffinity:</span></span><br><span class=\"line\"><span class=\"attr\">          requiredDuringSchedulingIgnoredDuringExecution:</span></span><br><span class=\"line\"><span class=\"attr\">            nodeSelectorTerms:</span></span><br><span class=\"line\"><span class=\"attr\">            - matchExpressions:</span></span><br><span class=\"line\"><span class=\"attr\">              - key:</span> <span class=\"string\">beta.kubernetes.io/arch</span></span><br><span class=\"line\"><span class=\"attr\">                operator:</span> <span class=\"string\">In</span></span><br><span class=\"line\"><span class=\"attr\">                values:</span></span><br><span class=\"line\"><span class=\"bullet\">                -</span> <span class=\"string\">\"amd64\"</span></span><br><span class=\"line\"><span class=\"bullet\">                -</span> <span class=\"string\">\"ppc64le\"</span></span><br><span class=\"line\"><span class=\"bullet\">                -</span> <span class=\"string\">\"s390x\"</span></span><br><span class=\"line\"><span class=\"attr\">          preferredDuringSchedulingIgnoredDuringExecution:</span></span><br><span class=\"line\"><span class=\"attr\">          - weight:</span> <span class=\"number\">2</span></span><br><span class=\"line\"><span class=\"attr\">            preference:</span></span><br><span class=\"line\"><span class=\"attr\">              matchExpressions:</span></span><br><span class=\"line\"><span class=\"attr\">              - key:</span> <span class=\"string\">beta.kubernetes.io/arch</span></span><br><span class=\"line\"><span class=\"attr\">                operator:</span> <span class=\"string\">In</span></span><br><span class=\"line\"><span class=\"attr\">                values:</span></span><br><span class=\"line\"><span class=\"bullet\">                -</span> <span class=\"string\">\"amd64\"</span></span><br><span class=\"line\"><span class=\"attr\">          - weight:</span> <span class=\"number\">2</span></span><br><span class=\"line\"><span class=\"attr\">            preference:</span></span><br><span class=\"line\"><span class=\"attr\">              matchExpressions:</span></span><br><span class=\"line\"><span class=\"attr\">              - key:</span> <span class=\"string\">beta.kubernetes.io/arch</span></span><br><span class=\"line\"><span class=\"attr\">                operator:</span> <span class=\"string\">In</span></span><br><span class=\"line\"><span class=\"attr\">                values:</span></span><br><span class=\"line\"><span class=\"bullet\">                -</span> <span class=\"string\">\"ppc64le\"</span></span><br><span class=\"line\"><span class=\"attr\">          - weight:</span> <span class=\"number\">2</span></span><br><span class=\"line\"><span class=\"attr\">            preference:</span></span><br><span class=\"line\"><span class=\"attr\">              matchExpressions:</span></span><br><span class=\"line\"><span class=\"attr\">              - key:</span> <span class=\"string\">beta.kubernetes.io/arch</span></span><br><span class=\"line\"><span class=\"attr\">                operator:</span> <span class=\"string\">In</span></span><br><span class=\"line\"><span class=\"attr\">                values:</span></span><br><span class=\"line\"><span class=\"bullet\">                -</span> <span class=\"string\">\"s390x\"</span></span><br></pre></td></tr></table></figure>\n\n<p>这个Pod主要做的事我们通过现象来分析。</p>\n<h1 id=\"Pod中的三个容器\"><a href=\"#Pod中的三个容器\" class=\"headerlink\" title=\"Pod中的三个容器\"></a>Pod中的三个容器</h1><p>我们通过istio官方的demo我们可以发现，开启了自动注入后创建的review Pod中有三个容器，分别是：</p>\n<ul>\n<li>k8s_reviews_revierws-v3</li>\n<li>k8s_istio_proxy_reviews-v3</li>\n<li>k8s_POD_reviews<br>通过分析，第一个就是应用本身，第三个是kubernetes的pause容器，第二个容器就是istio系统中的Sidecar，并且进入容器我们也能看到里边运行的就是Envoy。这个容器是和Pod一一对应的，<strong>所以Sidecar是部署在Pod这个层级的</strong>，这一点很重要。<h2 id=\"Sidecar是如何劫持流量的呢\"><a href=\"#Sidecar是如何劫持流量的呢\" class=\"headerlink\" title=\"Sidecar是如何劫持流量的呢\"></a>Sidecar是如何劫持流量的呢</h2>我们发现了istio会给我们的每个Pod创建一个Sidecar容器，那么他是如何劫持流量的呢？<br>我们进入到这个容器后，执行ifconfig会惊奇发现，应用容器使用的IP地址与istio-proxy竟然是一样的。这说明应用容器与istio-proxy两个容器共享了网络。也就是说，istio在pod启动的时候使用自己的特殊pause容器istio-proxy替换掉了Kubernetes官方的pause，使得应用与istio-proxy处于同一个网络栈下。那最后的问题就是istio如何将应用的进出流量都重新定向到istio-proxy容器监听的端口。为了搞明白这个问题，我们可以手动注入Sidecar，来对比yaml文件的变化。主要变化是init container中多了一个proxy_init容器，查看它的Dockerfile文件可以发现，这个容器主要就是运行了一个脚本：</li>\n</ul>\n<figure class=\"highlight powershell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">FROM ubuntu:xenial</span><br><span class=\"line\">RUN apt-get update &amp;&amp; apt-get install -y \\</span><br><span class=\"line\">    iproute2 \\</span><br><span class=\"line\">    iptables \\</span><br><span class=\"line\"> &amp;&amp; rm -rf /var/lib/apt/lists/*</span><br><span class=\"line\">ADD istio-iptables.sh /usr/local/bin/</span><br><span class=\"line\">ENTRYPOINT [<span class=\"string\">\"/usr/local/bin/istio-iptables.sh\"</span>]</span><br></pre></td></tr></table></figure>\n\n<p>该脚本源码就不具体分析了，不过也能猜出大概。istio正是通过iptables以及iproute2这个工具对Linux网络流量配置了过滤规则来实现Sidecar的流量劫持，其执行的脚本正是istio-iptables这个脚本文件。</p>\n"},{"title":"K8S集群日志收集方案","_content":"\n# K8S集群日志收集方案\n\n   在大型分布式部署的架构中，不同的服务模块部署在不同的服务器中，问题出现时，大部分情况需要根据问题暴露的关键信息定位具体的服务器和服务模块。常见的解决思路是建立一套集中式日志收集系统，将所有节点上的日志统一收集、管理、访问，将极大提高定位问题的效率。\n 一个完整的集中式日志系统，需要包含以下几个主要特点：\n\n - 收集－能够采集多种来源的日志数据 \n - 传输－能够稳定的把日志数据传输到中央系统 \n - 存储－如何存储日志数据 \n - 分析－可以支持 UI 分析\n - 警告－能够提供错误报告，监控机制\n\n目前在K8S集群内部收集日志有以下几种方案\n| 编号  | 方案 | 优点 | 缺点 |\n|----|----|----|----|\n| 1     |每个app的镜像中都集成日志收集组件  | 部署方便，kubernetes的yaml文件无须特别配置，可以为每个app自定义日志收集配置 | 强耦合，不方便应用和日志收集组件升级和维护且会导致镜像过大 |\n| 2     | 单独创建一个日志收集组件跟app的容器一起运行在同一个pod中 |低耦合，扩展性强，方便维护和升级  | 需要对kubernetes的yaml文件进行单独配置，略显繁琐 |\n| 3     | 将所有的Pod的日志都挂载到宿主机上，每台主机上单独起一个日志收集Pod | 完全解耦，性能最高，管理起来最方便 | 需要统一日志收集规则，目录和输出方式 |\n\n## 方案一\n基本不考虑\n## 方案二\n**方案二就是常见的ELK（Elasticsearch、Logstash、Kibana）+ Filebeat**。引入了各类Lib Beats（Package Beat、Top Beat、File Beat等）运行在app应用的Pod中收集日志，转发给Logstash。此方案将手机端的Logstash替换为beats，更灵活，消耗资源更少，扩展性更强。同时可配置Logstash 和Elasticsearch 集群用于支持大集群系统的运维日志数据监控和查询。\n### 简单介绍下ELK\nElasticsearch + Logstash + Kibana（ELK）是一套开源的日志管理方案\n\n - Logstash：负责日志的收集，处理和储存\n - Elasticsearch：负责日志检索和分析\n - Kibana：负责日志的可视化\n![在这里插入图片描述](https://img-blog.csdnimg.cn/20200103150908465.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0N1aV9DdWlfNjY2,size_16,color_FFFFFF,t_70)\n***Elasticsearch简介***\n默认情况下，ES集群节点都是混合节点，即在elasticsearch.yml中默认node.master: true和node.data: true。当ES集群规模达到一定程度以后，就需要注意对集群节点进行角色划分。ES集群节点可以划分为三种：主节点、数据节点和客户端节点。\n - **master-主节点**  维护元数据，管理集群节点状态；不负责数据写入和查询。elasticsearch.yml\n   ```\n   node.master: true\n   node.data: false\n   ```\n - **data-数据节点**  负责数据的写入与查询，压力大。elasticsearch.yml\n   ```\n   node.master: false\n   node.data: true\n   ```\n- **data-客户端节点**  负责任务分发和结果汇聚，分担数据节点压力。elasticsearch.yml\n   ```\n   node.master: false\n   node.data: false\n   ```\n- **data-混合节点**  综合上述三个节点的功能。elasticsearch.yml\n   ```\n   node.master: true\n   node.data: true\n   ```\n\n**Filebeat工作原理**\nFilebeat由两个主要组件组成：prospectors 和 harvesters。这两个组件协同工作将文件变动发送到指定的输出中。\n![在这里插入图片描述](https://img-blog.csdnimg.cn/20200103154511413.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0N1aV9DdWlfNjY2,size_16,color_FFFFFF,t_70)\n**Harvester（收割机）**：负责读取单个文件内容。每个文件会启动一个Harvester，每个Harvester会逐行读取各个文件，并将文件内容发送到制定输出中。Harvester负责打开和关闭文件，意味在Harvester运行的时候，文件描述符处于打开状态，如果文件在收集中被重命名或者被删除，Filebeat会继续读取此文件。所以在Harvester关闭之前，磁盘不会被释放。默认情况filebeat会保持文件打开的状态，直到达到close_inactive（如果此选项开启，filebeat会在指定时间内将不再更新的文件句柄关闭，时间从harvester读取最后一行的时间开始计时。若文件句柄被关闭后，文件发生变化，则会启动一个新的harvester。关闭文件句柄的时间不取决于文件的修改时间，若此参数配置不当，则可能发生日志不实时的情况，由scan_frequency参数决定，默认10s。Harvester使用内部时间戳来记录文件最后被收集的时间。例如：设置5m，则在Harvester读取文件的最后一行之后，开始倒计时5分钟，若5分钟内文件无变化，则关闭文件句柄。默认5m）。\n\n**Prospector（勘测者）**：负责管理Harvester并找到所有读取源。\n\n```yaml\nfilebeat.prospectors:\n\n- input_type: log\n\n  paths:\n\n    - /apps/logs/*/info.log\n```\nProspector会找到/apps/logs/*目录下的所有info.log文件，并为每个文件启动一个Harvester。Prospector会检查每个文件，看Harvester是否已经启动，是否需要启动，或者文件是否可以忽略。若Harvester关闭，只有在文件大小发生变化的时候Prospector才会执行检查。只能检测本地的文件。\n\n**Filebeat如何记录文件状态**：\n\n将文件状态记录在文件中（默认在/var/lib/filebeat/registry）。此状态可以记住Harvester收集文件的偏移量。若连接不上输出设备，如ES等，filebeat会记录发送前的最后一行，并再可以连接的时候继续发送。Filebeat在运行的时候，Prospector状态会被记录在内存中。Filebeat重启的时候，利用registry记录的状态来进行重建，用来还原到重启之前的状态。每个Prospector会为每个找到的文件记录一个状态，对于每个文件，Filebeat存储唯一标识符以检测文件是否先前被收集。\n\n**Filebeat如何保证事件至少被输出一次**：\n\nFilebeat之所以能保证事件至少被传递到配置的输出一次，没有数据丢失，是因为filebeat将每个事件的传递状态保存在文件中。在未得到输出方确认时，filebeat会尝试一直发送，直到得到回应。若filebeat在传输过程中被关闭，则不会再关闭之前确认所有时事件。任何在filebeat关闭之前为确认的时间，都会在filebeat重启之后重新发送。这可确保至少发送一次，但有可能会重复。可通过设置shutdown_timeout 参数来设置关闭之前的等待事件回应的时间（默认禁用）。\n\n \n\n**Logstash工作原理**：\nLogstash事件处理有三个阶段：inputs → filters → outputs。是一个接收，处理，转发日志的工具。支持系统日志，webserver日志，错误日志，应用日志，总之包括所有可以抛出来的日志类型。\n![在这里插入图片描述](https://img-blog.csdnimg.cn/20200103154804689.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0N1aV9DdWlfNjY2,size_16,color_FFFFFF,t_70)\n**Input：输入数据到logstash**。\n\n一些常用的输入为：\n\n- file：从文件系统的文件中读取，类似于tial -f命令\n\n- syslog：在514端口上监听系统日志消息，并根据RFC3164标准进行解析\n\n- redis：从redis service中读取\n\n- beats：从filebeat中读取\n\n- Filters：数据中间处理，对数据进行操作。\n\n一些常用的过滤器为：\n\n- grok：解析任意文本数据，Grok 是 Logstash 最重要的插件。它的主要作用就是将文本格式的字符串，转换成为具体的结构化的数据，配合正则表达式使用。内置120多个解析语法。\n\n官方提供的grok表达式：https://github.com/logstash-plugins/logstash-patterns-core/tree/master/patterns\ngrok在线调试：https://grokdebug.herokuapp.com/\n\n- mutate：对字段进行转换。例如对字段进行删除、替换、修改、重命名等。\n\n- drop：丢弃一部分events不进行处理。\n\n- clone：拷贝 event，这个过程中也可以添加或移除字段。\n\n- geoip：添加地理信息(为前台kibana图形化展示使用)\n\n**Outputs：outputs是logstash处理管道的最末端组件。**一个event可以在处理过程中经过多重输出，但是一旦所有的outputs都执行结束，这个event也就完成生命周期。\n\n一些常见的outputs为：\n\n- elasticsearch：可以高效的保存数据，并且能够方便和简单的进行查询。\n\n- file：将event数据保存到文件中。\n\n- graphite：将event数据发送到图形化组件中，一个很流行的开源存储图形化展示的组件。\n\n- Codecs：codecs 是基于数据流的过滤器，它可以作为input，output的一部分配置。Codecs可以帮助你轻松的分割发送过来已经被序列化的数据。\n\n一些常见的codecs：\n\n- json：使用json格式对数据进行编码/解码。\n\n- multiline：将汇多个事件中数据汇总为一个单一的行。比如：java异常信息和堆栈信息。\n\n***为什么要在ELK基础上引入Lib Beats？***\n在进行日志收集的过程中，我们首先想到的是使用Logstash，因为它是ELK stack中的重要成员，但是在测试过程中发现，Logstash是基于JDK的，在没有产生日志的情况单纯启动Logstash就大概要消耗500M内存，在每个Pod中都启动一个日志收集组件的情况下，使用logstash有点浪费系统资源，我们选择使用Filebeat替代，经测试单独启动Filebeat容器大约会消耗12M内存，比起logstash相当轻量级。\n**Kibana简介**\nKibana通常与 Elasticsearch 一起部署，Kibana 是 Elasticsearch 的一个功能强大的数据可视化 Dashboard，Kibana 允许你通过 web 界面来浏览 Elasticsearch 日志数据。\n## 方案三\n**此方案就是K8S官方推荐的EFK（ELasticsearch、Fluentd、Kibana）方案**\n此方案通过DaemonSet的方式在集群内部每个节点上运行一个Fluent Pod统一收集上层应用层的日志并反馈到Elasticsearch\n![在这里插入图片描述](https://img-blog.csdnimg.cn/20200103155624399.jpg?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0N1aV9DdWlfNjY2,size_16,color_FFFFFF,t_70)\n**Fluentd简介**\nFluentd是一个Ruby语言开发的开源数据收集器，通过它能对数据进行统一收集和消费，能够更好地使用和理解数据。Fluentd将数据结构化为JSON，从而能够统一处理日志数据，包括：收集、过滤、缓存和输出。Fluentd是一个基于插件体系的架构，包括输入插件、输出插件、过滤插件、解析插件、格式化插件、缓存插件和存储插件，通过插件可以扩展和更好的使用Fluentd。\n\nFluentd 通过一组给定的数据源抓取日志数据，处理后（转换成结构化的数据格式）将它们转发给其他服务，比如 Elasticsearch、对象存储等等。Fluentd 支持超过300个日志存储和分析服务，所以在这方面是非常灵活的。主要运行步骤如下：\n\n- 首先 Fluentd 从多个日志源获取数据\n- 结构化并且标记这些数据\n- 然后根据匹配的标签将数据发送到多个目标服务去\n![在这里插入图片描述](https://img-blog.csdnimg.cn/202001031600510.jpg?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0N1aV9DdWlfNjY2,size_16,color_FFFFFF,t_70)\n\n**Fluentd配置**\n一般来说我们是通过一个配置文件来告诉 Fluentd 如何采集、处理数据的，下面简单和大家介绍下 Fluentd 的配置方法。\n**日志源配置**\n比如我们这里为了收集 Kubernetes 节点上的所有容器日志，就需要做如下的日志源配置：\n\n```ruby\n<source>\n\n@id fluentd-containers.log\n\n@type tail\n\npath /var/log/containers/*.log\n\npos_file /var/log/fluentd-containers.log.pos\n\ntime_format %Y-%m-%dT%H:%M:%S.%NZ\n\ntag raw.kubernetes.*\n\nformat json\n\nread_from_head true\n\n</source>\n```\n\n上面配置部分参数说明如下：\n\n- id：表示引用该日志源的唯一标识符，该标识可用于进一步过滤和路由结构化日志数据\n- type：Fluentd 内置的指令，tail表示 Fluentd 从上次读取的位置通过 tail 不断获取数据，另外一个是http表示通过一个 GET 请求来收集数据。\n- path：tail类型下的特定参数，告诉 Fluentd 采集/var/log/containers目录下的所有日志，这是 docker 在 \n Kubernetes 节点上用来存储运行容器 stdout 输出日志数据的目录。\n- pos_file：检查点，如果 Fluentd 程序重新启动了，它将使用此文件中的位置来恢复日志数据收集。\n- tag：用来将日志源与目标或者过滤器匹配的自定义字符串，Fluentd 匹配源/目标标签来路由日志数据。\n路由配置\n\n上面是日志源的配置，接下来看看如何将日志数据发送到 Elasticsearch：\n\n```ruby\n<match **>\n\n@id elasticsearch\n\n@type elasticsearch\n\n@log_level info\n\ninclude_tag_key true\n\ntype_name fluentd\n\nhost \"#{ENV['OUTPUT_HOST']}\"\n\nport \"#{ENV['OUTPUT_PORT']}\"\n\nlogstash_format true\n\n<buffer>\n\n@type file\n\npath /var/log/fluentd-buffers/kubernetes.system.buffer\n\nflush_mode interval\n\nretry_type exponential_backoff\n\nflush_thread_count 2\n\nflush_interval 5s\n\nretry_forever\n\nretry_max_interval 30\n\nchunk_limit_size \"#{ENV['OUTPUT_BUFFER_CHUNK_LIMIT']}\"\n\nqueue_limit_length \"#{ENV['OUTPUT_BUFFER_QUEUE_LIMIT']}\"\n\noverflow_action block\n\n</buffer>\n```\n\n- match：标识一个目标标签，后面是一个匹配日志源的正则表达式，我们这里想要捕获所有的日志并将它们发送给 Elasticsearch，所以需要配置成**。\n- id：目标的一个唯一标识符。\n- type：支持的输出插件标识符，我们这里要输出到 Elasticsearch，所以配置成 elasticsearch，这是 Fluentd 的一个内置插件。\n- log_level：指定要捕获的日志级别，我们这里配置成info，表示任何该级别或者该级别以上（INFO、WARNING、ERROR）的日志都将被路由到 Elsasticsearch。\n- host/port：定义 Elasticsearch 的地址，也可以配置认证信息，我们的 Elasticsearch 不需要认证，所以这里直接指定 host 和 port 即可。\n- logstash_format：Elasticsearch 服务对日志数据构建反向索引进行搜索，将 logstash_format 设置为true，Fluentd 将会以 logstash 格式来转发结构化的日志数据。\n- Buffer： Fluentd 允许在目标不可用时进行缓存，比如，如果网络出现故障或者 Elasticsearch 不可用的时候。缓冲区配置也有助于降低磁盘的 IO。\n## Docker Image获取\n所需Docker image都可以从DockerHub或者[Google镜像仓库获取](https://console.cloud.google.com/projectselector2/gcr?supportedpurview=project)获取\n**目前Elasticsearch、Logstash、Kibana、Filebeat以及Fluentd都没有官方的ARM64镜像**\n**但是，Elasticsearch、Logstash、Kibana有提供DockerFile，另外，*此三组件镜像版本必须一致***\n- [Elasticsearch官方DockerFile](https://github.com/elastic/dockerfiles/tree/v7.5.1/elasticsearch)\n- [Kibana官方DockerFile](https://github.com/elastic/dockerfiles/tree/v7.5.1/kibana)\n- [Logstash官方DockerFile](https://github.com/elastic/dockerfiles/tree/v7.5.1/logstash)\n\n**Filebeat和Fluentd的非官方镜像**：\n\n- kasaoden/filebeat:7.2.0-arm64\n- carlosedp/fluentd-elasticsearch:latest\n","source":"_posts/K8S集群日志收集方案.md","raw":"---\ntitle: K8S集群日志收集方案\ncategories: Kubernetes\n---\n\n# K8S集群日志收集方案\n\n   在大型分布式部署的架构中，不同的服务模块部署在不同的服务器中，问题出现时，大部分情况需要根据问题暴露的关键信息定位具体的服务器和服务模块。常见的解决思路是建立一套集中式日志收集系统，将所有节点上的日志统一收集、管理、访问，将极大提高定位问题的效率。\n 一个完整的集中式日志系统，需要包含以下几个主要特点：\n\n - 收集－能够采集多种来源的日志数据 \n - 传输－能够稳定的把日志数据传输到中央系统 \n - 存储－如何存储日志数据 \n - 分析－可以支持 UI 分析\n - 警告－能够提供错误报告，监控机制\n\n目前在K8S集群内部收集日志有以下几种方案\n| 编号  | 方案 | 优点 | 缺点 |\n|----|----|----|----|\n| 1     |每个app的镜像中都集成日志收集组件  | 部署方便，kubernetes的yaml文件无须特别配置，可以为每个app自定义日志收集配置 | 强耦合，不方便应用和日志收集组件升级和维护且会导致镜像过大 |\n| 2     | 单独创建一个日志收集组件跟app的容器一起运行在同一个pod中 |低耦合，扩展性强，方便维护和升级  | 需要对kubernetes的yaml文件进行单独配置，略显繁琐 |\n| 3     | 将所有的Pod的日志都挂载到宿主机上，每台主机上单独起一个日志收集Pod | 完全解耦，性能最高，管理起来最方便 | 需要统一日志收集规则，目录和输出方式 |\n\n## 方案一\n基本不考虑\n## 方案二\n**方案二就是常见的ELK（Elasticsearch、Logstash、Kibana）+ Filebeat**。引入了各类Lib Beats（Package Beat、Top Beat、File Beat等）运行在app应用的Pod中收集日志，转发给Logstash。此方案将手机端的Logstash替换为beats，更灵活，消耗资源更少，扩展性更强。同时可配置Logstash 和Elasticsearch 集群用于支持大集群系统的运维日志数据监控和查询。\n### 简单介绍下ELK\nElasticsearch + Logstash + Kibana（ELK）是一套开源的日志管理方案\n\n - Logstash：负责日志的收集，处理和储存\n - Elasticsearch：负责日志检索和分析\n - Kibana：负责日志的可视化\n![在这里插入图片描述](https://img-blog.csdnimg.cn/20200103150908465.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0N1aV9DdWlfNjY2,size_16,color_FFFFFF,t_70)\n***Elasticsearch简介***\n默认情况下，ES集群节点都是混合节点，即在elasticsearch.yml中默认node.master: true和node.data: true。当ES集群规模达到一定程度以后，就需要注意对集群节点进行角色划分。ES集群节点可以划分为三种：主节点、数据节点和客户端节点。\n - **master-主节点**  维护元数据，管理集群节点状态；不负责数据写入和查询。elasticsearch.yml\n   ```\n   node.master: true\n   node.data: false\n   ```\n - **data-数据节点**  负责数据的写入与查询，压力大。elasticsearch.yml\n   ```\n   node.master: false\n   node.data: true\n   ```\n- **data-客户端节点**  负责任务分发和结果汇聚，分担数据节点压力。elasticsearch.yml\n   ```\n   node.master: false\n   node.data: false\n   ```\n- **data-混合节点**  综合上述三个节点的功能。elasticsearch.yml\n   ```\n   node.master: true\n   node.data: true\n   ```\n\n**Filebeat工作原理**\nFilebeat由两个主要组件组成：prospectors 和 harvesters。这两个组件协同工作将文件变动发送到指定的输出中。\n![在这里插入图片描述](https://img-blog.csdnimg.cn/20200103154511413.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0N1aV9DdWlfNjY2,size_16,color_FFFFFF,t_70)\n**Harvester（收割机）**：负责读取单个文件内容。每个文件会启动一个Harvester，每个Harvester会逐行读取各个文件，并将文件内容发送到制定输出中。Harvester负责打开和关闭文件，意味在Harvester运行的时候，文件描述符处于打开状态，如果文件在收集中被重命名或者被删除，Filebeat会继续读取此文件。所以在Harvester关闭之前，磁盘不会被释放。默认情况filebeat会保持文件打开的状态，直到达到close_inactive（如果此选项开启，filebeat会在指定时间内将不再更新的文件句柄关闭，时间从harvester读取最后一行的时间开始计时。若文件句柄被关闭后，文件发生变化，则会启动一个新的harvester。关闭文件句柄的时间不取决于文件的修改时间，若此参数配置不当，则可能发生日志不实时的情况，由scan_frequency参数决定，默认10s。Harvester使用内部时间戳来记录文件最后被收集的时间。例如：设置5m，则在Harvester读取文件的最后一行之后，开始倒计时5分钟，若5分钟内文件无变化，则关闭文件句柄。默认5m）。\n\n**Prospector（勘测者）**：负责管理Harvester并找到所有读取源。\n\n```yaml\nfilebeat.prospectors:\n\n- input_type: log\n\n  paths:\n\n    - /apps/logs/*/info.log\n```\nProspector会找到/apps/logs/*目录下的所有info.log文件，并为每个文件启动一个Harvester。Prospector会检查每个文件，看Harvester是否已经启动，是否需要启动，或者文件是否可以忽略。若Harvester关闭，只有在文件大小发生变化的时候Prospector才会执行检查。只能检测本地的文件。\n\n**Filebeat如何记录文件状态**：\n\n将文件状态记录在文件中（默认在/var/lib/filebeat/registry）。此状态可以记住Harvester收集文件的偏移量。若连接不上输出设备，如ES等，filebeat会记录发送前的最后一行，并再可以连接的时候继续发送。Filebeat在运行的时候，Prospector状态会被记录在内存中。Filebeat重启的时候，利用registry记录的状态来进行重建，用来还原到重启之前的状态。每个Prospector会为每个找到的文件记录一个状态，对于每个文件，Filebeat存储唯一标识符以检测文件是否先前被收集。\n\n**Filebeat如何保证事件至少被输出一次**：\n\nFilebeat之所以能保证事件至少被传递到配置的输出一次，没有数据丢失，是因为filebeat将每个事件的传递状态保存在文件中。在未得到输出方确认时，filebeat会尝试一直发送，直到得到回应。若filebeat在传输过程中被关闭，则不会再关闭之前确认所有时事件。任何在filebeat关闭之前为确认的时间，都会在filebeat重启之后重新发送。这可确保至少发送一次，但有可能会重复。可通过设置shutdown_timeout 参数来设置关闭之前的等待事件回应的时间（默认禁用）。\n\n \n\n**Logstash工作原理**：\nLogstash事件处理有三个阶段：inputs → filters → outputs。是一个接收，处理，转发日志的工具。支持系统日志，webserver日志，错误日志，应用日志，总之包括所有可以抛出来的日志类型。\n![在这里插入图片描述](https://img-blog.csdnimg.cn/20200103154804689.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0N1aV9DdWlfNjY2,size_16,color_FFFFFF,t_70)\n**Input：输入数据到logstash**。\n\n一些常用的输入为：\n\n- file：从文件系统的文件中读取，类似于tial -f命令\n\n- syslog：在514端口上监听系统日志消息，并根据RFC3164标准进行解析\n\n- redis：从redis service中读取\n\n- beats：从filebeat中读取\n\n- Filters：数据中间处理，对数据进行操作。\n\n一些常用的过滤器为：\n\n- grok：解析任意文本数据，Grok 是 Logstash 最重要的插件。它的主要作用就是将文本格式的字符串，转换成为具体的结构化的数据，配合正则表达式使用。内置120多个解析语法。\n\n官方提供的grok表达式：https://github.com/logstash-plugins/logstash-patterns-core/tree/master/patterns\ngrok在线调试：https://grokdebug.herokuapp.com/\n\n- mutate：对字段进行转换。例如对字段进行删除、替换、修改、重命名等。\n\n- drop：丢弃一部分events不进行处理。\n\n- clone：拷贝 event，这个过程中也可以添加或移除字段。\n\n- geoip：添加地理信息(为前台kibana图形化展示使用)\n\n**Outputs：outputs是logstash处理管道的最末端组件。**一个event可以在处理过程中经过多重输出，但是一旦所有的outputs都执行结束，这个event也就完成生命周期。\n\n一些常见的outputs为：\n\n- elasticsearch：可以高效的保存数据，并且能够方便和简单的进行查询。\n\n- file：将event数据保存到文件中。\n\n- graphite：将event数据发送到图形化组件中，一个很流行的开源存储图形化展示的组件。\n\n- Codecs：codecs 是基于数据流的过滤器，它可以作为input，output的一部分配置。Codecs可以帮助你轻松的分割发送过来已经被序列化的数据。\n\n一些常见的codecs：\n\n- json：使用json格式对数据进行编码/解码。\n\n- multiline：将汇多个事件中数据汇总为一个单一的行。比如：java异常信息和堆栈信息。\n\n***为什么要在ELK基础上引入Lib Beats？***\n在进行日志收集的过程中，我们首先想到的是使用Logstash，因为它是ELK stack中的重要成员，但是在测试过程中发现，Logstash是基于JDK的，在没有产生日志的情况单纯启动Logstash就大概要消耗500M内存，在每个Pod中都启动一个日志收集组件的情况下，使用logstash有点浪费系统资源，我们选择使用Filebeat替代，经测试单独启动Filebeat容器大约会消耗12M内存，比起logstash相当轻量级。\n**Kibana简介**\nKibana通常与 Elasticsearch 一起部署，Kibana 是 Elasticsearch 的一个功能强大的数据可视化 Dashboard，Kibana 允许你通过 web 界面来浏览 Elasticsearch 日志数据。\n## 方案三\n**此方案就是K8S官方推荐的EFK（ELasticsearch、Fluentd、Kibana）方案**\n此方案通过DaemonSet的方式在集群内部每个节点上运行一个Fluent Pod统一收集上层应用层的日志并反馈到Elasticsearch\n![在这里插入图片描述](https://img-blog.csdnimg.cn/20200103155624399.jpg?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0N1aV9DdWlfNjY2,size_16,color_FFFFFF,t_70)\n**Fluentd简介**\nFluentd是一个Ruby语言开发的开源数据收集器，通过它能对数据进行统一收集和消费，能够更好地使用和理解数据。Fluentd将数据结构化为JSON，从而能够统一处理日志数据，包括：收集、过滤、缓存和输出。Fluentd是一个基于插件体系的架构，包括输入插件、输出插件、过滤插件、解析插件、格式化插件、缓存插件和存储插件，通过插件可以扩展和更好的使用Fluentd。\n\nFluentd 通过一组给定的数据源抓取日志数据，处理后（转换成结构化的数据格式）将它们转发给其他服务，比如 Elasticsearch、对象存储等等。Fluentd 支持超过300个日志存储和分析服务，所以在这方面是非常灵活的。主要运行步骤如下：\n\n- 首先 Fluentd 从多个日志源获取数据\n- 结构化并且标记这些数据\n- 然后根据匹配的标签将数据发送到多个目标服务去\n![在这里插入图片描述](https://img-blog.csdnimg.cn/202001031600510.jpg?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0N1aV9DdWlfNjY2,size_16,color_FFFFFF,t_70)\n\n**Fluentd配置**\n一般来说我们是通过一个配置文件来告诉 Fluentd 如何采集、处理数据的，下面简单和大家介绍下 Fluentd 的配置方法。\n**日志源配置**\n比如我们这里为了收集 Kubernetes 节点上的所有容器日志，就需要做如下的日志源配置：\n\n```ruby\n<source>\n\n@id fluentd-containers.log\n\n@type tail\n\npath /var/log/containers/*.log\n\npos_file /var/log/fluentd-containers.log.pos\n\ntime_format %Y-%m-%dT%H:%M:%S.%NZ\n\ntag raw.kubernetes.*\n\nformat json\n\nread_from_head true\n\n</source>\n```\n\n上面配置部分参数说明如下：\n\n- id：表示引用该日志源的唯一标识符，该标识可用于进一步过滤和路由结构化日志数据\n- type：Fluentd 内置的指令，tail表示 Fluentd 从上次读取的位置通过 tail 不断获取数据，另外一个是http表示通过一个 GET 请求来收集数据。\n- path：tail类型下的特定参数，告诉 Fluentd 采集/var/log/containers目录下的所有日志，这是 docker 在 \n Kubernetes 节点上用来存储运行容器 stdout 输出日志数据的目录。\n- pos_file：检查点，如果 Fluentd 程序重新启动了，它将使用此文件中的位置来恢复日志数据收集。\n- tag：用来将日志源与目标或者过滤器匹配的自定义字符串，Fluentd 匹配源/目标标签来路由日志数据。\n路由配置\n\n上面是日志源的配置，接下来看看如何将日志数据发送到 Elasticsearch：\n\n```ruby\n<match **>\n\n@id elasticsearch\n\n@type elasticsearch\n\n@log_level info\n\ninclude_tag_key true\n\ntype_name fluentd\n\nhost \"#{ENV['OUTPUT_HOST']}\"\n\nport \"#{ENV['OUTPUT_PORT']}\"\n\nlogstash_format true\n\n<buffer>\n\n@type file\n\npath /var/log/fluentd-buffers/kubernetes.system.buffer\n\nflush_mode interval\n\nretry_type exponential_backoff\n\nflush_thread_count 2\n\nflush_interval 5s\n\nretry_forever\n\nretry_max_interval 30\n\nchunk_limit_size \"#{ENV['OUTPUT_BUFFER_CHUNK_LIMIT']}\"\n\nqueue_limit_length \"#{ENV['OUTPUT_BUFFER_QUEUE_LIMIT']}\"\n\noverflow_action block\n\n</buffer>\n```\n\n- match：标识一个目标标签，后面是一个匹配日志源的正则表达式，我们这里想要捕获所有的日志并将它们发送给 Elasticsearch，所以需要配置成**。\n- id：目标的一个唯一标识符。\n- type：支持的输出插件标识符，我们这里要输出到 Elasticsearch，所以配置成 elasticsearch，这是 Fluentd 的一个内置插件。\n- log_level：指定要捕获的日志级别，我们这里配置成info，表示任何该级别或者该级别以上（INFO、WARNING、ERROR）的日志都将被路由到 Elsasticsearch。\n- host/port：定义 Elasticsearch 的地址，也可以配置认证信息，我们的 Elasticsearch 不需要认证，所以这里直接指定 host 和 port 即可。\n- logstash_format：Elasticsearch 服务对日志数据构建反向索引进行搜索，将 logstash_format 设置为true，Fluentd 将会以 logstash 格式来转发结构化的日志数据。\n- Buffer： Fluentd 允许在目标不可用时进行缓存，比如，如果网络出现故障或者 Elasticsearch 不可用的时候。缓冲区配置也有助于降低磁盘的 IO。\n## Docker Image获取\n所需Docker image都可以从DockerHub或者[Google镜像仓库获取](https://console.cloud.google.com/projectselector2/gcr?supportedpurview=project)获取\n**目前Elasticsearch、Logstash、Kibana、Filebeat以及Fluentd都没有官方的ARM64镜像**\n**但是，Elasticsearch、Logstash、Kibana有提供DockerFile，另外，*此三组件镜像版本必须一致***\n- [Elasticsearch官方DockerFile](https://github.com/elastic/dockerfiles/tree/v7.5.1/elasticsearch)\n- [Kibana官方DockerFile](https://github.com/elastic/dockerfiles/tree/v7.5.1/kibana)\n- [Logstash官方DockerFile](https://github.com/elastic/dockerfiles/tree/v7.5.1/logstash)\n\n**Filebeat和Fluentd的非官方镜像**：\n\n- kasaoden/filebeat:7.2.0-arm64\n- carlosedp/fluentd-elasticsearch:latest\n","slug":"K8S集群日志收集方案","published":1,"date":"2020-04-05T03:54:46.697Z","updated":"2020-04-05T04:19:11.534Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck8x0luvc00062otv5c7eebpv","content":"<h1 id=\"K8S集群日志收集方案\"><a href=\"#K8S集群日志收集方案\" class=\"headerlink\" title=\"K8S集群日志收集方案\"></a>K8S集群日志收集方案</h1><p>   在大型分布式部署的架构中，不同的服务模块部署在不同的服务器中，问题出现时，大部分情况需要根据问题暴露的关键信息定位具体的服务器和服务模块。常见的解决思路是建立一套集中式日志收集系统，将所有节点上的日志统一收集、管理、访问，将极大提高定位问题的效率。<br> 一个完整的集中式日志系统，需要包含以下几个主要特点：</p>\n<ul>\n<li>收集－能够采集多种来源的日志数据 </li>\n<li>传输－能够稳定的把日志数据传输到中央系统 </li>\n<li>存储－如何存储日志数据 </li>\n<li>分析－可以支持 UI 分析</li>\n<li>警告－能够提供错误报告，监控机制</li>\n</ul>\n<p>目前在K8S集群内部收集日志有以下几种方案<br>| 编号  | 方案 | 优点 | 缺点 |<br>|—-|—-|—-|—-|<br>| 1     |每个app的镜像中都集成日志收集组件  | 部署方便，kubernetes的yaml文件无须特别配置，可以为每个app自定义日志收集配置 | 强耦合，不方便应用和日志收集组件升级和维护且会导致镜像过大 |<br>| 2     | 单独创建一个日志收集组件跟app的容器一起运行在同一个pod中 |低耦合，扩展性强，方便维护和升级  | 需要对kubernetes的yaml文件进行单独配置，略显繁琐 |<br>| 3     | 将所有的Pod的日志都挂载到宿主机上，每台主机上单独起一个日志收集Pod | 完全解耦，性能最高，管理起来最方便 | 需要统一日志收集规则，目录和输出方式 |</p>\n<h2 id=\"方案一\"><a href=\"#方案一\" class=\"headerlink\" title=\"方案一\"></a>方案一</h2><p>基本不考虑</p>\n<h2 id=\"方案二\"><a href=\"#方案二\" class=\"headerlink\" title=\"方案二\"></a>方案二</h2><p><strong>方案二就是常见的ELK（Elasticsearch、Logstash、Kibana）+ Filebeat</strong>。引入了各类Lib Beats（Package Beat、Top Beat、File Beat等）运行在app应用的Pod中收集日志，转发给Logstash。此方案将手机端的Logstash替换为beats，更灵活，消耗资源更少，扩展性更强。同时可配置Logstash 和Elasticsearch 集群用于支持大集群系统的运维日志数据监控和查询。</p>\n<h3 id=\"简单介绍下ELK\"><a href=\"#简单介绍下ELK\" class=\"headerlink\" title=\"简单介绍下ELK\"></a>简单介绍下ELK</h3><p>Elasticsearch + Logstash + Kibana（ELK）是一套开源的日志管理方案</p>\n<ul>\n<li><p>Logstash：负责日志的收集，处理和储存</p>\n</li>\n<li><p>Elasticsearch：负责日志检索和分析</p>\n</li>\n<li><p>Kibana：负责日志的可视化<br><img src=\"https://img-blog.csdnimg.cn/20200103150908465.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0N1aV9DdWlfNjY2,size_16,color_FFFFFF,t_70\" alt=\"在这里插入图片描述\"><br><strong><em>Elasticsearch简介</em></strong><br>默认情况下，ES集群节点都是混合节点，即在elasticsearch.yml中默认node.master: true和node.data: true。当ES集群规模达到一定程度以后，就需要注意对集群节点进行角色划分。ES集群节点可以划分为三种：主节点、数据节点和客户端节点。</p>\n</li>\n<li><p><strong>master-主节点</strong>  维护元数据，管理集群节点状态；不负责数据写入和查询。elasticsearch.yml</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">node.master: true</span><br><span class=\"line\">node.data: false</span><br></pre></td></tr></table></figure>\n</li>\n<li><p><strong>data-数据节点</strong>  负责数据的写入与查询，压力大。elasticsearch.yml</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">node.master: false</span><br><span class=\"line\">node.data: true</span><br></pre></td></tr></table></figure>\n\n</li>\n</ul>\n<ul>\n<li><p><strong>data-客户端节点</strong>  负责任务分发和结果汇聚，分担数据节点压力。elasticsearch.yml</p>\n <figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">node.master: false</span><br><span class=\"line\">node.data: false</span><br></pre></td></tr></table></figure>\n</li>\n<li><p><strong>data-混合节点</strong>  综合上述三个节点的功能。elasticsearch.yml</p>\n <figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">node.master: true</span><br><span class=\"line\">node.data: true</span><br></pre></td></tr></table></figure>\n\n</li>\n</ul>\n<p><strong>Filebeat工作原理</strong><br>Filebeat由两个主要组件组成：prospectors 和 harvesters。这两个组件协同工作将文件变动发送到指定的输出中。<br><img src=\"https://img-blog.csdnimg.cn/20200103154511413.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0N1aV9DdWlfNjY2,size_16,color_FFFFFF,t_70\" alt=\"在这里插入图片描述\"><br><strong>Harvester（收割机）</strong>：负责读取单个文件内容。每个文件会启动一个Harvester，每个Harvester会逐行读取各个文件，并将文件内容发送到制定输出中。Harvester负责打开和关闭文件，意味在Harvester运行的时候，文件描述符处于打开状态，如果文件在收集中被重命名或者被删除，Filebeat会继续读取此文件。所以在Harvester关闭之前，磁盘不会被释放。默认情况filebeat会保持文件打开的状态，直到达到close_inactive（如果此选项开启，filebeat会在指定时间内将不再更新的文件句柄关闭，时间从harvester读取最后一行的时间开始计时。若文件句柄被关闭后，文件发生变化，则会启动一个新的harvester。关闭文件句柄的时间不取决于文件的修改时间，若此参数配置不当，则可能发生日志不实时的情况，由scan_frequency参数决定，默认10s。Harvester使用内部时间戳来记录文件最后被收集的时间。例如：设置5m，则在Harvester读取文件的最后一行之后，开始倒计时5分钟，若5分钟内文件无变化，则关闭文件句柄。默认5m）。</p>\n<p><strong>Prospector（勘测者）</strong>：负责管理Harvester并找到所有读取源。</p>\n<figure class=\"highlight yaml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"string\">filebeat.prospectors:</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"attr\">- input_type:</span> <span class=\"string\">log</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"attr\">  paths:</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"bullet\">    -</span> <span class=\"string\">/apps/logs/*/info.log</span></span><br></pre></td></tr></table></figure>\n\n<p>Prospector会找到/apps/logs/*目录下的所有info.log文件，并为每个文件启动一个Harvester。Prospector会检查每个文件，看Harvester是否已经启动，是否需要启动，或者文件是否可以忽略。若Harvester关闭，只有在文件大小发生变化的时候Prospector才会执行检查。只能检测本地的文件。</p>\n<p><strong>Filebeat如何记录文件状态</strong>：</p>\n<p>将文件状态记录在文件中（默认在/var/lib/filebeat/registry）。此状态可以记住Harvester收集文件的偏移量。若连接不上输出设备，如ES等，filebeat会记录发送前的最后一行，并再可以连接的时候继续发送。Filebeat在运行的时候，Prospector状态会被记录在内存中。Filebeat重启的时候，利用registry记录的状态来进行重建，用来还原到重启之前的状态。每个Prospector会为每个找到的文件记录一个状态，对于每个文件，Filebeat存储唯一标识符以检测文件是否先前被收集。</p>\n<p><strong>Filebeat如何保证事件至少被输出一次</strong>：</p>\n<p>Filebeat之所以能保证事件至少被传递到配置的输出一次，没有数据丢失，是因为filebeat将每个事件的传递状态保存在文件中。在未得到输出方确认时，filebeat会尝试一直发送，直到得到回应。若filebeat在传输过程中被关闭，则不会再关闭之前确认所有时事件。任何在filebeat关闭之前为确认的时间，都会在filebeat重启之后重新发送。这可确保至少发送一次，但有可能会重复。可通过设置shutdown_timeout 参数来设置关闭之前的等待事件回应的时间（默认禁用）。</p>\n<p><strong>Logstash工作原理</strong>：<br>Logstash事件处理有三个阶段：inputs → filters → outputs。是一个接收，处理，转发日志的工具。支持系统日志，webserver日志，错误日志，应用日志，总之包括所有可以抛出来的日志类型。<br><img src=\"https://img-blog.csdnimg.cn/20200103154804689.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0N1aV9DdWlfNjY2,size_16,color_FFFFFF,t_70\" alt=\"在这里插入图片描述\"><br><strong>Input：输入数据到logstash</strong>。</p>\n<p>一些常用的输入为：</p>\n<ul>\n<li><p>file：从文件系统的文件中读取，类似于tial -f命令</p>\n</li>\n<li><p>syslog：在514端口上监听系统日志消息，并根据RFC3164标准进行解析</p>\n</li>\n<li><p>redis：从redis service中读取</p>\n</li>\n<li><p>beats：从filebeat中读取</p>\n</li>\n<li><p>Filters：数据中间处理，对数据进行操作。</p>\n</li>\n</ul>\n<p>一些常用的过滤器为：</p>\n<ul>\n<li>grok：解析任意文本数据，Grok 是 Logstash 最重要的插件。它的主要作用就是将文本格式的字符串，转换成为具体的结构化的数据，配合正则表达式使用。内置120多个解析语法。</li>\n</ul>\n<p>官方提供的grok表达式：<a href=\"https://github.com/logstash-plugins/logstash-patterns-core/tree/master/patterns\" target=\"_blank\" rel=\"noopener\">https://github.com/logstash-plugins/logstash-patterns-core/tree/master/patterns</a><br>grok在线调试：<a href=\"https://grokdebug.herokuapp.com/\" target=\"_blank\" rel=\"noopener\">https://grokdebug.herokuapp.com/</a></p>\n<ul>\n<li><p>mutate：对字段进行转换。例如对字段进行删除、替换、修改、重命名等。</p>\n</li>\n<li><p>drop：丢弃一部分events不进行处理。</p>\n</li>\n<li><p>clone：拷贝 event，这个过程中也可以添加或移除字段。</p>\n</li>\n<li><p>geoip：添加地理信息(为前台kibana图形化展示使用)</p>\n</li>\n</ul>\n<p><strong>Outputs：outputs是logstash处理管道的最末端组件。</strong>一个event可以在处理过程中经过多重输出，但是一旦所有的outputs都执行结束，这个event也就完成生命周期。</p>\n<p>一些常见的outputs为：</p>\n<ul>\n<li><p>elasticsearch：可以高效的保存数据，并且能够方便和简单的进行查询。</p>\n</li>\n<li><p>file：将event数据保存到文件中。</p>\n</li>\n<li><p>graphite：将event数据发送到图形化组件中，一个很流行的开源存储图形化展示的组件。</p>\n</li>\n<li><p>Codecs：codecs 是基于数据流的过滤器，它可以作为input，output的一部分配置。Codecs可以帮助你轻松的分割发送过来已经被序列化的数据。</p>\n</li>\n</ul>\n<p>一些常见的codecs：</p>\n<ul>\n<li><p>json：使用json格式对数据进行编码/解码。</p>\n</li>\n<li><p>multiline：将汇多个事件中数据汇总为一个单一的行。比如：java异常信息和堆栈信息。</p>\n</li>\n</ul>\n<p><strong><em>为什么要在ELK基础上引入Lib Beats？</em></strong><br>在进行日志收集的过程中，我们首先想到的是使用Logstash，因为它是ELK stack中的重要成员，但是在测试过程中发现，Logstash是基于JDK的，在没有产生日志的情况单纯启动Logstash就大概要消耗500M内存，在每个Pod中都启动一个日志收集组件的情况下，使用logstash有点浪费系统资源，我们选择使用Filebeat替代，经测试单独启动Filebeat容器大约会消耗12M内存，比起logstash相当轻量级。<br><strong>Kibana简介</strong><br>Kibana通常与 Elasticsearch 一起部署，Kibana 是 Elasticsearch 的一个功能强大的数据可视化 Dashboard，Kibana 允许你通过 web 界面来浏览 Elasticsearch 日志数据。</p>\n<h2 id=\"方案三\"><a href=\"#方案三\" class=\"headerlink\" title=\"方案三\"></a>方案三</h2><p><strong>此方案就是K8S官方推荐的EFK（ELasticsearch、Fluentd、Kibana）方案</strong><br>此方案通过DaemonSet的方式在集群内部每个节点上运行一个Fluent Pod统一收集上层应用层的日志并反馈到Elasticsearch<br><img src=\"https://img-blog.csdnimg.cn/20200103155624399.jpg?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0N1aV9DdWlfNjY2,size_16,color_FFFFFF,t_70\" alt=\"在这里插入图片描述\"><br><strong>Fluentd简介</strong><br>Fluentd是一个Ruby语言开发的开源数据收集器，通过它能对数据进行统一收集和消费，能够更好地使用和理解数据。Fluentd将数据结构化为JSON，从而能够统一处理日志数据，包括：收集、过滤、缓存和输出。Fluentd是一个基于插件体系的架构，包括输入插件、输出插件、过滤插件、解析插件、格式化插件、缓存插件和存储插件，通过插件可以扩展和更好的使用Fluentd。</p>\n<p>Fluentd 通过一组给定的数据源抓取日志数据，处理后（转换成结构化的数据格式）将它们转发给其他服务，比如 Elasticsearch、对象存储等等。Fluentd 支持超过300个日志存储和分析服务，所以在这方面是非常灵活的。主要运行步骤如下：</p>\n<ul>\n<li>首先 Fluentd 从多个日志源获取数据</li>\n<li>结构化并且标记这些数据</li>\n<li>然后根据匹配的标签将数据发送到多个目标服务去<br><img src=\"https://img-blog.csdnimg.cn/202001031600510.jpg?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0N1aV9DdWlfNjY2,size_16,color_FFFFFF,t_70\" alt=\"在这里插入图片描述\"></li>\n</ul>\n<p><strong>Fluentd配置</strong><br>一般来说我们是通过一个配置文件来告诉 Fluentd 如何采集、处理数据的，下面简单和大家介绍下 Fluentd 的配置方法。<br><strong>日志源配置</strong><br>比如我们这里为了收集 Kubernetes 节点上的所有容器日志，就需要做如下的日志源配置：</p>\n<figure class=\"highlight ruby\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&lt;source&gt;</span><br><span class=\"line\"></span><br><span class=\"line\">@id fluentd-containers.log</span><br><span class=\"line\"></span><br><span class=\"line\">@type tail</span><br><span class=\"line\"></span><br><span class=\"line\">path /var/log/containers/*.log</span><br><span class=\"line\"></span><br><span class=\"line\">pos_file /var/log/fluentd-containers.log.pos</span><br><span class=\"line\"></span><br><span class=\"line\">time_format %Y-%m-%dT%<span class=\"symbol\">H:</span>%<span class=\"symbol\">M:</span>%S.%NZ</span><br><span class=\"line\"></span><br><span class=\"line\">tag raw.kubernetes.*</span><br><span class=\"line\"></span><br><span class=\"line\">format json</span><br><span class=\"line\"></span><br><span class=\"line\">read_from_head <span class=\"literal\">true</span></span><br><span class=\"line\"></span><br><span class=\"line\">&lt;<span class=\"regexp\">/source&gt;</span></span><br></pre></td></tr></table></figure>\n\n<p>上面配置部分参数说明如下：</p>\n<ul>\n<li>id：表示引用该日志源的唯一标识符，该标识可用于进一步过滤和路由结构化日志数据</li>\n<li>type：Fluentd 内置的指令，tail表示 Fluentd 从上次读取的位置通过 tail 不断获取数据，另外一个是http表示通过一个 GET 请求来收集数据。</li>\n<li>path：tail类型下的特定参数，告诉 Fluentd 采集/var/log/containers目录下的所有日志，这是 docker 在<br>Kubernetes 节点上用来存储运行容器 stdout 输出日志数据的目录。</li>\n<li>pos_file：检查点，如果 Fluentd 程序重新启动了，它将使用此文件中的位置来恢复日志数据收集。</li>\n<li>tag：用来将日志源与目标或者过滤器匹配的自定义字符串，Fluentd 匹配源/目标标签来路由日志数据。<br>路由配置</li>\n</ul>\n<p>上面是日志源的配置，接下来看看如何将日志数据发送到 Elasticsearch：</p>\n<figure class=\"highlight ruby\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&lt;match **&gt;</span><br><span class=\"line\"></span><br><span class=\"line\">@id elasticsearch</span><br><span class=\"line\"></span><br><span class=\"line\">@type elasticsearch</span><br><span class=\"line\"></span><br><span class=\"line\">@log_level info</span><br><span class=\"line\"></span><br><span class=\"line\">include_tag_key <span class=\"literal\">true</span></span><br><span class=\"line\"></span><br><span class=\"line\">type_name fluentd</span><br><span class=\"line\"></span><br><span class=\"line\">host <span class=\"string\">\"<span class=\"subst\">#&#123;ENV[<span class=\"string\">'OUTPUT_HOST'</span>]&#125;</span>\"</span></span><br><span class=\"line\"></span><br><span class=\"line\">port <span class=\"string\">\"<span class=\"subst\">#&#123;ENV[<span class=\"string\">'OUTPUT_PORT'</span>]&#125;</span>\"</span></span><br><span class=\"line\"></span><br><span class=\"line\">logstash_format <span class=\"literal\">true</span></span><br><span class=\"line\"></span><br><span class=\"line\">&lt;buffer&gt;</span><br><span class=\"line\"></span><br><span class=\"line\">@type file</span><br><span class=\"line\"></span><br><span class=\"line\">path /var/log/fluentd-buffers/kubernetes.system.buffer</span><br><span class=\"line\"></span><br><span class=\"line\">flush_mode interval</span><br><span class=\"line\"></span><br><span class=\"line\">retry_type exponential_backoff</span><br><span class=\"line\"></span><br><span class=\"line\">flush_thread_count <span class=\"number\">2</span></span><br><span class=\"line\"></span><br><span class=\"line\">flush_interval <span class=\"number\">5</span>s</span><br><span class=\"line\"></span><br><span class=\"line\">retry_forever</span><br><span class=\"line\"></span><br><span class=\"line\">retry_max_interval <span class=\"number\">30</span></span><br><span class=\"line\"></span><br><span class=\"line\">chunk_limit_size <span class=\"string\">\"<span class=\"subst\">#&#123;ENV[<span class=\"string\">'OUTPUT_BUFFER_CHUNK_LIMIT'</span>]&#125;</span>\"</span></span><br><span class=\"line\"></span><br><span class=\"line\">queue_limit_length <span class=\"string\">\"<span class=\"subst\">#&#123;ENV[<span class=\"string\">'OUTPUT_BUFFER_QUEUE_LIMIT'</span>]&#125;</span>\"</span></span><br><span class=\"line\"></span><br><span class=\"line\">overflow_action block</span><br><span class=\"line\"></span><br><span class=\"line\">&lt;<span class=\"regexp\">/buffer&gt;</span></span><br></pre></td></tr></table></figure>\n\n<ul>\n<li>match：标识一个目标标签，后面是一个匹配日志源的正则表达式，我们这里想要捕获所有的日志并将它们发送给 Elasticsearch，所以需要配置成**。</li>\n<li>id：目标的一个唯一标识符。</li>\n<li>type：支持的输出插件标识符，我们这里要输出到 Elasticsearch，所以配置成 elasticsearch，这是 Fluentd 的一个内置插件。</li>\n<li>log_level：指定要捕获的日志级别，我们这里配置成info，表示任何该级别或者该级别以上（INFO、WARNING、ERROR）的日志都将被路由到 Elsasticsearch。</li>\n<li>host/port：定义 Elasticsearch 的地址，也可以配置认证信息，我们的 Elasticsearch 不需要认证，所以这里直接指定 host 和 port 即可。</li>\n<li>logstash_format：Elasticsearch 服务对日志数据构建反向索引进行搜索，将 logstash_format 设置为true，Fluentd 将会以 logstash 格式来转发结构化的日志数据。</li>\n<li>Buffer： Fluentd 允许在目标不可用时进行缓存，比如，如果网络出现故障或者 Elasticsearch 不可用的时候。缓冲区配置也有助于降低磁盘的 IO。<h2 id=\"Docker-Image获取\"><a href=\"#Docker-Image获取\" class=\"headerlink\" title=\"Docker Image获取\"></a>Docker Image获取</h2>所需Docker image都可以从DockerHub或者<a href=\"https://console.cloud.google.com/projectselector2/gcr?supportedpurview=project\" target=\"_blank\" rel=\"noopener\">Google镜像仓库获取</a>获取</li>\n</ul>\n<p><strong>目前Elasticsearch、Logstash、Kibana、Filebeat以及Fluentd都没有官方的ARM64镜像</strong><br><strong>但是，Elasticsearch、Logstash、Kibana有提供DockerFile，另外，<em>此三组件镜像版本必须一致</em></strong></p>\n<ul>\n<li><a href=\"https://github.com/elastic/dockerfiles/tree/v7.5.1/elasticsearch\" target=\"_blank\" rel=\"noopener\">Elasticsearch官方DockerFile</a></li>\n<li><a href=\"https://github.com/elastic/dockerfiles/tree/v7.5.1/kibana\" target=\"_blank\" rel=\"noopener\">Kibana官方DockerFile</a></li>\n<li><a href=\"https://github.com/elastic/dockerfiles/tree/v7.5.1/logstash\" target=\"_blank\" rel=\"noopener\">Logstash官方DockerFile</a></li>\n</ul>\n<p><strong>Filebeat和Fluentd的非官方镜像</strong>：</p>\n<ul>\n<li>kasaoden/filebeat:7.2.0-arm64</li>\n<li>carlosedp/fluentd-elasticsearch:latest</li>\n</ul>\n","site":{"data":{}},"excerpt":"","more":"<h1 id=\"K8S集群日志收集方案\"><a href=\"#K8S集群日志收集方案\" class=\"headerlink\" title=\"K8S集群日志收集方案\"></a>K8S集群日志收集方案</h1><p>   在大型分布式部署的架构中，不同的服务模块部署在不同的服务器中，问题出现时，大部分情况需要根据问题暴露的关键信息定位具体的服务器和服务模块。常见的解决思路是建立一套集中式日志收集系统，将所有节点上的日志统一收集、管理、访问，将极大提高定位问题的效率。<br> 一个完整的集中式日志系统，需要包含以下几个主要特点：</p>\n<ul>\n<li>收集－能够采集多种来源的日志数据 </li>\n<li>传输－能够稳定的把日志数据传输到中央系统 </li>\n<li>存储－如何存储日志数据 </li>\n<li>分析－可以支持 UI 分析</li>\n<li>警告－能够提供错误报告，监控机制</li>\n</ul>\n<p>目前在K8S集群内部收集日志有以下几种方案<br>| 编号  | 方案 | 优点 | 缺点 |<br>|—-|—-|—-|—-|<br>| 1     |每个app的镜像中都集成日志收集组件  | 部署方便，kubernetes的yaml文件无须特别配置，可以为每个app自定义日志收集配置 | 强耦合，不方便应用和日志收集组件升级和维护且会导致镜像过大 |<br>| 2     | 单独创建一个日志收集组件跟app的容器一起运行在同一个pod中 |低耦合，扩展性强，方便维护和升级  | 需要对kubernetes的yaml文件进行单独配置，略显繁琐 |<br>| 3     | 将所有的Pod的日志都挂载到宿主机上，每台主机上单独起一个日志收集Pod | 完全解耦，性能最高，管理起来最方便 | 需要统一日志收集规则，目录和输出方式 |</p>\n<h2 id=\"方案一\"><a href=\"#方案一\" class=\"headerlink\" title=\"方案一\"></a>方案一</h2><p>基本不考虑</p>\n<h2 id=\"方案二\"><a href=\"#方案二\" class=\"headerlink\" title=\"方案二\"></a>方案二</h2><p><strong>方案二就是常见的ELK（Elasticsearch、Logstash、Kibana）+ Filebeat</strong>。引入了各类Lib Beats（Package Beat、Top Beat、File Beat等）运行在app应用的Pod中收集日志，转发给Logstash。此方案将手机端的Logstash替换为beats，更灵活，消耗资源更少，扩展性更强。同时可配置Logstash 和Elasticsearch 集群用于支持大集群系统的运维日志数据监控和查询。</p>\n<h3 id=\"简单介绍下ELK\"><a href=\"#简单介绍下ELK\" class=\"headerlink\" title=\"简单介绍下ELK\"></a>简单介绍下ELK</h3><p>Elasticsearch + Logstash + Kibana（ELK）是一套开源的日志管理方案</p>\n<ul>\n<li><p>Logstash：负责日志的收集，处理和储存</p>\n</li>\n<li><p>Elasticsearch：负责日志检索和分析</p>\n</li>\n<li><p>Kibana：负责日志的可视化<br><img src=\"https://img-blog.csdnimg.cn/20200103150908465.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0N1aV9DdWlfNjY2,size_16,color_FFFFFF,t_70\" alt=\"在这里插入图片描述\"><br><strong><em>Elasticsearch简介</em></strong><br>默认情况下，ES集群节点都是混合节点，即在elasticsearch.yml中默认node.master: true和node.data: true。当ES集群规模达到一定程度以后，就需要注意对集群节点进行角色划分。ES集群节点可以划分为三种：主节点、数据节点和客户端节点。</p>\n</li>\n<li><p><strong>master-主节点</strong>  维护元数据，管理集群节点状态；不负责数据写入和查询。elasticsearch.yml</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">node.master: true</span><br><span class=\"line\">node.data: false</span><br></pre></td></tr></table></figure>\n</li>\n<li><p><strong>data-数据节点</strong>  负责数据的写入与查询，压力大。elasticsearch.yml</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">node.master: false</span><br><span class=\"line\">node.data: true</span><br></pre></td></tr></table></figure>\n\n</li>\n</ul>\n<ul>\n<li><p><strong>data-客户端节点</strong>  负责任务分发和结果汇聚，分担数据节点压力。elasticsearch.yml</p>\n <figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">node.master: false</span><br><span class=\"line\">node.data: false</span><br></pre></td></tr></table></figure>\n</li>\n<li><p><strong>data-混合节点</strong>  综合上述三个节点的功能。elasticsearch.yml</p>\n <figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">node.master: true</span><br><span class=\"line\">node.data: true</span><br></pre></td></tr></table></figure>\n\n</li>\n</ul>\n<p><strong>Filebeat工作原理</strong><br>Filebeat由两个主要组件组成：prospectors 和 harvesters。这两个组件协同工作将文件变动发送到指定的输出中。<br><img src=\"https://img-blog.csdnimg.cn/20200103154511413.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0N1aV9DdWlfNjY2,size_16,color_FFFFFF,t_70\" alt=\"在这里插入图片描述\"><br><strong>Harvester（收割机）</strong>：负责读取单个文件内容。每个文件会启动一个Harvester，每个Harvester会逐行读取各个文件，并将文件内容发送到制定输出中。Harvester负责打开和关闭文件，意味在Harvester运行的时候，文件描述符处于打开状态，如果文件在收集中被重命名或者被删除，Filebeat会继续读取此文件。所以在Harvester关闭之前，磁盘不会被释放。默认情况filebeat会保持文件打开的状态，直到达到close_inactive（如果此选项开启，filebeat会在指定时间内将不再更新的文件句柄关闭，时间从harvester读取最后一行的时间开始计时。若文件句柄被关闭后，文件发生变化，则会启动一个新的harvester。关闭文件句柄的时间不取决于文件的修改时间，若此参数配置不当，则可能发生日志不实时的情况，由scan_frequency参数决定，默认10s。Harvester使用内部时间戳来记录文件最后被收集的时间。例如：设置5m，则在Harvester读取文件的最后一行之后，开始倒计时5分钟，若5分钟内文件无变化，则关闭文件句柄。默认5m）。</p>\n<p><strong>Prospector（勘测者）</strong>：负责管理Harvester并找到所有读取源。</p>\n<figure class=\"highlight yaml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"string\">filebeat.prospectors:</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"attr\">- input_type:</span> <span class=\"string\">log</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"attr\">  paths:</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"bullet\">    -</span> <span class=\"string\">/apps/logs/*/info.log</span></span><br></pre></td></tr></table></figure>\n\n<p>Prospector会找到/apps/logs/*目录下的所有info.log文件，并为每个文件启动一个Harvester。Prospector会检查每个文件，看Harvester是否已经启动，是否需要启动，或者文件是否可以忽略。若Harvester关闭，只有在文件大小发生变化的时候Prospector才会执行检查。只能检测本地的文件。</p>\n<p><strong>Filebeat如何记录文件状态</strong>：</p>\n<p>将文件状态记录在文件中（默认在/var/lib/filebeat/registry）。此状态可以记住Harvester收集文件的偏移量。若连接不上输出设备，如ES等，filebeat会记录发送前的最后一行，并再可以连接的时候继续发送。Filebeat在运行的时候，Prospector状态会被记录在内存中。Filebeat重启的时候，利用registry记录的状态来进行重建，用来还原到重启之前的状态。每个Prospector会为每个找到的文件记录一个状态，对于每个文件，Filebeat存储唯一标识符以检测文件是否先前被收集。</p>\n<p><strong>Filebeat如何保证事件至少被输出一次</strong>：</p>\n<p>Filebeat之所以能保证事件至少被传递到配置的输出一次，没有数据丢失，是因为filebeat将每个事件的传递状态保存在文件中。在未得到输出方确认时，filebeat会尝试一直发送，直到得到回应。若filebeat在传输过程中被关闭，则不会再关闭之前确认所有时事件。任何在filebeat关闭之前为确认的时间，都会在filebeat重启之后重新发送。这可确保至少发送一次，但有可能会重复。可通过设置shutdown_timeout 参数来设置关闭之前的等待事件回应的时间（默认禁用）。</p>\n<p><strong>Logstash工作原理</strong>：<br>Logstash事件处理有三个阶段：inputs → filters → outputs。是一个接收，处理，转发日志的工具。支持系统日志，webserver日志，错误日志，应用日志，总之包括所有可以抛出来的日志类型。<br><img src=\"https://img-blog.csdnimg.cn/20200103154804689.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0N1aV9DdWlfNjY2,size_16,color_FFFFFF,t_70\" alt=\"在这里插入图片描述\"><br><strong>Input：输入数据到logstash</strong>。</p>\n<p>一些常用的输入为：</p>\n<ul>\n<li><p>file：从文件系统的文件中读取，类似于tial -f命令</p>\n</li>\n<li><p>syslog：在514端口上监听系统日志消息，并根据RFC3164标准进行解析</p>\n</li>\n<li><p>redis：从redis service中读取</p>\n</li>\n<li><p>beats：从filebeat中读取</p>\n</li>\n<li><p>Filters：数据中间处理，对数据进行操作。</p>\n</li>\n</ul>\n<p>一些常用的过滤器为：</p>\n<ul>\n<li>grok：解析任意文本数据，Grok 是 Logstash 最重要的插件。它的主要作用就是将文本格式的字符串，转换成为具体的结构化的数据，配合正则表达式使用。内置120多个解析语法。</li>\n</ul>\n<p>官方提供的grok表达式：<a href=\"https://github.com/logstash-plugins/logstash-patterns-core/tree/master/patterns\" target=\"_blank\" rel=\"noopener\">https://github.com/logstash-plugins/logstash-patterns-core/tree/master/patterns</a><br>grok在线调试：<a href=\"https://grokdebug.herokuapp.com/\" target=\"_blank\" rel=\"noopener\">https://grokdebug.herokuapp.com/</a></p>\n<ul>\n<li><p>mutate：对字段进行转换。例如对字段进行删除、替换、修改、重命名等。</p>\n</li>\n<li><p>drop：丢弃一部分events不进行处理。</p>\n</li>\n<li><p>clone：拷贝 event，这个过程中也可以添加或移除字段。</p>\n</li>\n<li><p>geoip：添加地理信息(为前台kibana图形化展示使用)</p>\n</li>\n</ul>\n<p><strong>Outputs：outputs是logstash处理管道的最末端组件。</strong>一个event可以在处理过程中经过多重输出，但是一旦所有的outputs都执行结束，这个event也就完成生命周期。</p>\n<p>一些常见的outputs为：</p>\n<ul>\n<li><p>elasticsearch：可以高效的保存数据，并且能够方便和简单的进行查询。</p>\n</li>\n<li><p>file：将event数据保存到文件中。</p>\n</li>\n<li><p>graphite：将event数据发送到图形化组件中，一个很流行的开源存储图形化展示的组件。</p>\n</li>\n<li><p>Codecs：codecs 是基于数据流的过滤器，它可以作为input，output的一部分配置。Codecs可以帮助你轻松的分割发送过来已经被序列化的数据。</p>\n</li>\n</ul>\n<p>一些常见的codecs：</p>\n<ul>\n<li><p>json：使用json格式对数据进行编码/解码。</p>\n</li>\n<li><p>multiline：将汇多个事件中数据汇总为一个单一的行。比如：java异常信息和堆栈信息。</p>\n</li>\n</ul>\n<p><strong><em>为什么要在ELK基础上引入Lib Beats？</em></strong><br>在进行日志收集的过程中，我们首先想到的是使用Logstash，因为它是ELK stack中的重要成员，但是在测试过程中发现，Logstash是基于JDK的，在没有产生日志的情况单纯启动Logstash就大概要消耗500M内存，在每个Pod中都启动一个日志收集组件的情况下，使用logstash有点浪费系统资源，我们选择使用Filebeat替代，经测试单独启动Filebeat容器大约会消耗12M内存，比起logstash相当轻量级。<br><strong>Kibana简介</strong><br>Kibana通常与 Elasticsearch 一起部署，Kibana 是 Elasticsearch 的一个功能强大的数据可视化 Dashboard，Kibana 允许你通过 web 界面来浏览 Elasticsearch 日志数据。</p>\n<h2 id=\"方案三\"><a href=\"#方案三\" class=\"headerlink\" title=\"方案三\"></a>方案三</h2><p><strong>此方案就是K8S官方推荐的EFK（ELasticsearch、Fluentd、Kibana）方案</strong><br>此方案通过DaemonSet的方式在集群内部每个节点上运行一个Fluent Pod统一收集上层应用层的日志并反馈到Elasticsearch<br><img src=\"https://img-blog.csdnimg.cn/20200103155624399.jpg?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0N1aV9DdWlfNjY2,size_16,color_FFFFFF,t_70\" alt=\"在这里插入图片描述\"><br><strong>Fluentd简介</strong><br>Fluentd是一个Ruby语言开发的开源数据收集器，通过它能对数据进行统一收集和消费，能够更好地使用和理解数据。Fluentd将数据结构化为JSON，从而能够统一处理日志数据，包括：收集、过滤、缓存和输出。Fluentd是一个基于插件体系的架构，包括输入插件、输出插件、过滤插件、解析插件、格式化插件、缓存插件和存储插件，通过插件可以扩展和更好的使用Fluentd。</p>\n<p>Fluentd 通过一组给定的数据源抓取日志数据，处理后（转换成结构化的数据格式）将它们转发给其他服务，比如 Elasticsearch、对象存储等等。Fluentd 支持超过300个日志存储和分析服务，所以在这方面是非常灵活的。主要运行步骤如下：</p>\n<ul>\n<li>首先 Fluentd 从多个日志源获取数据</li>\n<li>结构化并且标记这些数据</li>\n<li>然后根据匹配的标签将数据发送到多个目标服务去<br><img src=\"https://img-blog.csdnimg.cn/202001031600510.jpg?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0N1aV9DdWlfNjY2,size_16,color_FFFFFF,t_70\" alt=\"在这里插入图片描述\"></li>\n</ul>\n<p><strong>Fluentd配置</strong><br>一般来说我们是通过一个配置文件来告诉 Fluentd 如何采集、处理数据的，下面简单和大家介绍下 Fluentd 的配置方法。<br><strong>日志源配置</strong><br>比如我们这里为了收集 Kubernetes 节点上的所有容器日志，就需要做如下的日志源配置：</p>\n<figure class=\"highlight ruby\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&lt;source&gt;</span><br><span class=\"line\"></span><br><span class=\"line\">@id fluentd-containers.log</span><br><span class=\"line\"></span><br><span class=\"line\">@type tail</span><br><span class=\"line\"></span><br><span class=\"line\">path /var/log/containers/*.log</span><br><span class=\"line\"></span><br><span class=\"line\">pos_file /var/log/fluentd-containers.log.pos</span><br><span class=\"line\"></span><br><span class=\"line\">time_format %Y-%m-%dT%<span class=\"symbol\">H:</span>%<span class=\"symbol\">M:</span>%S.%NZ</span><br><span class=\"line\"></span><br><span class=\"line\">tag raw.kubernetes.*</span><br><span class=\"line\"></span><br><span class=\"line\">format json</span><br><span class=\"line\"></span><br><span class=\"line\">read_from_head <span class=\"literal\">true</span></span><br><span class=\"line\"></span><br><span class=\"line\">&lt;<span class=\"regexp\">/source&gt;</span></span><br></pre></td></tr></table></figure>\n\n<p>上面配置部分参数说明如下：</p>\n<ul>\n<li>id：表示引用该日志源的唯一标识符，该标识可用于进一步过滤和路由结构化日志数据</li>\n<li>type：Fluentd 内置的指令，tail表示 Fluentd 从上次读取的位置通过 tail 不断获取数据，另外一个是http表示通过一个 GET 请求来收集数据。</li>\n<li>path：tail类型下的特定参数，告诉 Fluentd 采集/var/log/containers目录下的所有日志，这是 docker 在<br>Kubernetes 节点上用来存储运行容器 stdout 输出日志数据的目录。</li>\n<li>pos_file：检查点，如果 Fluentd 程序重新启动了，它将使用此文件中的位置来恢复日志数据收集。</li>\n<li>tag：用来将日志源与目标或者过滤器匹配的自定义字符串，Fluentd 匹配源/目标标签来路由日志数据。<br>路由配置</li>\n</ul>\n<p>上面是日志源的配置，接下来看看如何将日志数据发送到 Elasticsearch：</p>\n<figure class=\"highlight ruby\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&lt;match **&gt;</span><br><span class=\"line\"></span><br><span class=\"line\">@id elasticsearch</span><br><span class=\"line\"></span><br><span class=\"line\">@type elasticsearch</span><br><span class=\"line\"></span><br><span class=\"line\">@log_level info</span><br><span class=\"line\"></span><br><span class=\"line\">include_tag_key <span class=\"literal\">true</span></span><br><span class=\"line\"></span><br><span class=\"line\">type_name fluentd</span><br><span class=\"line\"></span><br><span class=\"line\">host <span class=\"string\">\"<span class=\"subst\">#&#123;ENV[<span class=\"string\">'OUTPUT_HOST'</span>]&#125;</span>\"</span></span><br><span class=\"line\"></span><br><span class=\"line\">port <span class=\"string\">\"<span class=\"subst\">#&#123;ENV[<span class=\"string\">'OUTPUT_PORT'</span>]&#125;</span>\"</span></span><br><span class=\"line\"></span><br><span class=\"line\">logstash_format <span class=\"literal\">true</span></span><br><span class=\"line\"></span><br><span class=\"line\">&lt;buffer&gt;</span><br><span class=\"line\"></span><br><span class=\"line\">@type file</span><br><span class=\"line\"></span><br><span class=\"line\">path /var/log/fluentd-buffers/kubernetes.system.buffer</span><br><span class=\"line\"></span><br><span class=\"line\">flush_mode interval</span><br><span class=\"line\"></span><br><span class=\"line\">retry_type exponential_backoff</span><br><span class=\"line\"></span><br><span class=\"line\">flush_thread_count <span class=\"number\">2</span></span><br><span class=\"line\"></span><br><span class=\"line\">flush_interval <span class=\"number\">5</span>s</span><br><span class=\"line\"></span><br><span class=\"line\">retry_forever</span><br><span class=\"line\"></span><br><span class=\"line\">retry_max_interval <span class=\"number\">30</span></span><br><span class=\"line\"></span><br><span class=\"line\">chunk_limit_size <span class=\"string\">\"<span class=\"subst\">#&#123;ENV[<span class=\"string\">'OUTPUT_BUFFER_CHUNK_LIMIT'</span>]&#125;</span>\"</span></span><br><span class=\"line\"></span><br><span class=\"line\">queue_limit_length <span class=\"string\">\"<span class=\"subst\">#&#123;ENV[<span class=\"string\">'OUTPUT_BUFFER_QUEUE_LIMIT'</span>]&#125;</span>\"</span></span><br><span class=\"line\"></span><br><span class=\"line\">overflow_action block</span><br><span class=\"line\"></span><br><span class=\"line\">&lt;<span class=\"regexp\">/buffer&gt;</span></span><br></pre></td></tr></table></figure>\n\n<ul>\n<li>match：标识一个目标标签，后面是一个匹配日志源的正则表达式，我们这里想要捕获所有的日志并将它们发送给 Elasticsearch，所以需要配置成**。</li>\n<li>id：目标的一个唯一标识符。</li>\n<li>type：支持的输出插件标识符，我们这里要输出到 Elasticsearch，所以配置成 elasticsearch，这是 Fluentd 的一个内置插件。</li>\n<li>log_level：指定要捕获的日志级别，我们这里配置成info，表示任何该级别或者该级别以上（INFO、WARNING、ERROR）的日志都将被路由到 Elsasticsearch。</li>\n<li>host/port：定义 Elasticsearch 的地址，也可以配置认证信息，我们的 Elasticsearch 不需要认证，所以这里直接指定 host 和 port 即可。</li>\n<li>logstash_format：Elasticsearch 服务对日志数据构建反向索引进行搜索，将 logstash_format 设置为true，Fluentd 将会以 logstash 格式来转发结构化的日志数据。</li>\n<li>Buffer： Fluentd 允许在目标不可用时进行缓存，比如，如果网络出现故障或者 Elasticsearch 不可用的时候。缓冲区配置也有助于降低磁盘的 IO。<h2 id=\"Docker-Image获取\"><a href=\"#Docker-Image获取\" class=\"headerlink\" title=\"Docker Image获取\"></a>Docker Image获取</h2>所需Docker image都可以从DockerHub或者<a href=\"https://console.cloud.google.com/projectselector2/gcr?supportedpurview=project\" target=\"_blank\" rel=\"noopener\">Google镜像仓库获取</a>获取</li>\n</ul>\n<p><strong>目前Elasticsearch、Logstash、Kibana、Filebeat以及Fluentd都没有官方的ARM64镜像</strong><br><strong>但是，Elasticsearch、Logstash、Kibana有提供DockerFile，另外，<em>此三组件镜像版本必须一致</em></strong></p>\n<ul>\n<li><a href=\"https://github.com/elastic/dockerfiles/tree/v7.5.1/elasticsearch\" target=\"_blank\" rel=\"noopener\">Elasticsearch官方DockerFile</a></li>\n<li><a href=\"https://github.com/elastic/dockerfiles/tree/v7.5.1/kibana\" target=\"_blank\" rel=\"noopener\">Kibana官方DockerFile</a></li>\n<li><a href=\"https://github.com/elastic/dockerfiles/tree/v7.5.1/logstash\" target=\"_blank\" rel=\"noopener\">Logstash官方DockerFile</a></li>\n</ul>\n<p><strong>Filebeat和Fluentd的非官方镜像</strong>：</p>\n<ul>\n<li>kasaoden/filebeat:7.2.0-arm64</li>\n<li>carlosedp/fluentd-elasticsearch:latest</li>\n</ul>\n"},{"title":"kubernetes中的Requests和Limits","_content":"\n在k8s的集群环境中，资源的合理分配和使用至关重要。毕竟容器化要解决的问题之一就是资源的充分利用。在集群中分配资源的时候就不得不提到Limits和Requests。\n# Namespace配额\n众所周知，Kubernetes 是允许管理员在命名空间中指定资源 Requests 和 Limits 的，这一特性对于资源管理限制非常有用。但它目前还存在一定局限：**如果管理员在命名空间中设置了 CPU  Requests 配额，那么所有 Pod 也要在其定义中设置 CPU  Requests，否则就无法被调配资源。**\n\n```yaml\napiVersion: v1\nkind: ResourceQuota\nmetadata:\n  name: mem-cpu-example\nspec:\n  hard:\n    requests.cpu: 4\n    requests.memory: 4Gi\n    limits.cpu: 6\n    limits.memory: 6Gi\n```\n这是一个简单的ResourceQuota类型，也就是针对Namespace的配额。它会针对Namespace做如下限额：\n\n - 所有 CPU Requests 的总和不能超过 4 个内核\n - 所有 RAM Requests 的总和不能超过 4GiB\n - 所有 CPU Limits 的总和不能超过 6个内核\n - 所有 RAM Limits 的总和不能超过 6GiB\n\n# 针对Pod的Request和Limit\n刚才讲到我们可以针对Pod进行资源限额，同样也可以设置Pod申请资源的Request和Limit。k8s中会将一个CPU分成1000个shares，这和Cgroup中分成1024略有差异。正常情况下requests的数值应该小于limits，那么该Pod获得的资源可以分为两部分：\n\n - 完全可靠的资源，资源量大小等于requests值\n - 不可靠的资源，资源量最大等于limits和requests的差额，这份不可靠的资源能够申请到多少，取决于当时主机上容器可用资源的余量。\n如下例：\n\n```yaml\nkind: Deployment\napiVersion: extensions/v1beta1\nmetadata:\n name: redis\n labels:\n   name: redis\n   app: redis-app\nspec:\n replicas: 2\n selector:\n   matchLabels:\n    name: redis\n    role: redisdb\n    app: redis-app\n template:\n   spec:\n     containers:\n       - name: redis\n         image: redis:5.0.3-alpine\n         resources:\n           limits:\n             memory: 500Mi\n             cpu: 1\n           requests:\n             memory: 250Mi\n             cpu: 500m\n       - name: busybox\n         image: busybox:1.28\n         resources:\n           limits:\n             memory: 100Mi\n             cpu: 100m\n           requests:\n             memory: 50Mi\n             cpu: 50m\n```\n\n - Pod 中共两个容器，的有效  Request  是 300MiB 的内存和 550 毫核（millicore）的 CPU。我们需要一个具有足够可用可分配空间的节点来调度 Pod\n - 如果 Redis 容器尝试分配超过 500MB 的 RAM，就会被 OOM-killer\n - 如果 Redis 容器尝试每 100ms 使用 100ms 以上的 CPU，那么 Redis 就会受到 CPU 限制（如果我们一共有 4 个内核，可用时间为 400ms/100ms），从而导致性能下降\n - 如果 busybox 容器尝试分配 100MB 以上的 RAM，也会引起 OOM\n - 如果 busybox 容器尝试每 100ms 使用 10ms 以上的 CPU，也会使 CPU 受到限制，从而导致性能下降\n需要注意的是，**Kubernetes 限制的是每个容器，而不是每个 Pod**。其他 CPU 指标，如共享 CPU 资源使用情况，只对分配有参考价值，所以如果遇到了性能上的问题，建议不要在这些指标上浪费时间。\n# Requests等于Limits 的时候\n一般情况下我们设置的Requests值一般都要小于Limits，但是也存在特殊情况。涉及到一个概念就是**服务质量等级**\n - **Guaranteed**（完全可靠的）；Limits==requests,或者只设置了Limits，此时默认requests等于limits\n - **Burstable**（弹性波动、较可靠的）；分为两种情况：1、Pod中一部分容器在一种或多种资源类型中配置了requests和limits，2、Pod中一部分容器未定义资源配置（requests和limits都未配置）\n - **BestEffort**（尽力而为、不太可靠的）；Pod所有中所有容器都未定义requests和limits\n\n**注意：在容器未定义limits时，limits值默认是节点资源容量的上限。**\n\n另外，**当我们分配CPU的requests和limits相等的时候，就是指该容器独占CPU，需要在kubelet服务的配置中增加`--cpu-manager-policy=static`**\n# 可压缩资源和不可压缩资源\n我们上文提到，在容器可使用的资源有CPU和内存。所以我们拓展一下k8s集群中的可压缩资源和不可压缩资源概念。\n在k8s中，**CPU就是可压缩资源**。空闲的CPU资源会按照容器的requests值得比例进行分配，举例说明：容器A requests1 limits 10；容器B requests2 limits 8，加入一开始该节点上可用CPU位3，那么两个容器恰好得到各自requests的量。此时节点又释放了1.5CPU，A和B都需要更多CPU资源，那么这1.5CPU就会按照A和B的requests量按比例分配，最后A得到1.5CPU，B得到3CPU。\n\n\n**目前，k8s支持的不可压缩资源是内存**。Pod中可以得到requests的内存量，如果Pod使用小于该值，那么Pod正常运行；如果Pod使用超过了该值极=就有可能被k8s杀掉。比如，Pod A使用了大于requests但是小于limits的内存，此时Pod B使用了小于requests的内存，但是Pod B中的程序突然压力增大，向k8s请求更多的但是不超过自己requests的内存资源，而节点上已没有空闲内存资源，这时候k8s就可能会直接kill Pod A。\n\n# 选择可靠的Requests和Limits\n具备一定 Kubernetes 经验的人都知道正确设置 Request 和 Limit 对于应用程序和集群的性能的重要性。\n\n理想情况下，Pod 请求多少资源，它就用多少资源，但在现实场景下，资源使用是不断变化的，而且它的变化没有规律，不可预测。\n\n如果 Pod 的资源使用量远低于请求量，那会导致资源（金钱）浪费；如果资源使用量高于请求量，那就会使节点出现性能问题。因此在实际操作中，我们可以把  Request 值上下浮动 25％ 作为一个良性参考标准。\n\n而关于 Limit，设置合理的 Limit 数值其实需要尝试，因为它主要取决于应用程序的性质、需求模型、对错误的容忍度以及许多其他因素，没有固定答案。\n![在这里插入图片描述](https://img-blog.csdnimg.cn/20200412200909653.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0N1aV9DdWlfNjY2,size_16,color_FFFFFF,t_70)\n**另一件需要考虑的事是在节点上允许的 Limits 过量使用。**\n![\n](https://img-blog.csdnimg.cn/20200412200932891.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0N1aV9DdWlfNjY2,size_16,color_FFFFFF,t_70)\n\n**这些 Limits 由用户执行，因为 Kubernetes 没有关于超额使用的自动化机制。**\n","source":"_posts/Kubernetes的Limits和Requests.md","raw":"---\ntitle: kubernetes中的Requests和Limits\ncategories: Kubernetes\n---\n\n在k8s的集群环境中，资源的合理分配和使用至关重要。毕竟容器化要解决的问题之一就是资源的充分利用。在集群中分配资源的时候就不得不提到Limits和Requests。\n# Namespace配额\n众所周知，Kubernetes 是允许管理员在命名空间中指定资源 Requests 和 Limits 的，这一特性对于资源管理限制非常有用。但它目前还存在一定局限：**如果管理员在命名空间中设置了 CPU  Requests 配额，那么所有 Pod 也要在其定义中设置 CPU  Requests，否则就无法被调配资源。**\n\n```yaml\napiVersion: v1\nkind: ResourceQuota\nmetadata:\n  name: mem-cpu-example\nspec:\n  hard:\n    requests.cpu: 4\n    requests.memory: 4Gi\n    limits.cpu: 6\n    limits.memory: 6Gi\n```\n这是一个简单的ResourceQuota类型，也就是针对Namespace的配额。它会针对Namespace做如下限额：\n\n - 所有 CPU Requests 的总和不能超过 4 个内核\n - 所有 RAM Requests 的总和不能超过 4GiB\n - 所有 CPU Limits 的总和不能超过 6个内核\n - 所有 RAM Limits 的总和不能超过 6GiB\n\n# 针对Pod的Request和Limit\n刚才讲到我们可以针对Pod进行资源限额，同样也可以设置Pod申请资源的Request和Limit。k8s中会将一个CPU分成1000个shares，这和Cgroup中分成1024略有差异。正常情况下requests的数值应该小于limits，那么该Pod获得的资源可以分为两部分：\n\n - 完全可靠的资源，资源量大小等于requests值\n - 不可靠的资源，资源量最大等于limits和requests的差额，这份不可靠的资源能够申请到多少，取决于当时主机上容器可用资源的余量。\n如下例：\n\n```yaml\nkind: Deployment\napiVersion: extensions/v1beta1\nmetadata:\n name: redis\n labels:\n   name: redis\n   app: redis-app\nspec:\n replicas: 2\n selector:\n   matchLabels:\n    name: redis\n    role: redisdb\n    app: redis-app\n template:\n   spec:\n     containers:\n       - name: redis\n         image: redis:5.0.3-alpine\n         resources:\n           limits:\n             memory: 500Mi\n             cpu: 1\n           requests:\n             memory: 250Mi\n             cpu: 500m\n       - name: busybox\n         image: busybox:1.28\n         resources:\n           limits:\n             memory: 100Mi\n             cpu: 100m\n           requests:\n             memory: 50Mi\n             cpu: 50m\n```\n\n - Pod 中共两个容器，的有效  Request  是 300MiB 的内存和 550 毫核（millicore）的 CPU。我们需要一个具有足够可用可分配空间的节点来调度 Pod\n - 如果 Redis 容器尝试分配超过 500MB 的 RAM，就会被 OOM-killer\n - 如果 Redis 容器尝试每 100ms 使用 100ms 以上的 CPU，那么 Redis 就会受到 CPU 限制（如果我们一共有 4 个内核，可用时间为 400ms/100ms），从而导致性能下降\n - 如果 busybox 容器尝试分配 100MB 以上的 RAM，也会引起 OOM\n - 如果 busybox 容器尝试每 100ms 使用 10ms 以上的 CPU，也会使 CPU 受到限制，从而导致性能下降\n需要注意的是，**Kubernetes 限制的是每个容器，而不是每个 Pod**。其他 CPU 指标，如共享 CPU 资源使用情况，只对分配有参考价值，所以如果遇到了性能上的问题，建议不要在这些指标上浪费时间。\n# Requests等于Limits 的时候\n一般情况下我们设置的Requests值一般都要小于Limits，但是也存在特殊情况。涉及到一个概念就是**服务质量等级**\n - **Guaranteed**（完全可靠的）；Limits==requests,或者只设置了Limits，此时默认requests等于limits\n - **Burstable**（弹性波动、较可靠的）；分为两种情况：1、Pod中一部分容器在一种或多种资源类型中配置了requests和limits，2、Pod中一部分容器未定义资源配置（requests和limits都未配置）\n - **BestEffort**（尽力而为、不太可靠的）；Pod所有中所有容器都未定义requests和limits\n\n**注意：在容器未定义limits时，limits值默认是节点资源容量的上限。**\n\n另外，**当我们分配CPU的requests和limits相等的时候，就是指该容器独占CPU，需要在kubelet服务的配置中增加`--cpu-manager-policy=static`**\n# 可压缩资源和不可压缩资源\n我们上文提到，在容器可使用的资源有CPU和内存。所以我们拓展一下k8s集群中的可压缩资源和不可压缩资源概念。\n在k8s中，**CPU就是可压缩资源**。空闲的CPU资源会按照容器的requests值得比例进行分配，举例说明：容器A requests1 limits 10；容器B requests2 limits 8，加入一开始该节点上可用CPU位3，那么两个容器恰好得到各自requests的量。此时节点又释放了1.5CPU，A和B都需要更多CPU资源，那么这1.5CPU就会按照A和B的requests量按比例分配，最后A得到1.5CPU，B得到3CPU。\n\n\n**目前，k8s支持的不可压缩资源是内存**。Pod中可以得到requests的内存量，如果Pod使用小于该值，那么Pod正常运行；如果Pod使用超过了该值极=就有可能被k8s杀掉。比如，Pod A使用了大于requests但是小于limits的内存，此时Pod B使用了小于requests的内存，但是Pod B中的程序突然压力增大，向k8s请求更多的但是不超过自己requests的内存资源，而节点上已没有空闲内存资源，这时候k8s就可能会直接kill Pod A。\n\n# 选择可靠的Requests和Limits\n具备一定 Kubernetes 经验的人都知道正确设置 Request 和 Limit 对于应用程序和集群的性能的重要性。\n\n理想情况下，Pod 请求多少资源，它就用多少资源，但在现实场景下，资源使用是不断变化的，而且它的变化没有规律，不可预测。\n\n如果 Pod 的资源使用量远低于请求量，那会导致资源（金钱）浪费；如果资源使用量高于请求量，那就会使节点出现性能问题。因此在实际操作中，我们可以把  Request 值上下浮动 25％ 作为一个良性参考标准。\n\n而关于 Limit，设置合理的 Limit 数值其实需要尝试，因为它主要取决于应用程序的性质、需求模型、对错误的容忍度以及许多其他因素，没有固定答案。\n![在这里插入图片描述](https://img-blog.csdnimg.cn/20200412200909653.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0N1aV9DdWlfNjY2,size_16,color_FFFFFF,t_70)\n**另一件需要考虑的事是在节点上允许的 Limits 过量使用。**\n![\n](https://img-blog.csdnimg.cn/20200412200932891.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0N1aV9DdWlfNjY2,size_16,color_FFFFFF,t_70)\n\n**这些 Limits 由用户执行，因为 Kubernetes 没有关于超额使用的自动化机制。**\n","slug":"Kubernetes的Limits和Requests","published":1,"date":"2020-04-12T12:11:47.684Z","updated":"2020-04-12T12:12:57.803Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck8x0luvd00072otv31bqe9qn","content":"<p>在k8s的集群环境中，资源的合理分配和使用至关重要。毕竟容器化要解决的问题之一就是资源的充分利用。在集群中分配资源的时候就不得不提到Limits和Requests。</p>\n<h1 id=\"Namespace配额\"><a href=\"#Namespace配额\" class=\"headerlink\" title=\"Namespace配额\"></a>Namespace配额</h1><p>众所周知，Kubernetes 是允许管理员在命名空间中指定资源 Requests 和 Limits 的，这一特性对于资源管理限制非常有用。但它目前还存在一定局限：<strong>如果管理员在命名空间中设置了 CPU  Requests 配额，那么所有 Pod 也要在其定义中设置 CPU  Requests，否则就无法被调配资源。</strong></p>\n<figure class=\"highlight yaml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"attr\">apiVersion:</span> <span class=\"string\">v1</span></span><br><span class=\"line\"><span class=\"attr\">kind:</span> <span class=\"string\">ResourceQuota</span></span><br><span class=\"line\"><span class=\"attr\">metadata:</span></span><br><span class=\"line\"><span class=\"attr\">  name:</span> <span class=\"string\">mem-cpu-example</span></span><br><span class=\"line\"><span class=\"attr\">spec:</span></span><br><span class=\"line\"><span class=\"attr\">  hard:</span></span><br><span class=\"line\">    <span class=\"string\">requests.cpu:</span> <span class=\"number\">4</span></span><br><span class=\"line\">    <span class=\"string\">requests.memory:</span> <span class=\"number\">4</span><span class=\"string\">Gi</span></span><br><span class=\"line\">    <span class=\"string\">limits.cpu:</span> <span class=\"number\">6</span></span><br><span class=\"line\">    <span class=\"string\">limits.memory:</span> <span class=\"number\">6</span><span class=\"string\">Gi</span></span><br></pre></td></tr></table></figure>\n\n<p>这是一个简单的ResourceQuota类型，也就是针对Namespace的配额。它会针对Namespace做如下限额：</p>\n<ul>\n<li>所有 CPU Requests 的总和不能超过 4 个内核</li>\n<li>所有 RAM Requests 的总和不能超过 4GiB</li>\n<li>所有 CPU Limits 的总和不能超过 6个内核</li>\n<li>所有 RAM Limits 的总和不能超过 6GiB</li>\n</ul>\n<h1 id=\"针对Pod的Request和Limit\"><a href=\"#针对Pod的Request和Limit\" class=\"headerlink\" title=\"针对Pod的Request和Limit\"></a>针对Pod的Request和Limit</h1><p>刚才讲到我们可以针对Pod进行资源限额，同样也可以设置Pod申请资源的Request和Limit。k8s中会将一个CPU分成1000个shares，这和Cgroup中分成1024略有差异。正常情况下requests的数值应该小于limits，那么该Pod获得的资源可以分为两部分：</p>\n<ul>\n<li>完全可靠的资源，资源量大小等于requests值</li>\n<li>不可靠的资源，资源量最大等于limits和requests的差额，这份不可靠的资源能够申请到多少，取决于当时主机上容器可用资源的余量。<br>如下例：</li>\n</ul>\n<figure class=\"highlight yaml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"attr\">kind:</span> <span class=\"string\">Deployment</span></span><br><span class=\"line\"><span class=\"attr\">apiVersion:</span> <span class=\"string\">extensions/v1beta1</span></span><br><span class=\"line\"><span class=\"attr\">metadata:</span></span><br><span class=\"line\"><span class=\"attr\"> name:</span> <span class=\"string\">redis</span></span><br><span class=\"line\"><span class=\"attr\"> labels:</span></span><br><span class=\"line\"><span class=\"attr\">   name:</span> <span class=\"string\">redis</span></span><br><span class=\"line\"><span class=\"attr\">   app:</span> <span class=\"string\">redis-app</span></span><br><span class=\"line\"><span class=\"attr\">spec:</span></span><br><span class=\"line\"><span class=\"attr\"> replicas:</span> <span class=\"number\">2</span></span><br><span class=\"line\"><span class=\"attr\"> selector:</span></span><br><span class=\"line\"><span class=\"attr\">   matchLabels:</span></span><br><span class=\"line\"><span class=\"attr\">    name:</span> <span class=\"string\">redis</span></span><br><span class=\"line\"><span class=\"attr\">    role:</span> <span class=\"string\">redisdb</span></span><br><span class=\"line\"><span class=\"attr\">    app:</span> <span class=\"string\">redis-app</span></span><br><span class=\"line\"><span class=\"attr\"> template:</span></span><br><span class=\"line\"><span class=\"attr\">   spec:</span></span><br><span class=\"line\"><span class=\"attr\">     containers:</span></span><br><span class=\"line\"><span class=\"attr\">       - name:</span> <span class=\"string\">redis</span></span><br><span class=\"line\"><span class=\"attr\">         image:</span> <span class=\"attr\">redis:5.0.3-alpine</span></span><br><span class=\"line\"><span class=\"attr\">         resources:</span></span><br><span class=\"line\"><span class=\"attr\">           limits:</span></span><br><span class=\"line\"><span class=\"attr\">             memory:</span> <span class=\"number\">500</span><span class=\"string\">Mi</span></span><br><span class=\"line\"><span class=\"attr\">             cpu:</span> <span class=\"number\">1</span></span><br><span class=\"line\"><span class=\"attr\">           requests:</span></span><br><span class=\"line\"><span class=\"attr\">             memory:</span> <span class=\"number\">250</span><span class=\"string\">Mi</span></span><br><span class=\"line\"><span class=\"attr\">             cpu:</span> <span class=\"number\">500</span><span class=\"string\">m</span></span><br><span class=\"line\"><span class=\"attr\">       - name:</span> <span class=\"string\">busybox</span></span><br><span class=\"line\"><span class=\"attr\">         image:</span> <span class=\"attr\">busybox:1.28</span></span><br><span class=\"line\"><span class=\"attr\">         resources:</span></span><br><span class=\"line\"><span class=\"attr\">           limits:</span></span><br><span class=\"line\"><span class=\"attr\">             memory:</span> <span class=\"number\">100</span><span class=\"string\">Mi</span></span><br><span class=\"line\"><span class=\"attr\">             cpu:</span> <span class=\"number\">100</span><span class=\"string\">m</span></span><br><span class=\"line\"><span class=\"attr\">           requests:</span></span><br><span class=\"line\"><span class=\"attr\">             memory:</span> <span class=\"number\">50</span><span class=\"string\">Mi</span></span><br><span class=\"line\"><span class=\"attr\">             cpu:</span> <span class=\"number\">50</span><span class=\"string\">m</span></span><br></pre></td></tr></table></figure>\n\n<ul>\n<li>Pod 中共两个容器，的有效  Request  是 300MiB 的内存和 550 毫核（millicore）的 CPU。我们需要一个具有足够可用可分配空间的节点来调度 Pod</li>\n<li>如果 Redis 容器尝试分配超过 500MB 的 RAM，就会被 OOM-killer</li>\n<li>如果 Redis 容器尝试每 100ms 使用 100ms 以上的 CPU，那么 Redis 就会受到 CPU 限制（如果我们一共有 4 个内核，可用时间为 400ms/100ms），从而导致性能下降</li>\n<li>如果 busybox 容器尝试分配 100MB 以上的 RAM，也会引起 OOM</li>\n<li>如果 busybox 容器尝试每 100ms 使用 10ms 以上的 CPU，也会使 CPU 受到限制，从而导致性能下降<br>需要注意的是，<strong>Kubernetes 限制的是每个容器，而不是每个 Pod</strong>。其他 CPU 指标，如共享 CPU 资源使用情况，只对分配有参考价值，所以如果遇到了性能上的问题，建议不要在这些指标上浪费时间。<h1 id=\"Requests等于Limits-的时候\"><a href=\"#Requests等于Limits-的时候\" class=\"headerlink\" title=\"Requests等于Limits 的时候\"></a>Requests等于Limits 的时候</h1>一般情况下我们设置的Requests值一般都要小于Limits，但是也存在特殊情况。涉及到一个概念就是<strong>服务质量等级</strong></li>\n<li><strong>Guaranteed</strong>（完全可靠的）；Limits==requests,或者只设置了Limits，此时默认requests等于limits</li>\n<li><strong>Burstable</strong>（弹性波动、较可靠的）；分为两种情况：1、Pod中一部分容器在一种或多种资源类型中配置了requests和limits，2、Pod中一部分容器未定义资源配置（requests和limits都未配置）</li>\n<li><strong>BestEffort</strong>（尽力而为、不太可靠的）；Pod所有中所有容器都未定义requests和limits</li>\n</ul>\n<p><strong>注意：在容器未定义limits时，limits值默认是节点资源容量的上限。</strong></p>\n<p>另外，<strong>当我们分配CPU的requests和limits相等的时候，就是指该容器独占CPU，需要在kubelet服务的配置中增加<code>--cpu-manager-policy=static</code></strong></p>\n<h1 id=\"可压缩资源和不可压缩资源\"><a href=\"#可压缩资源和不可压缩资源\" class=\"headerlink\" title=\"可压缩资源和不可压缩资源\"></a>可压缩资源和不可压缩资源</h1><p>我们上文提到，在容器可使用的资源有CPU和内存。所以我们拓展一下k8s集群中的可压缩资源和不可压缩资源概念。<br>在k8s中，<strong>CPU就是可压缩资源</strong>。空闲的CPU资源会按照容器的requests值得比例进行分配，举例说明：容器A requests1 limits 10；容器B requests2 limits 8，加入一开始该节点上可用CPU位3，那么两个容器恰好得到各自requests的量。此时节点又释放了1.5CPU，A和B都需要更多CPU资源，那么这1.5CPU就会按照A和B的requests量按比例分配，最后A得到1.5CPU，B得到3CPU。</p>\n<p><strong>目前，k8s支持的不可压缩资源是内存</strong>。Pod中可以得到requests的内存量，如果Pod使用小于该值，那么Pod正常运行；如果Pod使用超过了该值极=就有可能被k8s杀掉。比如，Pod A使用了大于requests但是小于limits的内存，此时Pod B使用了小于requests的内存，但是Pod B中的程序突然压力增大，向k8s请求更多的但是不超过自己requests的内存资源，而节点上已没有空闲内存资源，这时候k8s就可能会直接kill Pod A。</p>\n<h1 id=\"选择可靠的Requests和Limits\"><a href=\"#选择可靠的Requests和Limits\" class=\"headerlink\" title=\"选择可靠的Requests和Limits\"></a>选择可靠的Requests和Limits</h1><p>具备一定 Kubernetes 经验的人都知道正确设置 Request 和 Limit 对于应用程序和集群的性能的重要性。</p>\n<p>理想情况下，Pod 请求多少资源，它就用多少资源，但在现实场景下，资源使用是不断变化的，而且它的变化没有规律，不可预测。</p>\n<p>如果 Pod 的资源使用量远低于请求量，那会导致资源（金钱）浪费；如果资源使用量高于请求量，那就会使节点出现性能问题。因此在实际操作中，我们可以把  Request 值上下浮动 25％ 作为一个良性参考标准。</p>\n<p>而关于 Limit，设置合理的 Limit 数值其实需要尝试，因为它主要取决于应用程序的性质、需求模型、对错误的容忍度以及许多其他因素，没有固定答案。<br><img src=\"https://img-blog.csdnimg.cn/20200412200909653.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0N1aV9DdWlfNjY2,size_16,color_FFFFFF,t_70\" alt=\"在这里插入图片描述\"><br><strong>另一件需要考虑的事是在节点上允许的 Limits 过量使用。</strong><br><img src=\"https://img-blog.csdnimg.cn/20200412200932891.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0N1aV9DdWlfNjY2,size_16,color_FFFFFF,t_70\" alt=\"\n\"></p>\n<p><strong>这些 Limits 由用户执行，因为 Kubernetes 没有关于超额使用的自动化机制。</strong></p>\n","site":{"data":{}},"excerpt":"","more":"<p>在k8s的集群环境中，资源的合理分配和使用至关重要。毕竟容器化要解决的问题之一就是资源的充分利用。在集群中分配资源的时候就不得不提到Limits和Requests。</p>\n<h1 id=\"Namespace配额\"><a href=\"#Namespace配额\" class=\"headerlink\" title=\"Namespace配额\"></a>Namespace配额</h1><p>众所周知，Kubernetes 是允许管理员在命名空间中指定资源 Requests 和 Limits 的，这一特性对于资源管理限制非常有用。但它目前还存在一定局限：<strong>如果管理员在命名空间中设置了 CPU  Requests 配额，那么所有 Pod 也要在其定义中设置 CPU  Requests，否则就无法被调配资源。</strong></p>\n<figure class=\"highlight yaml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"attr\">apiVersion:</span> <span class=\"string\">v1</span></span><br><span class=\"line\"><span class=\"attr\">kind:</span> <span class=\"string\">ResourceQuota</span></span><br><span class=\"line\"><span class=\"attr\">metadata:</span></span><br><span class=\"line\"><span class=\"attr\">  name:</span> <span class=\"string\">mem-cpu-example</span></span><br><span class=\"line\"><span class=\"attr\">spec:</span></span><br><span class=\"line\"><span class=\"attr\">  hard:</span></span><br><span class=\"line\">    <span class=\"string\">requests.cpu:</span> <span class=\"number\">4</span></span><br><span class=\"line\">    <span class=\"string\">requests.memory:</span> <span class=\"number\">4</span><span class=\"string\">Gi</span></span><br><span class=\"line\">    <span class=\"string\">limits.cpu:</span> <span class=\"number\">6</span></span><br><span class=\"line\">    <span class=\"string\">limits.memory:</span> <span class=\"number\">6</span><span class=\"string\">Gi</span></span><br></pre></td></tr></table></figure>\n\n<p>这是一个简单的ResourceQuota类型，也就是针对Namespace的配额。它会针对Namespace做如下限额：</p>\n<ul>\n<li>所有 CPU Requests 的总和不能超过 4 个内核</li>\n<li>所有 RAM Requests 的总和不能超过 4GiB</li>\n<li>所有 CPU Limits 的总和不能超过 6个内核</li>\n<li>所有 RAM Limits 的总和不能超过 6GiB</li>\n</ul>\n<h1 id=\"针对Pod的Request和Limit\"><a href=\"#针对Pod的Request和Limit\" class=\"headerlink\" title=\"针对Pod的Request和Limit\"></a>针对Pod的Request和Limit</h1><p>刚才讲到我们可以针对Pod进行资源限额，同样也可以设置Pod申请资源的Request和Limit。k8s中会将一个CPU分成1000个shares，这和Cgroup中分成1024略有差异。正常情况下requests的数值应该小于limits，那么该Pod获得的资源可以分为两部分：</p>\n<ul>\n<li>完全可靠的资源，资源量大小等于requests值</li>\n<li>不可靠的资源，资源量最大等于limits和requests的差额，这份不可靠的资源能够申请到多少，取决于当时主机上容器可用资源的余量。<br>如下例：</li>\n</ul>\n<figure class=\"highlight yaml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"attr\">kind:</span> <span class=\"string\">Deployment</span></span><br><span class=\"line\"><span class=\"attr\">apiVersion:</span> <span class=\"string\">extensions/v1beta1</span></span><br><span class=\"line\"><span class=\"attr\">metadata:</span></span><br><span class=\"line\"><span class=\"attr\"> name:</span> <span class=\"string\">redis</span></span><br><span class=\"line\"><span class=\"attr\"> labels:</span></span><br><span class=\"line\"><span class=\"attr\">   name:</span> <span class=\"string\">redis</span></span><br><span class=\"line\"><span class=\"attr\">   app:</span> <span class=\"string\">redis-app</span></span><br><span class=\"line\"><span class=\"attr\">spec:</span></span><br><span class=\"line\"><span class=\"attr\"> replicas:</span> <span class=\"number\">2</span></span><br><span class=\"line\"><span class=\"attr\"> selector:</span></span><br><span class=\"line\"><span class=\"attr\">   matchLabels:</span></span><br><span class=\"line\"><span class=\"attr\">    name:</span> <span class=\"string\">redis</span></span><br><span class=\"line\"><span class=\"attr\">    role:</span> <span class=\"string\">redisdb</span></span><br><span class=\"line\"><span class=\"attr\">    app:</span> <span class=\"string\">redis-app</span></span><br><span class=\"line\"><span class=\"attr\"> template:</span></span><br><span class=\"line\"><span class=\"attr\">   spec:</span></span><br><span class=\"line\"><span class=\"attr\">     containers:</span></span><br><span class=\"line\"><span class=\"attr\">       - name:</span> <span class=\"string\">redis</span></span><br><span class=\"line\"><span class=\"attr\">         image:</span> <span class=\"attr\">redis:5.0.3-alpine</span></span><br><span class=\"line\"><span class=\"attr\">         resources:</span></span><br><span class=\"line\"><span class=\"attr\">           limits:</span></span><br><span class=\"line\"><span class=\"attr\">             memory:</span> <span class=\"number\">500</span><span class=\"string\">Mi</span></span><br><span class=\"line\"><span class=\"attr\">             cpu:</span> <span class=\"number\">1</span></span><br><span class=\"line\"><span class=\"attr\">           requests:</span></span><br><span class=\"line\"><span class=\"attr\">             memory:</span> <span class=\"number\">250</span><span class=\"string\">Mi</span></span><br><span class=\"line\"><span class=\"attr\">             cpu:</span> <span class=\"number\">500</span><span class=\"string\">m</span></span><br><span class=\"line\"><span class=\"attr\">       - name:</span> <span class=\"string\">busybox</span></span><br><span class=\"line\"><span class=\"attr\">         image:</span> <span class=\"attr\">busybox:1.28</span></span><br><span class=\"line\"><span class=\"attr\">         resources:</span></span><br><span class=\"line\"><span class=\"attr\">           limits:</span></span><br><span class=\"line\"><span class=\"attr\">             memory:</span> <span class=\"number\">100</span><span class=\"string\">Mi</span></span><br><span class=\"line\"><span class=\"attr\">             cpu:</span> <span class=\"number\">100</span><span class=\"string\">m</span></span><br><span class=\"line\"><span class=\"attr\">           requests:</span></span><br><span class=\"line\"><span class=\"attr\">             memory:</span> <span class=\"number\">50</span><span class=\"string\">Mi</span></span><br><span class=\"line\"><span class=\"attr\">             cpu:</span> <span class=\"number\">50</span><span class=\"string\">m</span></span><br></pre></td></tr></table></figure>\n\n<ul>\n<li>Pod 中共两个容器，的有效  Request  是 300MiB 的内存和 550 毫核（millicore）的 CPU。我们需要一个具有足够可用可分配空间的节点来调度 Pod</li>\n<li>如果 Redis 容器尝试分配超过 500MB 的 RAM，就会被 OOM-killer</li>\n<li>如果 Redis 容器尝试每 100ms 使用 100ms 以上的 CPU，那么 Redis 就会受到 CPU 限制（如果我们一共有 4 个内核，可用时间为 400ms/100ms），从而导致性能下降</li>\n<li>如果 busybox 容器尝试分配 100MB 以上的 RAM，也会引起 OOM</li>\n<li>如果 busybox 容器尝试每 100ms 使用 10ms 以上的 CPU，也会使 CPU 受到限制，从而导致性能下降<br>需要注意的是，<strong>Kubernetes 限制的是每个容器，而不是每个 Pod</strong>。其他 CPU 指标，如共享 CPU 资源使用情况，只对分配有参考价值，所以如果遇到了性能上的问题，建议不要在这些指标上浪费时间。<h1 id=\"Requests等于Limits-的时候\"><a href=\"#Requests等于Limits-的时候\" class=\"headerlink\" title=\"Requests等于Limits 的时候\"></a>Requests等于Limits 的时候</h1>一般情况下我们设置的Requests值一般都要小于Limits，但是也存在特殊情况。涉及到一个概念就是<strong>服务质量等级</strong></li>\n<li><strong>Guaranteed</strong>（完全可靠的）；Limits==requests,或者只设置了Limits，此时默认requests等于limits</li>\n<li><strong>Burstable</strong>（弹性波动、较可靠的）；分为两种情况：1、Pod中一部分容器在一种或多种资源类型中配置了requests和limits，2、Pod中一部分容器未定义资源配置（requests和limits都未配置）</li>\n<li><strong>BestEffort</strong>（尽力而为、不太可靠的）；Pod所有中所有容器都未定义requests和limits</li>\n</ul>\n<p><strong>注意：在容器未定义limits时，limits值默认是节点资源容量的上限。</strong></p>\n<p>另外，<strong>当我们分配CPU的requests和limits相等的时候，就是指该容器独占CPU，需要在kubelet服务的配置中增加<code>--cpu-manager-policy=static</code></strong></p>\n<h1 id=\"可压缩资源和不可压缩资源\"><a href=\"#可压缩资源和不可压缩资源\" class=\"headerlink\" title=\"可压缩资源和不可压缩资源\"></a>可压缩资源和不可压缩资源</h1><p>我们上文提到，在容器可使用的资源有CPU和内存。所以我们拓展一下k8s集群中的可压缩资源和不可压缩资源概念。<br>在k8s中，<strong>CPU就是可压缩资源</strong>。空闲的CPU资源会按照容器的requests值得比例进行分配，举例说明：容器A requests1 limits 10；容器B requests2 limits 8，加入一开始该节点上可用CPU位3，那么两个容器恰好得到各自requests的量。此时节点又释放了1.5CPU，A和B都需要更多CPU资源，那么这1.5CPU就会按照A和B的requests量按比例分配，最后A得到1.5CPU，B得到3CPU。</p>\n<p><strong>目前，k8s支持的不可压缩资源是内存</strong>。Pod中可以得到requests的内存量，如果Pod使用小于该值，那么Pod正常运行；如果Pod使用超过了该值极=就有可能被k8s杀掉。比如，Pod A使用了大于requests但是小于limits的内存，此时Pod B使用了小于requests的内存，但是Pod B中的程序突然压力增大，向k8s请求更多的但是不超过自己requests的内存资源，而节点上已没有空闲内存资源，这时候k8s就可能会直接kill Pod A。</p>\n<h1 id=\"选择可靠的Requests和Limits\"><a href=\"#选择可靠的Requests和Limits\" class=\"headerlink\" title=\"选择可靠的Requests和Limits\"></a>选择可靠的Requests和Limits</h1><p>具备一定 Kubernetes 经验的人都知道正确设置 Request 和 Limit 对于应用程序和集群的性能的重要性。</p>\n<p>理想情况下，Pod 请求多少资源，它就用多少资源，但在现实场景下，资源使用是不断变化的，而且它的变化没有规律，不可预测。</p>\n<p>如果 Pod 的资源使用量远低于请求量，那会导致资源（金钱）浪费；如果资源使用量高于请求量，那就会使节点出现性能问题。因此在实际操作中，我们可以把  Request 值上下浮动 25％ 作为一个良性参考标准。</p>\n<p>而关于 Limit，设置合理的 Limit 数值其实需要尝试，因为它主要取决于应用程序的性质、需求模型、对错误的容忍度以及许多其他因素，没有固定答案。<br><img src=\"https://img-blog.csdnimg.cn/20200412200909653.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0N1aV9DdWlfNjY2,size_16,color_FFFFFF,t_70\" alt=\"在这里插入图片描述\"><br><strong>另一件需要考虑的事是在节点上允许的 Limits 过量使用。</strong><br><img src=\"https://img-blog.csdnimg.cn/20200412200932891.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0N1aV9DdWlfNjY2,size_16,color_FFFFFF,t_70\" alt=\"\n\"></p>\n<p><strong>这些 Limits 由用户执行，因为 Kubernetes 没有关于超额使用的自动化机制。</strong></p>\n"},{"title":"k8s集群部署Calico踩坑","_content":"\n## 部署注意事项\n在使用 Calico 前当然最好撸一下官方文档，地址在这里 [Calico 官方文档](https://www.projectcalico.org/)，其中部署前需要注意以下几点\n\n 1. 官方文档中要求 kubelet 配置必须增加 --network-plugin=cni 选项\n 3. kubec-proxy 组件不能采用 --masquerade-all 启动，因为会与 Calico policy 冲突\n 4. 启用 RBAC 后需要设置对应的 RoleBinding，参考 官方文档 RBAC 部分\n<!--more-->\n关于在k8s集群中部署calico所用yaml有两个，不同点在于是使用Kubernetes API datastore还是etcd.使用etcd的calico文件在[这里](https://docs.projectcalico.org/v3.8/manifests/calico-etcd.yaml)\n## Calico 官方部署方式\n在已经有了一个 Kubernetes 集群的情况下，官方部署方式描述的很简单，只需要改一改 yml 配置，然后 create 一下即可，具体描述见 [官方文档](https://docs.projectcalico.org/v3.8/getting-started/kubernetes/)\n但是，如果我们有使用证书的话，需要对calico的yaml文件做如下修改\n\n```\nsed -i 's@.*etcd_endpoints:.*@\\ \\ etcd_endpoints:\\ \\\"https://192.168.168.2:2379,https://192.168.168.3:2379,https://192.168.168.4:2379\\\"@gi' calico.yaml\n \n### 替换 Etcd 证书\nexport ETCD_CERT=`cat /opt/kubernetes/ssl/etcd.pem | base64 | tr -d '\\n'`\nexport ETCD_KEY=`cat /opt/kubernetes/ssl/etcd-key.pem | base64 | tr -d '\\n'`\nexport ETCD_CA=`cat /opt/kubernetes/ssl/ca.pem | base64 | tr -d '\\n'`\n \nsed -i \"s@.*etcd-cert:.*@\\ \\ etcd-cert:\\ ${ETCD_CERT}@gi\" calico.yaml\nsed -i \"s@.*etcd-key:.*@\\ \\ etcd-key:\\ ${ETCD_KEY}@gi\" calico.yaml\nsed -i \"s@.*etcd-ca:.*@\\ \\ etcd-ca:\\ ${ETCD_CA}@gi\" calico.yaml\n \nsed -i 's@.*etcd_ca:.*@\\ \\ etcd_ca:\\ \"/calico-secrets/etcd-ca\"@gi' calico.yaml\nsed -i 's@.*etcd_cert:.*@\\ \\ etcd_cert:\\ \"/calico-secrets/etcd-cert\"@gi' calico.yaml\nsed -i 's@.*etcd_key:.*@\\ \\ etcd_key:\\ \"/calico-secrets/etcd-key\"@gi' calico.yaml\n \n### 替换 IPPOOL 地址\nsed -i 's/192.168.0.0/10.2.0.0/g' calico.yaml\n```\n## Standard Hosted Install 的坑\n**由于我的k8s集群各节点存在多网卡，不同子网。结果出现的问题是个别 Calico 节点无法启动，同时创建 deployment 后，执行 route -n 会发现每个 node 只有自己节点 Pod 的路由，正常每个 node 上会有所有 node 上 Pod 网段的路由**。官方文档中直接创建的 calico.yml 文件中，使用 DaemonSet 方式启动 calico-node，同时 calico-node 的 IP 设置和 NODENAME 设置均为空，此时 calico-node 会进行自动获取，网络复杂情况下获取会出现问题；比如 IP 拿到了 不同网卡的 IP，NODENAME 获取不正确等，最终导致出现很奇怪的错误。\n\n解决方法也很简单。直接修改calico的yaml文件即可。有些博客会推荐大家使用service来启动calico node。实在是多此一举。**因为我们在启动pod内的容器时可以获取到当前k8s节点和pod的一些物理信息的，比如ip、hostname等等。** 具体文档可以参考[这里](https://kubernetes.io/zh/docs/tasks/inject-data-application/environment-variable-expose-pod-information/) 所以我们可以修改calico yaml文件如下：\n**我们分别使用k8s节点的ip作为calico node容器内的IP和NODENAME信息。** 防止name重复和自动获取所用的ip地址不在同一网段。\n```\n# Source: calico/templates/calico-node.yaml\n# This manifest installs the calico-node container, as well\n# as the CNI plugins and network config on\n# each master and worker node in a Kubernetes cluster.\nkind: DaemonSet\napiVersion: apps/v1\nmetadata:\n  name: calico-node\n  namespace: kube-system\n  labels:\n    k8s-app: calico-node\nspec:\n  selector:\n    matchLabels:\n      k8s-app: calico-node\n  updateStrategy:\n    type: RollingUpdate\n    rollingUpdate:\n      maxUnavailable: 1\n  template:\n    metadata:\n      labels:\n        k8s-app: calico-node\n      annotations:\n        # This, along with the CriticalAddonsOnly toleration below,\n        # marks the pod as a critical add-on, ensuring it gets\n        # priority scheduling and that its resources are reserved\n        # if it ever gets evicted.\n        scheduler.alpha.kubernetes.io/critical-pod: ''\n    spec:\n      nodeSelector:\n        beta.kubernetes.io/os: linux\n      hostNetwork: true\n      tolerations:\n        # Make sure calico-node gets scheduled on all nodes.\n        - effect: NoSchedule\n          operator: Exists\n        # Mark the pod as a critical add-on for rescheduling.\n        - key: CriticalAddonsOnly\n          operator: Exists\n        - effect: NoExecute\n          operator: Exists\n      serviceAccountName: calico-node\n      # Minimize downtime during a rolling upgrade or deletion; tell Kubernetes to do a \"force\n      # deletion\": https://kubernetes.io/docs/concepts/workloads/pods/pod/#termination-of-pods.\n      terminationGracePeriodSeconds: 0\n      priorityClassName: system-node-critical\n      initContainers:\n        # This container installs the CNI binaries\n        # and CNI network config file on each node.\n        - name: install-cni\n          image: calico/cni:v3.8.2\n          command: [\"/install-cni.sh\"]\n          env:\n            # Name of the CNI config file to create.\n            - name: CNI_CONF_NAME\n              value: \"10-calico.conflist\"\n            # The CNI network config to install on each node.\n            - name: CNI_NETWORK_CONFIG\n              valueFrom:\n                configMapKeyRef:\n                  name: calico-config\n                  key: cni_network_config\n            # The location of the etcd cluster.\n            - name: ETCD_ENDPOINTS\n              valueFrom:\n                configMapKeyRef:\n                  name: calico-config\n                  key: etcd_endpoints\n            # CNI MTU Config variable\n            - name: CNI_MTU\n              valueFrom:\n                configMapKeyRef:\n                  name: calico-config\n                  key: veth_mtu\n            # Prevents the container from sleeping forever.\n            - name: SLEEP\n              value: \"false\"\n          volumeMounts:\n            - mountPath: /host/opt/cni/bin\n              name: cni-bin-dir\n            - mountPath: /host/etc/cni/net.d\n              name: cni-net-dir\n            - mountPath: /calico-secrets\n              name: etcd-certs\n        # Adds a Flex Volume Driver that creates a per-pod Unix Domain Socket to allow Dikastes\n        # to communicate with Felix over the Policy Sync API.\n        - name: flexvol-driver\n          image: calico/pod2daemon-flexvol:v3.8.2\n          volumeMounts:\n          - name: flexvol-driver-host\n            mountPath: /host/driver\n      containers:\n        # Runs calico-node container on each Kubernetes node.  This\n        # container programs network policy and routes on each\n        # host.\n        - name: calico-node\n          image: calico/node:v3.8.2\n          env:\n            # The location of the etcd cluster.\n            - name: ETCD_ENDPOINTS\n              valueFrom:\n                configMapKeyRef:\n                  name: calico-config\n                  key: etcd_endpoints\n            # Location of the CA certificate for etcd.\n            - name: ETCD_CA_CERT_FILE\n              valueFrom:\n                configMapKeyRef:\n                  name: calico-config\n                  key: etcd_ca\n            # Location of the client key for etcd.\n            - name: ETCD_KEY_FILE\n              valueFrom:\n                configMapKeyRef:\n                  name: calico-config\n                  key: etcd_key\n            # Location of the client certificate for etcd.\n            - name: ETCD_CERT_FILE\n              valueFrom:\n                configMapKeyRef:\n                  name: calico-config\n                  key: etcd_cert\n            # Set noderef for node controller.\n            - name: CALICO_K8S_NODE_REF\n              valueFrom:\n                fieldRef:\n                  fieldPath: spec.nodeName\n            # Choose the backend to use.\n            - name: CALICO_NETWORKING_BACKEND\n              valueFrom:\n                configMapKeyRef:\n                  name: calico-config\n                  key: calico_backend\n            # Cluster type to identify the deployment type\n            - name: CLUSTER_TYPE\n              value: \"k8s,bgp\"\n            # Auto-detect the BGP IP address.\n            - name: IP\n              valueFrom:\n                fieldRef:\n                  fieldPath: status.hostIP\n            # Enable IPIP\n            - name: CALICO_IPV4POOL_IPIP\n              value: \"Always\"\n            # Set MTU for tunnel device used if ipip is enabled\n            - name: FELIX_IPINIPMTU\n              valueFrom:\n                configMapKeyRef:\n                  name: calico-config\n                  key: veth_mtu\n            # The default IPv4 pool to create on startup if none exists. Pod IPs will be\n            # chosen from this range. Changing this value after installation will have\n            # no effect. This should fall within `--cluster-cidr`.\n            - name: CALICO_IPV4POOL_CIDR\n              value: \"192.168.0.0/16\"\n            # Disable file logging so `kubectl logs` works.\n            - name: CALICO_DISABLE_FILE_LOGGING\n              value: \"true\"\n            # Set Felix endpoint to host default action to ACCEPT.\n            - name: FELIX_DEFAULTENDPOINTTOHOSTACTION\n              value: \"ACCEPT\"\n            # Disable IPv6 on Kubernetes.\n            - name: FELIX_IPV6SUPPORT\n              value: \"false\"\n            # Set Felix logging to \"info\"\n            - name: FELIX_LOGSEVERITYSCREEN\n              value: \"info\"\n            - name: FELIX_HEALTHENABLED\n              value: \"true\"\n            #  set calico node name\n            - name: NODENAME\n              valueFrom:\n                fieldRef:\n                  fieldPath: status.hostIP\n          securityContext:\n            privileged: true\n          resources:\n            requests:\n              cpu: 250m\n          livenessProbe:\n            httpGet:\n              path: /liveness\n              port: 9099\n              host: localhost\n            periodSeconds: 10\n            initialDelaySeconds: 10\n            failureThreshold: 6\n          readinessProbe:\n            exec:\n              command:\n              - /bin/calico-node\n              - -bird-ready\n              - -felix-ready\n            periodSeconds: 10\n          volumeMounts:\n            - mountPath: /lib/modules\n              name: lib-modules\n              readOnly: true\n            - mountPath: /run/xtables.lock\n              name: xtables-lock\n              readOnly: false\n            - mountPath: /var/run/calico\n              name: var-run-calico\n              readOnly: false\n            - mountPath: /var/lib/calico\n              name: var-lib-calico\n              readOnly: false\n            - mountPath: /calico-secrets\n              name: etcd-certs\n            - name: policysync\n              mountPath: /var/run/nodeagent\n      volumes:\n        # Used by calico-node.\n        - name: lib-modules\n          hostPath:\n            path: /lib/modules\n        - name: var-run-calico\n          hostPath:\n            path: /var/run/calico\n        - name: var-lib-calico\n          hostPath:\n            path: /var/lib/calico\n        - name: xtables-lock\n          hostPath:\n            path: /run/xtables.lock\n            type: FileOrCreate\n        # Used to install CNI.\n        - name: cni-bin-dir\n          hostPath:\n            path: /opt/cni/bin\n        - name: cni-net-dir\n          hostPath:\n            path: /etc/cni/net.d\n        # Mount in the etcd TLS secrets with mode 400.\n        # See https://kubernetes.io/docs/concepts/configuration/secret/\n        - name: etcd-certs\n          secret:\n            secretName: calico-etcd-secrets\n            defaultMode: 0400\n        # Used to create per-pod Unix Domain Sockets\n        - name: policysync\n          hostPath:\n            type: DirectoryOrCreate\n            path: /var/run/nodeagent\n        # Used to install Flex Volume Driver\n        - name: flexvol-driver-host\n          hostPath:\n            type: DirectoryOrCreate\n            path: /usr/libexec/kubernetes/kubelet-plugins/volume/exec/nodeagent~uds\n```\n## 关于在集群中使用keepalived挂载VIP后NodePort无法通过VIP访问的问题\n\n**目前由于kube-proxy的代理mode使用的是ipvs，已经取代了之前的iptables，导致目前该问题还无法解决。如果切换到iptables就可以了。**\n","source":"_posts/k8s集群中部署Calico踩坑笔记.md","raw":"---\ntitle: k8s集群部署Calico踩坑\ncategories: Kubernetes\n---\n\n## 部署注意事项\n在使用 Calico 前当然最好撸一下官方文档，地址在这里 [Calico 官方文档](https://www.projectcalico.org/)，其中部署前需要注意以下几点\n\n 1. 官方文档中要求 kubelet 配置必须增加 --network-plugin=cni 选项\n 3. kubec-proxy 组件不能采用 --masquerade-all 启动，因为会与 Calico policy 冲突\n 4. 启用 RBAC 后需要设置对应的 RoleBinding，参考 官方文档 RBAC 部分\n<!--more-->\n关于在k8s集群中部署calico所用yaml有两个，不同点在于是使用Kubernetes API datastore还是etcd.使用etcd的calico文件在[这里](https://docs.projectcalico.org/v3.8/manifests/calico-etcd.yaml)\n## Calico 官方部署方式\n在已经有了一个 Kubernetes 集群的情况下，官方部署方式描述的很简单，只需要改一改 yml 配置，然后 create 一下即可，具体描述见 [官方文档](https://docs.projectcalico.org/v3.8/getting-started/kubernetes/)\n但是，如果我们有使用证书的话，需要对calico的yaml文件做如下修改\n\n```\nsed -i 's@.*etcd_endpoints:.*@\\ \\ etcd_endpoints:\\ \\\"https://192.168.168.2:2379,https://192.168.168.3:2379,https://192.168.168.4:2379\\\"@gi' calico.yaml\n \n### 替换 Etcd 证书\nexport ETCD_CERT=`cat /opt/kubernetes/ssl/etcd.pem | base64 | tr -d '\\n'`\nexport ETCD_KEY=`cat /opt/kubernetes/ssl/etcd-key.pem | base64 | tr -d '\\n'`\nexport ETCD_CA=`cat /opt/kubernetes/ssl/ca.pem | base64 | tr -d '\\n'`\n \nsed -i \"s@.*etcd-cert:.*@\\ \\ etcd-cert:\\ ${ETCD_CERT}@gi\" calico.yaml\nsed -i \"s@.*etcd-key:.*@\\ \\ etcd-key:\\ ${ETCD_KEY}@gi\" calico.yaml\nsed -i \"s@.*etcd-ca:.*@\\ \\ etcd-ca:\\ ${ETCD_CA}@gi\" calico.yaml\n \nsed -i 's@.*etcd_ca:.*@\\ \\ etcd_ca:\\ \"/calico-secrets/etcd-ca\"@gi' calico.yaml\nsed -i 's@.*etcd_cert:.*@\\ \\ etcd_cert:\\ \"/calico-secrets/etcd-cert\"@gi' calico.yaml\nsed -i 's@.*etcd_key:.*@\\ \\ etcd_key:\\ \"/calico-secrets/etcd-key\"@gi' calico.yaml\n \n### 替换 IPPOOL 地址\nsed -i 's/192.168.0.0/10.2.0.0/g' calico.yaml\n```\n## Standard Hosted Install 的坑\n**由于我的k8s集群各节点存在多网卡，不同子网。结果出现的问题是个别 Calico 节点无法启动，同时创建 deployment 后，执行 route -n 会发现每个 node 只有自己节点 Pod 的路由，正常每个 node 上会有所有 node 上 Pod 网段的路由**。官方文档中直接创建的 calico.yml 文件中，使用 DaemonSet 方式启动 calico-node，同时 calico-node 的 IP 设置和 NODENAME 设置均为空，此时 calico-node 会进行自动获取，网络复杂情况下获取会出现问题；比如 IP 拿到了 不同网卡的 IP，NODENAME 获取不正确等，最终导致出现很奇怪的错误。\n\n解决方法也很简单。直接修改calico的yaml文件即可。有些博客会推荐大家使用service来启动calico node。实在是多此一举。**因为我们在启动pod内的容器时可以获取到当前k8s节点和pod的一些物理信息的，比如ip、hostname等等。** 具体文档可以参考[这里](https://kubernetes.io/zh/docs/tasks/inject-data-application/environment-variable-expose-pod-information/) 所以我们可以修改calico yaml文件如下：\n**我们分别使用k8s节点的ip作为calico node容器内的IP和NODENAME信息。** 防止name重复和自动获取所用的ip地址不在同一网段。\n```\n# Source: calico/templates/calico-node.yaml\n# This manifest installs the calico-node container, as well\n# as the CNI plugins and network config on\n# each master and worker node in a Kubernetes cluster.\nkind: DaemonSet\napiVersion: apps/v1\nmetadata:\n  name: calico-node\n  namespace: kube-system\n  labels:\n    k8s-app: calico-node\nspec:\n  selector:\n    matchLabels:\n      k8s-app: calico-node\n  updateStrategy:\n    type: RollingUpdate\n    rollingUpdate:\n      maxUnavailable: 1\n  template:\n    metadata:\n      labels:\n        k8s-app: calico-node\n      annotations:\n        # This, along with the CriticalAddonsOnly toleration below,\n        # marks the pod as a critical add-on, ensuring it gets\n        # priority scheduling and that its resources are reserved\n        # if it ever gets evicted.\n        scheduler.alpha.kubernetes.io/critical-pod: ''\n    spec:\n      nodeSelector:\n        beta.kubernetes.io/os: linux\n      hostNetwork: true\n      tolerations:\n        # Make sure calico-node gets scheduled on all nodes.\n        - effect: NoSchedule\n          operator: Exists\n        # Mark the pod as a critical add-on for rescheduling.\n        - key: CriticalAddonsOnly\n          operator: Exists\n        - effect: NoExecute\n          operator: Exists\n      serviceAccountName: calico-node\n      # Minimize downtime during a rolling upgrade or deletion; tell Kubernetes to do a \"force\n      # deletion\": https://kubernetes.io/docs/concepts/workloads/pods/pod/#termination-of-pods.\n      terminationGracePeriodSeconds: 0\n      priorityClassName: system-node-critical\n      initContainers:\n        # This container installs the CNI binaries\n        # and CNI network config file on each node.\n        - name: install-cni\n          image: calico/cni:v3.8.2\n          command: [\"/install-cni.sh\"]\n          env:\n            # Name of the CNI config file to create.\n            - name: CNI_CONF_NAME\n              value: \"10-calico.conflist\"\n            # The CNI network config to install on each node.\n            - name: CNI_NETWORK_CONFIG\n              valueFrom:\n                configMapKeyRef:\n                  name: calico-config\n                  key: cni_network_config\n            # The location of the etcd cluster.\n            - name: ETCD_ENDPOINTS\n              valueFrom:\n                configMapKeyRef:\n                  name: calico-config\n                  key: etcd_endpoints\n            # CNI MTU Config variable\n            - name: CNI_MTU\n              valueFrom:\n                configMapKeyRef:\n                  name: calico-config\n                  key: veth_mtu\n            # Prevents the container from sleeping forever.\n            - name: SLEEP\n              value: \"false\"\n          volumeMounts:\n            - mountPath: /host/opt/cni/bin\n              name: cni-bin-dir\n            - mountPath: /host/etc/cni/net.d\n              name: cni-net-dir\n            - mountPath: /calico-secrets\n              name: etcd-certs\n        # Adds a Flex Volume Driver that creates a per-pod Unix Domain Socket to allow Dikastes\n        # to communicate with Felix over the Policy Sync API.\n        - name: flexvol-driver\n          image: calico/pod2daemon-flexvol:v3.8.2\n          volumeMounts:\n          - name: flexvol-driver-host\n            mountPath: /host/driver\n      containers:\n        # Runs calico-node container on each Kubernetes node.  This\n        # container programs network policy and routes on each\n        # host.\n        - name: calico-node\n          image: calico/node:v3.8.2\n          env:\n            # The location of the etcd cluster.\n            - name: ETCD_ENDPOINTS\n              valueFrom:\n                configMapKeyRef:\n                  name: calico-config\n                  key: etcd_endpoints\n            # Location of the CA certificate for etcd.\n            - name: ETCD_CA_CERT_FILE\n              valueFrom:\n                configMapKeyRef:\n                  name: calico-config\n                  key: etcd_ca\n            # Location of the client key for etcd.\n            - name: ETCD_KEY_FILE\n              valueFrom:\n                configMapKeyRef:\n                  name: calico-config\n                  key: etcd_key\n            # Location of the client certificate for etcd.\n            - name: ETCD_CERT_FILE\n              valueFrom:\n                configMapKeyRef:\n                  name: calico-config\n                  key: etcd_cert\n            # Set noderef for node controller.\n            - name: CALICO_K8S_NODE_REF\n              valueFrom:\n                fieldRef:\n                  fieldPath: spec.nodeName\n            # Choose the backend to use.\n            - name: CALICO_NETWORKING_BACKEND\n              valueFrom:\n                configMapKeyRef:\n                  name: calico-config\n                  key: calico_backend\n            # Cluster type to identify the deployment type\n            - name: CLUSTER_TYPE\n              value: \"k8s,bgp\"\n            # Auto-detect the BGP IP address.\n            - name: IP\n              valueFrom:\n                fieldRef:\n                  fieldPath: status.hostIP\n            # Enable IPIP\n            - name: CALICO_IPV4POOL_IPIP\n              value: \"Always\"\n            # Set MTU for tunnel device used if ipip is enabled\n            - name: FELIX_IPINIPMTU\n              valueFrom:\n                configMapKeyRef:\n                  name: calico-config\n                  key: veth_mtu\n            # The default IPv4 pool to create on startup if none exists. Pod IPs will be\n            # chosen from this range. Changing this value after installation will have\n            # no effect. This should fall within `--cluster-cidr`.\n            - name: CALICO_IPV4POOL_CIDR\n              value: \"192.168.0.0/16\"\n            # Disable file logging so `kubectl logs` works.\n            - name: CALICO_DISABLE_FILE_LOGGING\n              value: \"true\"\n            # Set Felix endpoint to host default action to ACCEPT.\n            - name: FELIX_DEFAULTENDPOINTTOHOSTACTION\n              value: \"ACCEPT\"\n            # Disable IPv6 on Kubernetes.\n            - name: FELIX_IPV6SUPPORT\n              value: \"false\"\n            # Set Felix logging to \"info\"\n            - name: FELIX_LOGSEVERITYSCREEN\n              value: \"info\"\n            - name: FELIX_HEALTHENABLED\n              value: \"true\"\n            #  set calico node name\n            - name: NODENAME\n              valueFrom:\n                fieldRef:\n                  fieldPath: status.hostIP\n          securityContext:\n            privileged: true\n          resources:\n            requests:\n              cpu: 250m\n          livenessProbe:\n            httpGet:\n              path: /liveness\n              port: 9099\n              host: localhost\n            periodSeconds: 10\n            initialDelaySeconds: 10\n            failureThreshold: 6\n          readinessProbe:\n            exec:\n              command:\n              - /bin/calico-node\n              - -bird-ready\n              - -felix-ready\n            periodSeconds: 10\n          volumeMounts:\n            - mountPath: /lib/modules\n              name: lib-modules\n              readOnly: true\n            - mountPath: /run/xtables.lock\n              name: xtables-lock\n              readOnly: false\n            - mountPath: /var/run/calico\n              name: var-run-calico\n              readOnly: false\n            - mountPath: /var/lib/calico\n              name: var-lib-calico\n              readOnly: false\n            - mountPath: /calico-secrets\n              name: etcd-certs\n            - name: policysync\n              mountPath: /var/run/nodeagent\n      volumes:\n        # Used by calico-node.\n        - name: lib-modules\n          hostPath:\n            path: /lib/modules\n        - name: var-run-calico\n          hostPath:\n            path: /var/run/calico\n        - name: var-lib-calico\n          hostPath:\n            path: /var/lib/calico\n        - name: xtables-lock\n          hostPath:\n            path: /run/xtables.lock\n            type: FileOrCreate\n        # Used to install CNI.\n        - name: cni-bin-dir\n          hostPath:\n            path: /opt/cni/bin\n        - name: cni-net-dir\n          hostPath:\n            path: /etc/cni/net.d\n        # Mount in the etcd TLS secrets with mode 400.\n        # See https://kubernetes.io/docs/concepts/configuration/secret/\n        - name: etcd-certs\n          secret:\n            secretName: calico-etcd-secrets\n            defaultMode: 0400\n        # Used to create per-pod Unix Domain Sockets\n        - name: policysync\n          hostPath:\n            type: DirectoryOrCreate\n            path: /var/run/nodeagent\n        # Used to install Flex Volume Driver\n        - name: flexvol-driver-host\n          hostPath:\n            type: DirectoryOrCreate\n            path: /usr/libexec/kubernetes/kubelet-plugins/volume/exec/nodeagent~uds\n```\n## 关于在集群中使用keepalived挂载VIP后NodePort无法通过VIP访问的问题\n\n**目前由于kube-proxy的代理mode使用的是ipvs，已经取代了之前的iptables，导致目前该问题还无法解决。如果切换到iptables就可以了。**\n","slug":"k8s集群中部署Calico踩坑笔记","published":1,"date":"2020-04-05T03:06:43.063Z","updated":"2020-04-05T03:06:43.063Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck8x0luvf00092otv28woz5a9","content":"<h2 id=\"部署注意事项\"><a href=\"#部署注意事项\" class=\"headerlink\" title=\"部署注意事项\"></a>部署注意事项</h2><p>在使用 Calico 前当然最好撸一下官方文档，地址在这里 <a href=\"https://www.projectcalico.org/\" target=\"_blank\" rel=\"noopener\">Calico 官方文档</a>，其中部署前需要注意以下几点</p>\n<ol>\n<li>官方文档中要求 kubelet 配置必须增加 –network-plugin=cni 选项</li>\n<li>kubec-proxy 组件不能采用 –masquerade-all 启动，因为会与 Calico policy 冲突</li>\n<li>启用 RBAC 后需要设置对应的 RoleBinding，参考 官方文档 RBAC 部分<a id=\"more\"></a>\n关于在k8s集群中部署calico所用yaml有两个，不同点在于是使用Kubernetes API datastore还是etcd.使用etcd的calico文件在<a href=\"https://docs.projectcalico.org/v3.8/manifests/calico-etcd.yaml\" target=\"_blank\" rel=\"noopener\">这里</a><h2 id=\"Calico-官方部署方式\"><a href=\"#Calico-官方部署方式\" class=\"headerlink\" title=\"Calico 官方部署方式\"></a>Calico 官方部署方式</h2>在已经有了一个 Kubernetes 集群的情况下，官方部署方式描述的很简单，只需要改一改 yml 配置，然后 create 一下即可，具体描述见 <a href=\"https://docs.projectcalico.org/v3.8/getting-started/kubernetes/\" target=\"_blank\" rel=\"noopener\">官方文档</a><br>但是，如果我们有使用证书的话，需要对calico的yaml文件做如下修改</li>\n</ol>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sed -i &apos;s@.*etcd_endpoints:.*@\\ \\ etcd_endpoints:\\ \\&quot;https://192.168.168.2:2379,https://192.168.168.3:2379,https://192.168.168.4:2379\\&quot;@gi&apos; calico.yaml</span><br><span class=\"line\"> </span><br><span class=\"line\">### 替换 Etcd 证书</span><br><span class=\"line\">export ETCD_CERT=`cat /opt/kubernetes/ssl/etcd.pem | base64 | tr -d &apos;\\n&apos;`</span><br><span class=\"line\">export ETCD_KEY=`cat /opt/kubernetes/ssl/etcd-key.pem | base64 | tr -d &apos;\\n&apos;`</span><br><span class=\"line\">export ETCD_CA=`cat /opt/kubernetes/ssl/ca.pem | base64 | tr -d &apos;\\n&apos;`</span><br><span class=\"line\"> </span><br><span class=\"line\">sed -i &quot;s@.*etcd-cert:.*@\\ \\ etcd-cert:\\ $&#123;ETCD_CERT&#125;@gi&quot; calico.yaml</span><br><span class=\"line\">sed -i &quot;s@.*etcd-key:.*@\\ \\ etcd-key:\\ $&#123;ETCD_KEY&#125;@gi&quot; calico.yaml</span><br><span class=\"line\">sed -i &quot;s@.*etcd-ca:.*@\\ \\ etcd-ca:\\ $&#123;ETCD_CA&#125;@gi&quot; calico.yaml</span><br><span class=\"line\"> </span><br><span class=\"line\">sed -i &apos;s@.*etcd_ca:.*@\\ \\ etcd_ca:\\ &quot;/calico-secrets/etcd-ca&quot;@gi&apos; calico.yaml</span><br><span class=\"line\">sed -i &apos;s@.*etcd_cert:.*@\\ \\ etcd_cert:\\ &quot;/calico-secrets/etcd-cert&quot;@gi&apos; calico.yaml</span><br><span class=\"line\">sed -i &apos;s@.*etcd_key:.*@\\ \\ etcd_key:\\ &quot;/calico-secrets/etcd-key&quot;@gi&apos; calico.yaml</span><br><span class=\"line\"> </span><br><span class=\"line\">### 替换 IPPOOL 地址</span><br><span class=\"line\">sed -i &apos;s/192.168.0.0/10.2.0.0/g&apos; calico.yaml</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"Standard-Hosted-Install-的坑\"><a href=\"#Standard-Hosted-Install-的坑\" class=\"headerlink\" title=\"Standard Hosted Install 的坑\"></a>Standard Hosted Install 的坑</h2><p><strong>由于我的k8s集群各节点存在多网卡，不同子网。结果出现的问题是个别 Calico 节点无法启动，同时创建 deployment 后，执行 route -n 会发现每个 node 只有自己节点 Pod 的路由，正常每个 node 上会有所有 node 上 Pod 网段的路由</strong>。官方文档中直接创建的 calico.yml 文件中，使用 DaemonSet 方式启动 calico-node，同时 calico-node 的 IP 设置和 NODENAME 设置均为空，此时 calico-node 会进行自动获取，网络复杂情况下获取会出现问题；比如 IP 拿到了 不同网卡的 IP，NODENAME 获取不正确等，最终导致出现很奇怪的错误。</p>\n<p>解决方法也很简单。直接修改calico的yaml文件即可。有些博客会推荐大家使用service来启动calico node。实在是多此一举。<strong>因为我们在启动pod内的容器时可以获取到当前k8s节点和pod的一些物理信息的，比如ip、hostname等等。</strong> 具体文档可以参考<a href=\"https://kubernetes.io/zh/docs/tasks/inject-data-application/environment-variable-expose-pod-information/\" target=\"_blank\" rel=\"noopener\">这里</a> 所以我们可以修改calico yaml文件如下：<br><strong>我们分别使用k8s节点的ip作为calico node容器内的IP和NODENAME信息。</strong> 防止name重复和自动获取所用的ip地址不在同一网段。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br><span class=\"line\">78</span><br><span class=\"line\">79</span><br><span class=\"line\">80</span><br><span class=\"line\">81</span><br><span class=\"line\">82</span><br><span class=\"line\">83</span><br><span class=\"line\">84</span><br><span class=\"line\">85</span><br><span class=\"line\">86</span><br><span class=\"line\">87</span><br><span class=\"line\">88</span><br><span class=\"line\">89</span><br><span class=\"line\">90</span><br><span class=\"line\">91</span><br><span class=\"line\">92</span><br><span class=\"line\">93</span><br><span class=\"line\">94</span><br><span class=\"line\">95</span><br><span class=\"line\">96</span><br><span class=\"line\">97</span><br><span class=\"line\">98</span><br><span class=\"line\">99</span><br><span class=\"line\">100</span><br><span class=\"line\">101</span><br><span class=\"line\">102</span><br><span class=\"line\">103</span><br><span class=\"line\">104</span><br><span class=\"line\">105</span><br><span class=\"line\">106</span><br><span class=\"line\">107</span><br><span class=\"line\">108</span><br><span class=\"line\">109</span><br><span class=\"line\">110</span><br><span class=\"line\">111</span><br><span class=\"line\">112</span><br><span class=\"line\">113</span><br><span class=\"line\">114</span><br><span class=\"line\">115</span><br><span class=\"line\">116</span><br><span class=\"line\">117</span><br><span class=\"line\">118</span><br><span class=\"line\">119</span><br><span class=\"line\">120</span><br><span class=\"line\">121</span><br><span class=\"line\">122</span><br><span class=\"line\">123</span><br><span class=\"line\">124</span><br><span class=\"line\">125</span><br><span class=\"line\">126</span><br><span class=\"line\">127</span><br><span class=\"line\">128</span><br><span class=\"line\">129</span><br><span class=\"line\">130</span><br><span class=\"line\">131</span><br><span class=\"line\">132</span><br><span class=\"line\">133</span><br><span class=\"line\">134</span><br><span class=\"line\">135</span><br><span class=\"line\">136</span><br><span class=\"line\">137</span><br><span class=\"line\">138</span><br><span class=\"line\">139</span><br><span class=\"line\">140</span><br><span class=\"line\">141</span><br><span class=\"line\">142</span><br><span class=\"line\">143</span><br><span class=\"line\">144</span><br><span class=\"line\">145</span><br><span class=\"line\">146</span><br><span class=\"line\">147</span><br><span class=\"line\">148</span><br><span class=\"line\">149</span><br><span class=\"line\">150</span><br><span class=\"line\">151</span><br><span class=\"line\">152</span><br><span class=\"line\">153</span><br><span class=\"line\">154</span><br><span class=\"line\">155</span><br><span class=\"line\">156</span><br><span class=\"line\">157</span><br><span class=\"line\">158</span><br><span class=\"line\">159</span><br><span class=\"line\">160</span><br><span class=\"line\">161</span><br><span class=\"line\">162</span><br><span class=\"line\">163</span><br><span class=\"line\">164</span><br><span class=\"line\">165</span><br><span class=\"line\">166</span><br><span class=\"line\">167</span><br><span class=\"line\">168</span><br><span class=\"line\">169</span><br><span class=\"line\">170</span><br><span class=\"line\">171</span><br><span class=\"line\">172</span><br><span class=\"line\">173</span><br><span class=\"line\">174</span><br><span class=\"line\">175</span><br><span class=\"line\">176</span><br><span class=\"line\">177</span><br><span class=\"line\">178</span><br><span class=\"line\">179</span><br><span class=\"line\">180</span><br><span class=\"line\">181</span><br><span class=\"line\">182</span><br><span class=\"line\">183</span><br><span class=\"line\">184</span><br><span class=\"line\">185</span><br><span class=\"line\">186</span><br><span class=\"line\">187</span><br><span class=\"line\">188</span><br><span class=\"line\">189</span><br><span class=\"line\">190</span><br><span class=\"line\">191</span><br><span class=\"line\">192</span><br><span class=\"line\">193</span><br><span class=\"line\">194</span><br><span class=\"line\">195</span><br><span class=\"line\">196</span><br><span class=\"line\">197</span><br><span class=\"line\">198</span><br><span class=\"line\">199</span><br><span class=\"line\">200</span><br><span class=\"line\">201</span><br><span class=\"line\">202</span><br><span class=\"line\">203</span><br><span class=\"line\">204</span><br><span class=\"line\">205</span><br><span class=\"line\">206</span><br><span class=\"line\">207</span><br><span class=\"line\">208</span><br><span class=\"line\">209</span><br><span class=\"line\">210</span><br><span class=\"line\">211</span><br><span class=\"line\">212</span><br><span class=\"line\">213</span><br><span class=\"line\">214</span><br><span class=\"line\">215</span><br><span class=\"line\">216</span><br><span class=\"line\">217</span><br><span class=\"line\">218</span><br><span class=\"line\">219</span><br><span class=\"line\">220</span><br><span class=\"line\">221</span><br><span class=\"line\">222</span><br><span class=\"line\">223</span><br><span class=\"line\">224</span><br><span class=\"line\">225</span><br><span class=\"line\">226</span><br><span class=\"line\">227</span><br><span class=\"line\">228</span><br><span class=\"line\">229</span><br><span class=\"line\">230</span><br><span class=\"line\">231</span><br><span class=\"line\">232</span><br><span class=\"line\">233</span><br><span class=\"line\">234</span><br><span class=\"line\">235</span><br><span class=\"line\">236</span><br><span class=\"line\">237</span><br><span class=\"line\">238</span><br><span class=\"line\">239</span><br><span class=\"line\">240</span><br><span class=\"line\">241</span><br><span class=\"line\">242</span><br><span class=\"line\">243</span><br><span class=\"line\">244</span><br><span class=\"line\">245</span><br><span class=\"line\">246</span><br><span class=\"line\">247</span><br><span class=\"line\">248</span><br><span class=\"line\">249</span><br><span class=\"line\">250</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"># Source: calico/templates/calico-node.yaml</span><br><span class=\"line\"># This manifest installs the calico-node container, as well</span><br><span class=\"line\"># as the CNI plugins and network config on</span><br><span class=\"line\"># each master and worker node in a Kubernetes cluster.</span><br><span class=\"line\">kind: DaemonSet</span><br><span class=\"line\">apiVersion: apps/v1</span><br><span class=\"line\">metadata:</span><br><span class=\"line\">  name: calico-node</span><br><span class=\"line\">  namespace: kube-system</span><br><span class=\"line\">  labels:</span><br><span class=\"line\">    k8s-app: calico-node</span><br><span class=\"line\">spec:</span><br><span class=\"line\">  selector:</span><br><span class=\"line\">    matchLabels:</span><br><span class=\"line\">      k8s-app: calico-node</span><br><span class=\"line\">  updateStrategy:</span><br><span class=\"line\">    type: RollingUpdate</span><br><span class=\"line\">    rollingUpdate:</span><br><span class=\"line\">      maxUnavailable: 1</span><br><span class=\"line\">  template:</span><br><span class=\"line\">    metadata:</span><br><span class=\"line\">      labels:</span><br><span class=\"line\">        k8s-app: calico-node</span><br><span class=\"line\">      annotations:</span><br><span class=\"line\">        # This, along with the CriticalAddonsOnly toleration below,</span><br><span class=\"line\">        # marks the pod as a critical add-on, ensuring it gets</span><br><span class=\"line\">        # priority scheduling and that its resources are reserved</span><br><span class=\"line\">        # if it ever gets evicted.</span><br><span class=\"line\">        scheduler.alpha.kubernetes.io/critical-pod: &apos;&apos;</span><br><span class=\"line\">    spec:</span><br><span class=\"line\">      nodeSelector:</span><br><span class=\"line\">        beta.kubernetes.io/os: linux</span><br><span class=\"line\">      hostNetwork: true</span><br><span class=\"line\">      tolerations:</span><br><span class=\"line\">        # Make sure calico-node gets scheduled on all nodes.</span><br><span class=\"line\">        - effect: NoSchedule</span><br><span class=\"line\">          operator: Exists</span><br><span class=\"line\">        # Mark the pod as a critical add-on for rescheduling.</span><br><span class=\"line\">        - key: CriticalAddonsOnly</span><br><span class=\"line\">          operator: Exists</span><br><span class=\"line\">        - effect: NoExecute</span><br><span class=\"line\">          operator: Exists</span><br><span class=\"line\">      serviceAccountName: calico-node</span><br><span class=\"line\">      # Minimize downtime during a rolling upgrade or deletion; tell Kubernetes to do a &quot;force</span><br><span class=\"line\">      # deletion&quot;: https://kubernetes.io/docs/concepts/workloads/pods/pod/#termination-of-pods.</span><br><span class=\"line\">      terminationGracePeriodSeconds: 0</span><br><span class=\"line\">      priorityClassName: system-node-critical</span><br><span class=\"line\">      initContainers:</span><br><span class=\"line\">        # This container installs the CNI binaries</span><br><span class=\"line\">        # and CNI network config file on each node.</span><br><span class=\"line\">        - name: install-cni</span><br><span class=\"line\">          image: calico/cni:v3.8.2</span><br><span class=\"line\">          command: [&quot;/install-cni.sh&quot;]</span><br><span class=\"line\">          env:</span><br><span class=\"line\">            # Name of the CNI config file to create.</span><br><span class=\"line\">            - name: CNI_CONF_NAME</span><br><span class=\"line\">              value: &quot;10-calico.conflist&quot;</span><br><span class=\"line\">            # The CNI network config to install on each node.</span><br><span class=\"line\">            - name: CNI_NETWORK_CONFIG</span><br><span class=\"line\">              valueFrom:</span><br><span class=\"line\">                configMapKeyRef:</span><br><span class=\"line\">                  name: calico-config</span><br><span class=\"line\">                  key: cni_network_config</span><br><span class=\"line\">            # The location of the etcd cluster.</span><br><span class=\"line\">            - name: ETCD_ENDPOINTS</span><br><span class=\"line\">              valueFrom:</span><br><span class=\"line\">                configMapKeyRef:</span><br><span class=\"line\">                  name: calico-config</span><br><span class=\"line\">                  key: etcd_endpoints</span><br><span class=\"line\">            # CNI MTU Config variable</span><br><span class=\"line\">            - name: CNI_MTU</span><br><span class=\"line\">              valueFrom:</span><br><span class=\"line\">                configMapKeyRef:</span><br><span class=\"line\">                  name: calico-config</span><br><span class=\"line\">                  key: veth_mtu</span><br><span class=\"line\">            # Prevents the container from sleeping forever.</span><br><span class=\"line\">            - name: SLEEP</span><br><span class=\"line\">              value: &quot;false&quot;</span><br><span class=\"line\">          volumeMounts:</span><br><span class=\"line\">            - mountPath: /host/opt/cni/bin</span><br><span class=\"line\">              name: cni-bin-dir</span><br><span class=\"line\">            - mountPath: /host/etc/cni/net.d</span><br><span class=\"line\">              name: cni-net-dir</span><br><span class=\"line\">            - mountPath: /calico-secrets</span><br><span class=\"line\">              name: etcd-certs</span><br><span class=\"line\">        # Adds a Flex Volume Driver that creates a per-pod Unix Domain Socket to allow Dikastes</span><br><span class=\"line\">        # to communicate with Felix over the Policy Sync API.</span><br><span class=\"line\">        - name: flexvol-driver</span><br><span class=\"line\">          image: calico/pod2daemon-flexvol:v3.8.2</span><br><span class=\"line\">          volumeMounts:</span><br><span class=\"line\">          - name: flexvol-driver-host</span><br><span class=\"line\">            mountPath: /host/driver</span><br><span class=\"line\">      containers:</span><br><span class=\"line\">        # Runs calico-node container on each Kubernetes node.  This</span><br><span class=\"line\">        # container programs network policy and routes on each</span><br><span class=\"line\">        # host.</span><br><span class=\"line\">        - name: calico-node</span><br><span class=\"line\">          image: calico/node:v3.8.2</span><br><span class=\"line\">          env:</span><br><span class=\"line\">            # The location of the etcd cluster.</span><br><span class=\"line\">            - name: ETCD_ENDPOINTS</span><br><span class=\"line\">              valueFrom:</span><br><span class=\"line\">                configMapKeyRef:</span><br><span class=\"line\">                  name: calico-config</span><br><span class=\"line\">                  key: etcd_endpoints</span><br><span class=\"line\">            # Location of the CA certificate for etcd.</span><br><span class=\"line\">            - name: ETCD_CA_CERT_FILE</span><br><span class=\"line\">              valueFrom:</span><br><span class=\"line\">                configMapKeyRef:</span><br><span class=\"line\">                  name: calico-config</span><br><span class=\"line\">                  key: etcd_ca</span><br><span class=\"line\">            # Location of the client key for etcd.</span><br><span class=\"line\">            - name: ETCD_KEY_FILE</span><br><span class=\"line\">              valueFrom:</span><br><span class=\"line\">                configMapKeyRef:</span><br><span class=\"line\">                  name: calico-config</span><br><span class=\"line\">                  key: etcd_key</span><br><span class=\"line\">            # Location of the client certificate for etcd.</span><br><span class=\"line\">            - name: ETCD_CERT_FILE</span><br><span class=\"line\">              valueFrom:</span><br><span class=\"line\">                configMapKeyRef:</span><br><span class=\"line\">                  name: calico-config</span><br><span class=\"line\">                  key: etcd_cert</span><br><span class=\"line\">            # Set noderef for node controller.</span><br><span class=\"line\">            - name: CALICO_K8S_NODE_REF</span><br><span class=\"line\">              valueFrom:</span><br><span class=\"line\">                fieldRef:</span><br><span class=\"line\">                  fieldPath: spec.nodeName</span><br><span class=\"line\">            # Choose the backend to use.</span><br><span class=\"line\">            - name: CALICO_NETWORKING_BACKEND</span><br><span class=\"line\">              valueFrom:</span><br><span class=\"line\">                configMapKeyRef:</span><br><span class=\"line\">                  name: calico-config</span><br><span class=\"line\">                  key: calico_backend</span><br><span class=\"line\">            # Cluster type to identify the deployment type</span><br><span class=\"line\">            - name: CLUSTER_TYPE</span><br><span class=\"line\">              value: &quot;k8s,bgp&quot;</span><br><span class=\"line\">            # Auto-detect the BGP IP address.</span><br><span class=\"line\">            - name: IP</span><br><span class=\"line\">              valueFrom:</span><br><span class=\"line\">                fieldRef:</span><br><span class=\"line\">                  fieldPath: status.hostIP</span><br><span class=\"line\">            # Enable IPIP</span><br><span class=\"line\">            - name: CALICO_IPV4POOL_IPIP</span><br><span class=\"line\">              value: &quot;Always&quot;</span><br><span class=\"line\">            # Set MTU for tunnel device used if ipip is enabled</span><br><span class=\"line\">            - name: FELIX_IPINIPMTU</span><br><span class=\"line\">              valueFrom:</span><br><span class=\"line\">                configMapKeyRef:</span><br><span class=\"line\">                  name: calico-config</span><br><span class=\"line\">                  key: veth_mtu</span><br><span class=\"line\">            # The default IPv4 pool to create on startup if none exists. Pod IPs will be</span><br><span class=\"line\">            # chosen from this range. Changing this value after installation will have</span><br><span class=\"line\">            # no effect. This should fall within `--cluster-cidr`.</span><br><span class=\"line\">            - name: CALICO_IPV4POOL_CIDR</span><br><span class=\"line\">              value: &quot;192.168.0.0/16&quot;</span><br><span class=\"line\">            # Disable file logging so `kubectl logs` works.</span><br><span class=\"line\">            - name: CALICO_DISABLE_FILE_LOGGING</span><br><span class=\"line\">              value: &quot;true&quot;</span><br><span class=\"line\">            # Set Felix endpoint to host default action to ACCEPT.</span><br><span class=\"line\">            - name: FELIX_DEFAULTENDPOINTTOHOSTACTION</span><br><span class=\"line\">              value: &quot;ACCEPT&quot;</span><br><span class=\"line\">            # Disable IPv6 on Kubernetes.</span><br><span class=\"line\">            - name: FELIX_IPV6SUPPORT</span><br><span class=\"line\">              value: &quot;false&quot;</span><br><span class=\"line\">            # Set Felix logging to &quot;info&quot;</span><br><span class=\"line\">            - name: FELIX_LOGSEVERITYSCREEN</span><br><span class=\"line\">              value: &quot;info&quot;</span><br><span class=\"line\">            - name: FELIX_HEALTHENABLED</span><br><span class=\"line\">              value: &quot;true&quot;</span><br><span class=\"line\">            #  set calico node name</span><br><span class=\"line\">            - name: NODENAME</span><br><span class=\"line\">              valueFrom:</span><br><span class=\"line\">                fieldRef:</span><br><span class=\"line\">                  fieldPath: status.hostIP</span><br><span class=\"line\">          securityContext:</span><br><span class=\"line\">            privileged: true</span><br><span class=\"line\">          resources:</span><br><span class=\"line\">            requests:</span><br><span class=\"line\">              cpu: 250m</span><br><span class=\"line\">          livenessProbe:</span><br><span class=\"line\">            httpGet:</span><br><span class=\"line\">              path: /liveness</span><br><span class=\"line\">              port: 9099</span><br><span class=\"line\">              host: localhost</span><br><span class=\"line\">            periodSeconds: 10</span><br><span class=\"line\">            initialDelaySeconds: 10</span><br><span class=\"line\">            failureThreshold: 6</span><br><span class=\"line\">          readinessProbe:</span><br><span class=\"line\">            exec:</span><br><span class=\"line\">              command:</span><br><span class=\"line\">              - /bin/calico-node</span><br><span class=\"line\">              - -bird-ready</span><br><span class=\"line\">              - -felix-ready</span><br><span class=\"line\">            periodSeconds: 10</span><br><span class=\"line\">          volumeMounts:</span><br><span class=\"line\">            - mountPath: /lib/modules</span><br><span class=\"line\">              name: lib-modules</span><br><span class=\"line\">              readOnly: true</span><br><span class=\"line\">            - mountPath: /run/xtables.lock</span><br><span class=\"line\">              name: xtables-lock</span><br><span class=\"line\">              readOnly: false</span><br><span class=\"line\">            - mountPath: /var/run/calico</span><br><span class=\"line\">              name: var-run-calico</span><br><span class=\"line\">              readOnly: false</span><br><span class=\"line\">            - mountPath: /var/lib/calico</span><br><span class=\"line\">              name: var-lib-calico</span><br><span class=\"line\">              readOnly: false</span><br><span class=\"line\">            - mountPath: /calico-secrets</span><br><span class=\"line\">              name: etcd-certs</span><br><span class=\"line\">            - name: policysync</span><br><span class=\"line\">              mountPath: /var/run/nodeagent</span><br><span class=\"line\">      volumes:</span><br><span class=\"line\">        # Used by calico-node.</span><br><span class=\"line\">        - name: lib-modules</span><br><span class=\"line\">          hostPath:</span><br><span class=\"line\">            path: /lib/modules</span><br><span class=\"line\">        - name: var-run-calico</span><br><span class=\"line\">          hostPath:</span><br><span class=\"line\">            path: /var/run/calico</span><br><span class=\"line\">        - name: var-lib-calico</span><br><span class=\"line\">          hostPath:</span><br><span class=\"line\">            path: /var/lib/calico</span><br><span class=\"line\">        - name: xtables-lock</span><br><span class=\"line\">          hostPath:</span><br><span class=\"line\">            path: /run/xtables.lock</span><br><span class=\"line\">            type: FileOrCreate</span><br><span class=\"line\">        # Used to install CNI.</span><br><span class=\"line\">        - name: cni-bin-dir</span><br><span class=\"line\">          hostPath:</span><br><span class=\"line\">            path: /opt/cni/bin</span><br><span class=\"line\">        - name: cni-net-dir</span><br><span class=\"line\">          hostPath:</span><br><span class=\"line\">            path: /etc/cni/net.d</span><br><span class=\"line\">        # Mount in the etcd TLS secrets with mode 400.</span><br><span class=\"line\">        # See https://kubernetes.io/docs/concepts/configuration/secret/</span><br><span class=\"line\">        - name: etcd-certs</span><br><span class=\"line\">          secret:</span><br><span class=\"line\">            secretName: calico-etcd-secrets</span><br><span class=\"line\">            defaultMode: 0400</span><br><span class=\"line\">        # Used to create per-pod Unix Domain Sockets</span><br><span class=\"line\">        - name: policysync</span><br><span class=\"line\">          hostPath:</span><br><span class=\"line\">            type: DirectoryOrCreate</span><br><span class=\"line\">            path: /var/run/nodeagent</span><br><span class=\"line\">        # Used to install Flex Volume Driver</span><br><span class=\"line\">        - name: flexvol-driver-host</span><br><span class=\"line\">          hostPath:</span><br><span class=\"line\">            type: DirectoryOrCreate</span><br><span class=\"line\">            path: /usr/libexec/kubernetes/kubelet-plugins/volume/exec/nodeagent~uds</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"关于在集群中使用keepalived挂载VIP后NodePort无法通过VIP访问的问题\"><a href=\"#关于在集群中使用keepalived挂载VIP后NodePort无法通过VIP访问的问题\" class=\"headerlink\" title=\"关于在集群中使用keepalived挂载VIP后NodePort无法通过VIP访问的问题\"></a>关于在集群中使用keepalived挂载VIP后NodePort无法通过VIP访问的问题</h2><p><strong>目前由于kube-proxy的代理mode使用的是ipvs，已经取代了之前的iptables，导致目前该问题还无法解决。如果切换到iptables就可以了。</strong></p>\n","site":{"data":{}},"excerpt":"<h2 id=\"部署注意事项\"><a href=\"#部署注意事项\" class=\"headerlink\" title=\"部署注意事项\"></a>部署注意事项</h2><p>在使用 Calico 前当然最好撸一下官方文档，地址在这里 <a href=\"https://www.projectcalico.org/\" target=\"_blank\" rel=\"noopener\">Calico 官方文档</a>，其中部署前需要注意以下几点</p>\n<ol>\n<li>官方文档中要求 kubelet 配置必须增加 –network-plugin=cni 选项</li>\n<li>kubec-proxy 组件不能采用 –masquerade-all 启动，因为会与 Calico policy 冲突</li>\n<li>启用 RBAC 后需要设置对应的 RoleBinding，参考 官方文档 RBAC 部分","more":"关于在k8s集群中部署calico所用yaml有两个，不同点在于是使用Kubernetes API datastore还是etcd.使用etcd的calico文件在<a href=\"https://docs.projectcalico.org/v3.8/manifests/calico-etcd.yaml\" target=\"_blank\" rel=\"noopener\">这里</a><h2 id=\"Calico-官方部署方式\"><a href=\"#Calico-官方部署方式\" class=\"headerlink\" title=\"Calico 官方部署方式\"></a>Calico 官方部署方式</h2>在已经有了一个 Kubernetes 集群的情况下，官方部署方式描述的很简单，只需要改一改 yml 配置，然后 create 一下即可，具体描述见 <a href=\"https://docs.projectcalico.org/v3.8/getting-started/kubernetes/\" target=\"_blank\" rel=\"noopener\">官方文档</a><br>但是，如果我们有使用证书的话，需要对calico的yaml文件做如下修改</li>\n</ol>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sed -i &apos;s@.*etcd_endpoints:.*@\\ \\ etcd_endpoints:\\ \\&quot;https://192.168.168.2:2379,https://192.168.168.3:2379,https://192.168.168.4:2379\\&quot;@gi&apos; calico.yaml</span><br><span class=\"line\"> </span><br><span class=\"line\">### 替换 Etcd 证书</span><br><span class=\"line\">export ETCD_CERT=`cat /opt/kubernetes/ssl/etcd.pem | base64 | tr -d &apos;\\n&apos;`</span><br><span class=\"line\">export ETCD_KEY=`cat /opt/kubernetes/ssl/etcd-key.pem | base64 | tr -d &apos;\\n&apos;`</span><br><span class=\"line\">export ETCD_CA=`cat /opt/kubernetes/ssl/ca.pem | base64 | tr -d &apos;\\n&apos;`</span><br><span class=\"line\"> </span><br><span class=\"line\">sed -i &quot;s@.*etcd-cert:.*@\\ \\ etcd-cert:\\ $&#123;ETCD_CERT&#125;@gi&quot; calico.yaml</span><br><span class=\"line\">sed -i &quot;s@.*etcd-key:.*@\\ \\ etcd-key:\\ $&#123;ETCD_KEY&#125;@gi&quot; calico.yaml</span><br><span class=\"line\">sed -i &quot;s@.*etcd-ca:.*@\\ \\ etcd-ca:\\ $&#123;ETCD_CA&#125;@gi&quot; calico.yaml</span><br><span class=\"line\"> </span><br><span class=\"line\">sed -i &apos;s@.*etcd_ca:.*@\\ \\ etcd_ca:\\ &quot;/calico-secrets/etcd-ca&quot;@gi&apos; calico.yaml</span><br><span class=\"line\">sed -i &apos;s@.*etcd_cert:.*@\\ \\ etcd_cert:\\ &quot;/calico-secrets/etcd-cert&quot;@gi&apos; calico.yaml</span><br><span class=\"line\">sed -i &apos;s@.*etcd_key:.*@\\ \\ etcd_key:\\ &quot;/calico-secrets/etcd-key&quot;@gi&apos; calico.yaml</span><br><span class=\"line\"> </span><br><span class=\"line\">### 替换 IPPOOL 地址</span><br><span class=\"line\">sed -i &apos;s/192.168.0.0/10.2.0.0/g&apos; calico.yaml</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"Standard-Hosted-Install-的坑\"><a href=\"#Standard-Hosted-Install-的坑\" class=\"headerlink\" title=\"Standard Hosted Install 的坑\"></a>Standard Hosted Install 的坑</h2><p><strong>由于我的k8s集群各节点存在多网卡，不同子网。结果出现的问题是个别 Calico 节点无法启动，同时创建 deployment 后，执行 route -n 会发现每个 node 只有自己节点 Pod 的路由，正常每个 node 上会有所有 node 上 Pod 网段的路由</strong>。官方文档中直接创建的 calico.yml 文件中，使用 DaemonSet 方式启动 calico-node，同时 calico-node 的 IP 设置和 NODENAME 设置均为空，此时 calico-node 会进行自动获取，网络复杂情况下获取会出现问题；比如 IP 拿到了 不同网卡的 IP，NODENAME 获取不正确等，最终导致出现很奇怪的错误。</p>\n<p>解决方法也很简单。直接修改calico的yaml文件即可。有些博客会推荐大家使用service来启动calico node。实在是多此一举。<strong>因为我们在启动pod内的容器时可以获取到当前k8s节点和pod的一些物理信息的，比如ip、hostname等等。</strong> 具体文档可以参考<a href=\"https://kubernetes.io/zh/docs/tasks/inject-data-application/environment-variable-expose-pod-information/\" target=\"_blank\" rel=\"noopener\">这里</a> 所以我们可以修改calico yaml文件如下：<br><strong>我们分别使用k8s节点的ip作为calico node容器内的IP和NODENAME信息。</strong> 防止name重复和自动获取所用的ip地址不在同一网段。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br><span class=\"line\">78</span><br><span class=\"line\">79</span><br><span class=\"line\">80</span><br><span class=\"line\">81</span><br><span class=\"line\">82</span><br><span class=\"line\">83</span><br><span class=\"line\">84</span><br><span class=\"line\">85</span><br><span class=\"line\">86</span><br><span class=\"line\">87</span><br><span class=\"line\">88</span><br><span class=\"line\">89</span><br><span class=\"line\">90</span><br><span class=\"line\">91</span><br><span class=\"line\">92</span><br><span class=\"line\">93</span><br><span class=\"line\">94</span><br><span class=\"line\">95</span><br><span class=\"line\">96</span><br><span class=\"line\">97</span><br><span class=\"line\">98</span><br><span class=\"line\">99</span><br><span class=\"line\">100</span><br><span class=\"line\">101</span><br><span class=\"line\">102</span><br><span class=\"line\">103</span><br><span class=\"line\">104</span><br><span class=\"line\">105</span><br><span class=\"line\">106</span><br><span class=\"line\">107</span><br><span class=\"line\">108</span><br><span class=\"line\">109</span><br><span class=\"line\">110</span><br><span class=\"line\">111</span><br><span class=\"line\">112</span><br><span class=\"line\">113</span><br><span class=\"line\">114</span><br><span class=\"line\">115</span><br><span class=\"line\">116</span><br><span class=\"line\">117</span><br><span class=\"line\">118</span><br><span class=\"line\">119</span><br><span class=\"line\">120</span><br><span class=\"line\">121</span><br><span class=\"line\">122</span><br><span class=\"line\">123</span><br><span class=\"line\">124</span><br><span class=\"line\">125</span><br><span class=\"line\">126</span><br><span class=\"line\">127</span><br><span class=\"line\">128</span><br><span class=\"line\">129</span><br><span class=\"line\">130</span><br><span class=\"line\">131</span><br><span class=\"line\">132</span><br><span class=\"line\">133</span><br><span class=\"line\">134</span><br><span class=\"line\">135</span><br><span class=\"line\">136</span><br><span class=\"line\">137</span><br><span class=\"line\">138</span><br><span class=\"line\">139</span><br><span class=\"line\">140</span><br><span class=\"line\">141</span><br><span class=\"line\">142</span><br><span class=\"line\">143</span><br><span class=\"line\">144</span><br><span class=\"line\">145</span><br><span class=\"line\">146</span><br><span class=\"line\">147</span><br><span class=\"line\">148</span><br><span class=\"line\">149</span><br><span class=\"line\">150</span><br><span class=\"line\">151</span><br><span class=\"line\">152</span><br><span class=\"line\">153</span><br><span class=\"line\">154</span><br><span class=\"line\">155</span><br><span class=\"line\">156</span><br><span class=\"line\">157</span><br><span class=\"line\">158</span><br><span class=\"line\">159</span><br><span class=\"line\">160</span><br><span class=\"line\">161</span><br><span class=\"line\">162</span><br><span class=\"line\">163</span><br><span class=\"line\">164</span><br><span class=\"line\">165</span><br><span class=\"line\">166</span><br><span class=\"line\">167</span><br><span class=\"line\">168</span><br><span class=\"line\">169</span><br><span class=\"line\">170</span><br><span class=\"line\">171</span><br><span class=\"line\">172</span><br><span class=\"line\">173</span><br><span class=\"line\">174</span><br><span class=\"line\">175</span><br><span class=\"line\">176</span><br><span class=\"line\">177</span><br><span class=\"line\">178</span><br><span class=\"line\">179</span><br><span class=\"line\">180</span><br><span class=\"line\">181</span><br><span class=\"line\">182</span><br><span class=\"line\">183</span><br><span class=\"line\">184</span><br><span class=\"line\">185</span><br><span class=\"line\">186</span><br><span class=\"line\">187</span><br><span class=\"line\">188</span><br><span class=\"line\">189</span><br><span class=\"line\">190</span><br><span class=\"line\">191</span><br><span class=\"line\">192</span><br><span class=\"line\">193</span><br><span class=\"line\">194</span><br><span class=\"line\">195</span><br><span class=\"line\">196</span><br><span class=\"line\">197</span><br><span class=\"line\">198</span><br><span class=\"line\">199</span><br><span class=\"line\">200</span><br><span class=\"line\">201</span><br><span class=\"line\">202</span><br><span class=\"line\">203</span><br><span class=\"line\">204</span><br><span class=\"line\">205</span><br><span class=\"line\">206</span><br><span class=\"line\">207</span><br><span class=\"line\">208</span><br><span class=\"line\">209</span><br><span class=\"line\">210</span><br><span class=\"line\">211</span><br><span class=\"line\">212</span><br><span class=\"line\">213</span><br><span class=\"line\">214</span><br><span class=\"line\">215</span><br><span class=\"line\">216</span><br><span class=\"line\">217</span><br><span class=\"line\">218</span><br><span class=\"line\">219</span><br><span class=\"line\">220</span><br><span class=\"line\">221</span><br><span class=\"line\">222</span><br><span class=\"line\">223</span><br><span class=\"line\">224</span><br><span class=\"line\">225</span><br><span class=\"line\">226</span><br><span class=\"line\">227</span><br><span class=\"line\">228</span><br><span class=\"line\">229</span><br><span class=\"line\">230</span><br><span class=\"line\">231</span><br><span class=\"line\">232</span><br><span class=\"line\">233</span><br><span class=\"line\">234</span><br><span class=\"line\">235</span><br><span class=\"line\">236</span><br><span class=\"line\">237</span><br><span class=\"line\">238</span><br><span class=\"line\">239</span><br><span class=\"line\">240</span><br><span class=\"line\">241</span><br><span class=\"line\">242</span><br><span class=\"line\">243</span><br><span class=\"line\">244</span><br><span class=\"line\">245</span><br><span class=\"line\">246</span><br><span class=\"line\">247</span><br><span class=\"line\">248</span><br><span class=\"line\">249</span><br><span class=\"line\">250</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"># Source: calico/templates/calico-node.yaml</span><br><span class=\"line\"># This manifest installs the calico-node container, as well</span><br><span class=\"line\"># as the CNI plugins and network config on</span><br><span class=\"line\"># each master and worker node in a Kubernetes cluster.</span><br><span class=\"line\">kind: DaemonSet</span><br><span class=\"line\">apiVersion: apps/v1</span><br><span class=\"line\">metadata:</span><br><span class=\"line\">  name: calico-node</span><br><span class=\"line\">  namespace: kube-system</span><br><span class=\"line\">  labels:</span><br><span class=\"line\">    k8s-app: calico-node</span><br><span class=\"line\">spec:</span><br><span class=\"line\">  selector:</span><br><span class=\"line\">    matchLabels:</span><br><span class=\"line\">      k8s-app: calico-node</span><br><span class=\"line\">  updateStrategy:</span><br><span class=\"line\">    type: RollingUpdate</span><br><span class=\"line\">    rollingUpdate:</span><br><span class=\"line\">      maxUnavailable: 1</span><br><span class=\"line\">  template:</span><br><span class=\"line\">    metadata:</span><br><span class=\"line\">      labels:</span><br><span class=\"line\">        k8s-app: calico-node</span><br><span class=\"line\">      annotations:</span><br><span class=\"line\">        # This, along with the CriticalAddonsOnly toleration below,</span><br><span class=\"line\">        # marks the pod as a critical add-on, ensuring it gets</span><br><span class=\"line\">        # priority scheduling and that its resources are reserved</span><br><span class=\"line\">        # if it ever gets evicted.</span><br><span class=\"line\">        scheduler.alpha.kubernetes.io/critical-pod: &apos;&apos;</span><br><span class=\"line\">    spec:</span><br><span class=\"line\">      nodeSelector:</span><br><span class=\"line\">        beta.kubernetes.io/os: linux</span><br><span class=\"line\">      hostNetwork: true</span><br><span class=\"line\">      tolerations:</span><br><span class=\"line\">        # Make sure calico-node gets scheduled on all nodes.</span><br><span class=\"line\">        - effect: NoSchedule</span><br><span class=\"line\">          operator: Exists</span><br><span class=\"line\">        # Mark the pod as a critical add-on for rescheduling.</span><br><span class=\"line\">        - key: CriticalAddonsOnly</span><br><span class=\"line\">          operator: Exists</span><br><span class=\"line\">        - effect: NoExecute</span><br><span class=\"line\">          operator: Exists</span><br><span class=\"line\">      serviceAccountName: calico-node</span><br><span class=\"line\">      # Minimize downtime during a rolling upgrade or deletion; tell Kubernetes to do a &quot;force</span><br><span class=\"line\">      # deletion&quot;: https://kubernetes.io/docs/concepts/workloads/pods/pod/#termination-of-pods.</span><br><span class=\"line\">      terminationGracePeriodSeconds: 0</span><br><span class=\"line\">      priorityClassName: system-node-critical</span><br><span class=\"line\">      initContainers:</span><br><span class=\"line\">        # This container installs the CNI binaries</span><br><span class=\"line\">        # and CNI network config file on each node.</span><br><span class=\"line\">        - name: install-cni</span><br><span class=\"line\">          image: calico/cni:v3.8.2</span><br><span class=\"line\">          command: [&quot;/install-cni.sh&quot;]</span><br><span class=\"line\">          env:</span><br><span class=\"line\">            # Name of the CNI config file to create.</span><br><span class=\"line\">            - name: CNI_CONF_NAME</span><br><span class=\"line\">              value: &quot;10-calico.conflist&quot;</span><br><span class=\"line\">            # The CNI network config to install on each node.</span><br><span class=\"line\">            - name: CNI_NETWORK_CONFIG</span><br><span class=\"line\">              valueFrom:</span><br><span class=\"line\">                configMapKeyRef:</span><br><span class=\"line\">                  name: calico-config</span><br><span class=\"line\">                  key: cni_network_config</span><br><span class=\"line\">            # The location of the etcd cluster.</span><br><span class=\"line\">            - name: ETCD_ENDPOINTS</span><br><span class=\"line\">              valueFrom:</span><br><span class=\"line\">                configMapKeyRef:</span><br><span class=\"line\">                  name: calico-config</span><br><span class=\"line\">                  key: etcd_endpoints</span><br><span class=\"line\">            # CNI MTU Config variable</span><br><span class=\"line\">            - name: CNI_MTU</span><br><span class=\"line\">              valueFrom:</span><br><span class=\"line\">                configMapKeyRef:</span><br><span class=\"line\">                  name: calico-config</span><br><span class=\"line\">                  key: veth_mtu</span><br><span class=\"line\">            # Prevents the container from sleeping forever.</span><br><span class=\"line\">            - name: SLEEP</span><br><span class=\"line\">              value: &quot;false&quot;</span><br><span class=\"line\">          volumeMounts:</span><br><span class=\"line\">            - mountPath: /host/opt/cni/bin</span><br><span class=\"line\">              name: cni-bin-dir</span><br><span class=\"line\">            - mountPath: /host/etc/cni/net.d</span><br><span class=\"line\">              name: cni-net-dir</span><br><span class=\"line\">            - mountPath: /calico-secrets</span><br><span class=\"line\">              name: etcd-certs</span><br><span class=\"line\">        # Adds a Flex Volume Driver that creates a per-pod Unix Domain Socket to allow Dikastes</span><br><span class=\"line\">        # to communicate with Felix over the Policy Sync API.</span><br><span class=\"line\">        - name: flexvol-driver</span><br><span class=\"line\">          image: calico/pod2daemon-flexvol:v3.8.2</span><br><span class=\"line\">          volumeMounts:</span><br><span class=\"line\">          - name: flexvol-driver-host</span><br><span class=\"line\">            mountPath: /host/driver</span><br><span class=\"line\">      containers:</span><br><span class=\"line\">        # Runs calico-node container on each Kubernetes node.  This</span><br><span class=\"line\">        # container programs network policy and routes on each</span><br><span class=\"line\">        # host.</span><br><span class=\"line\">        - name: calico-node</span><br><span class=\"line\">          image: calico/node:v3.8.2</span><br><span class=\"line\">          env:</span><br><span class=\"line\">            # The location of the etcd cluster.</span><br><span class=\"line\">            - name: ETCD_ENDPOINTS</span><br><span class=\"line\">              valueFrom:</span><br><span class=\"line\">                configMapKeyRef:</span><br><span class=\"line\">                  name: calico-config</span><br><span class=\"line\">                  key: etcd_endpoints</span><br><span class=\"line\">            # Location of the CA certificate for etcd.</span><br><span class=\"line\">            - name: ETCD_CA_CERT_FILE</span><br><span class=\"line\">              valueFrom:</span><br><span class=\"line\">                configMapKeyRef:</span><br><span class=\"line\">                  name: calico-config</span><br><span class=\"line\">                  key: etcd_ca</span><br><span class=\"line\">            # Location of the client key for etcd.</span><br><span class=\"line\">            - name: ETCD_KEY_FILE</span><br><span class=\"line\">              valueFrom:</span><br><span class=\"line\">                configMapKeyRef:</span><br><span class=\"line\">                  name: calico-config</span><br><span class=\"line\">                  key: etcd_key</span><br><span class=\"line\">            # Location of the client certificate for etcd.</span><br><span class=\"line\">            - name: ETCD_CERT_FILE</span><br><span class=\"line\">              valueFrom:</span><br><span class=\"line\">                configMapKeyRef:</span><br><span class=\"line\">                  name: calico-config</span><br><span class=\"line\">                  key: etcd_cert</span><br><span class=\"line\">            # Set noderef for node controller.</span><br><span class=\"line\">            - name: CALICO_K8S_NODE_REF</span><br><span class=\"line\">              valueFrom:</span><br><span class=\"line\">                fieldRef:</span><br><span class=\"line\">                  fieldPath: spec.nodeName</span><br><span class=\"line\">            # Choose the backend to use.</span><br><span class=\"line\">            - name: CALICO_NETWORKING_BACKEND</span><br><span class=\"line\">              valueFrom:</span><br><span class=\"line\">                configMapKeyRef:</span><br><span class=\"line\">                  name: calico-config</span><br><span class=\"line\">                  key: calico_backend</span><br><span class=\"line\">            # Cluster type to identify the deployment type</span><br><span class=\"line\">            - name: CLUSTER_TYPE</span><br><span class=\"line\">              value: &quot;k8s,bgp&quot;</span><br><span class=\"line\">            # Auto-detect the BGP IP address.</span><br><span class=\"line\">            - name: IP</span><br><span class=\"line\">              valueFrom:</span><br><span class=\"line\">                fieldRef:</span><br><span class=\"line\">                  fieldPath: status.hostIP</span><br><span class=\"line\">            # Enable IPIP</span><br><span class=\"line\">            - name: CALICO_IPV4POOL_IPIP</span><br><span class=\"line\">              value: &quot;Always&quot;</span><br><span class=\"line\">            # Set MTU for tunnel device used if ipip is enabled</span><br><span class=\"line\">            - name: FELIX_IPINIPMTU</span><br><span class=\"line\">              valueFrom:</span><br><span class=\"line\">                configMapKeyRef:</span><br><span class=\"line\">                  name: calico-config</span><br><span class=\"line\">                  key: veth_mtu</span><br><span class=\"line\">            # The default IPv4 pool to create on startup if none exists. Pod IPs will be</span><br><span class=\"line\">            # chosen from this range. Changing this value after installation will have</span><br><span class=\"line\">            # no effect. This should fall within `--cluster-cidr`.</span><br><span class=\"line\">            - name: CALICO_IPV4POOL_CIDR</span><br><span class=\"line\">              value: &quot;192.168.0.0/16&quot;</span><br><span class=\"line\">            # Disable file logging so `kubectl logs` works.</span><br><span class=\"line\">            - name: CALICO_DISABLE_FILE_LOGGING</span><br><span class=\"line\">              value: &quot;true&quot;</span><br><span class=\"line\">            # Set Felix endpoint to host default action to ACCEPT.</span><br><span class=\"line\">            - name: FELIX_DEFAULTENDPOINTTOHOSTACTION</span><br><span class=\"line\">              value: &quot;ACCEPT&quot;</span><br><span class=\"line\">            # Disable IPv6 on Kubernetes.</span><br><span class=\"line\">            - name: FELIX_IPV6SUPPORT</span><br><span class=\"line\">              value: &quot;false&quot;</span><br><span class=\"line\">            # Set Felix logging to &quot;info&quot;</span><br><span class=\"line\">            - name: FELIX_LOGSEVERITYSCREEN</span><br><span class=\"line\">              value: &quot;info&quot;</span><br><span class=\"line\">            - name: FELIX_HEALTHENABLED</span><br><span class=\"line\">              value: &quot;true&quot;</span><br><span class=\"line\">            #  set calico node name</span><br><span class=\"line\">            - name: NODENAME</span><br><span class=\"line\">              valueFrom:</span><br><span class=\"line\">                fieldRef:</span><br><span class=\"line\">                  fieldPath: status.hostIP</span><br><span class=\"line\">          securityContext:</span><br><span class=\"line\">            privileged: true</span><br><span class=\"line\">          resources:</span><br><span class=\"line\">            requests:</span><br><span class=\"line\">              cpu: 250m</span><br><span class=\"line\">          livenessProbe:</span><br><span class=\"line\">            httpGet:</span><br><span class=\"line\">              path: /liveness</span><br><span class=\"line\">              port: 9099</span><br><span class=\"line\">              host: localhost</span><br><span class=\"line\">            periodSeconds: 10</span><br><span class=\"line\">            initialDelaySeconds: 10</span><br><span class=\"line\">            failureThreshold: 6</span><br><span class=\"line\">          readinessProbe:</span><br><span class=\"line\">            exec:</span><br><span class=\"line\">              command:</span><br><span class=\"line\">              - /bin/calico-node</span><br><span class=\"line\">              - -bird-ready</span><br><span class=\"line\">              - -felix-ready</span><br><span class=\"line\">            periodSeconds: 10</span><br><span class=\"line\">          volumeMounts:</span><br><span class=\"line\">            - mountPath: /lib/modules</span><br><span class=\"line\">              name: lib-modules</span><br><span class=\"line\">              readOnly: true</span><br><span class=\"line\">            - mountPath: /run/xtables.lock</span><br><span class=\"line\">              name: xtables-lock</span><br><span class=\"line\">              readOnly: false</span><br><span class=\"line\">            - mountPath: /var/run/calico</span><br><span class=\"line\">              name: var-run-calico</span><br><span class=\"line\">              readOnly: false</span><br><span class=\"line\">            - mountPath: /var/lib/calico</span><br><span class=\"line\">              name: var-lib-calico</span><br><span class=\"line\">              readOnly: false</span><br><span class=\"line\">            - mountPath: /calico-secrets</span><br><span class=\"line\">              name: etcd-certs</span><br><span class=\"line\">            - name: policysync</span><br><span class=\"line\">              mountPath: /var/run/nodeagent</span><br><span class=\"line\">      volumes:</span><br><span class=\"line\">        # Used by calico-node.</span><br><span class=\"line\">        - name: lib-modules</span><br><span class=\"line\">          hostPath:</span><br><span class=\"line\">            path: /lib/modules</span><br><span class=\"line\">        - name: var-run-calico</span><br><span class=\"line\">          hostPath:</span><br><span class=\"line\">            path: /var/run/calico</span><br><span class=\"line\">        - name: var-lib-calico</span><br><span class=\"line\">          hostPath:</span><br><span class=\"line\">            path: /var/lib/calico</span><br><span class=\"line\">        - name: xtables-lock</span><br><span class=\"line\">          hostPath:</span><br><span class=\"line\">            path: /run/xtables.lock</span><br><span class=\"line\">            type: FileOrCreate</span><br><span class=\"line\">        # Used to install CNI.</span><br><span class=\"line\">        - name: cni-bin-dir</span><br><span class=\"line\">          hostPath:</span><br><span class=\"line\">            path: /opt/cni/bin</span><br><span class=\"line\">        - name: cni-net-dir</span><br><span class=\"line\">          hostPath:</span><br><span class=\"line\">            path: /etc/cni/net.d</span><br><span class=\"line\">        # Mount in the etcd TLS secrets with mode 400.</span><br><span class=\"line\">        # See https://kubernetes.io/docs/concepts/configuration/secret/</span><br><span class=\"line\">        - name: etcd-certs</span><br><span class=\"line\">          secret:</span><br><span class=\"line\">            secretName: calico-etcd-secrets</span><br><span class=\"line\">            defaultMode: 0400</span><br><span class=\"line\">        # Used to create per-pod Unix Domain Sockets</span><br><span class=\"line\">        - name: policysync</span><br><span class=\"line\">          hostPath:</span><br><span class=\"line\">            type: DirectoryOrCreate</span><br><span class=\"line\">            path: /var/run/nodeagent</span><br><span class=\"line\">        # Used to install Flex Volume Driver</span><br><span class=\"line\">        - name: flexvol-driver-host</span><br><span class=\"line\">          hostPath:</span><br><span class=\"line\">            type: DirectoryOrCreate</span><br><span class=\"line\">            path: /usr/libexec/kubernetes/kubelet-plugins/volume/exec/nodeagent~uds</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"关于在集群中使用keepalived挂载VIP后NodePort无法通过VIP访问的问题\"><a href=\"#关于在集群中使用keepalived挂载VIP后NodePort无法通过VIP访问的问题\" class=\"headerlink\" title=\"关于在集群中使用keepalived挂载VIP后NodePort无法通过VIP访问的问题\"></a>关于在集群中使用keepalived挂载VIP后NodePort无法通过VIP访问的问题</h2><p><strong>目前由于kube-proxy的代理mode使用的是ipvs，已经取代了之前的iptables，导致目前该问题还无法解决。如果切换到iptables就可以了。</strong></p>"},{"title":"kubernetes dashboard","_content":"\n# 自己动手搭建kubernetes dashboard界面\n\nkubernetes官方提供了一套实用的dashboard界面。但是，入学者按照github上搭建安装时往往会遇到各种问题。顺手写个博客记录一下，也希望能帮到一些初学者。\n\n## 搭建前准备\nkubernetes官方提供了一套实用的dashboard界面。但是，入学者按照github上搭建安装时往往会遇到各种问题。顺手写个博客记录一下，也希望能帮到一些初学者。目前，我搭建的kubernetes dashboard版本是1.10.1.搭建之前我们首先要有一套k8s集群环境。搭建k8s环境有空再写博客，另外还需要准备以下东西。\n<!--more-->\n\n 1. 从github上下载kubernetes dashboard的安装yaml文件，github地址在[此](https://github.com/kubernetes/dashboard)，yaml文件在[此](https://raw.githubusercontent.com/kubernetes/dashboard/v1.10.1/src/deploy/recommended/kubernetes-dashboard.yaml)\n 2. 默认安装dashboard的时候，会需要**heapster**服务，yaml文件的地址在[此](https://github.com/kubernetes-retired/heapster)，依据README安装即可；\n 3. 还需要**metrics**，地址在[此](https://github.com/kubernetes-incubator/metrics-server)，依据README安装即可；\n 4. 所需各类镜像如是局域网环境，需提前下载好，通过docker save压缩成tar包，再copy到局域网后docker load加载。\n\n## 搭建步骤\n创建dashboard各服务。将dashboard service改为Nodeport方便我们测试连接\n![在这里插入图片描述](https://img-blog.csdnimg.cn/2019091917002441.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0N1aV9DdWlfNjY2,size_16,color_FFFFFF,t_70)\n然后依次创建heapster、metrics服务。然后我们访问集群任一节点https://Ip:Nodeport url。得到如下界面：\n![在这里插入图片描述](https://img-blog.csdnimg.cn/20190919170322147.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0N1aV9DdWlfNjY2,size_16,color_FFFFFF,t_70)\n我们看到访问需要token。我们需要一个用户授予admin权限。通过以下yaml文件来创建：\n\n```\napiVersion: v1\nkind: ServiceAccount\nmetadata:\n  name: admin-user\n  namespace: kube-system\n\n---\napiVersion: rbac.authorization.k8s.io/v1\nkind: ClusterRoleBinding\nmetadata:\n  name: admin-user\nroleRef:\n  apiGroup: rbac.authorization.k8s.io\n  kind: ClusterRole\n  name: cluster-admin\nsubjects:\n- kind: ServiceAccount\n  name: admin-user\n  namespace: kube-system\n```\n我们创建了一个名为admin-user的SA，通过ClusterRoleBinding绑定名为cluster-admin的ClusterRole。\n\n```\nkubectl get secret -n kube-system|grep admin-token\n获取secret名字\nkubectl get secret “secret的名字” -o jsonpath={.data.token} -n kube-system |base64 -d\n```\n获得一个base64字符串，粘贴到网页中。\n**切记，请使用火狐浏览器，我使用google和IE都无法进入页面**\n\n","source":"_posts/自己动手搭建kubernetes dashboard界面.md","raw":"---\ntitle: kubernetes dashboard\ncategories: Kubernetes\n---\n\n# 自己动手搭建kubernetes dashboard界面\n\nkubernetes官方提供了一套实用的dashboard界面。但是，入学者按照github上搭建安装时往往会遇到各种问题。顺手写个博客记录一下，也希望能帮到一些初学者。\n\n## 搭建前准备\nkubernetes官方提供了一套实用的dashboard界面。但是，入学者按照github上搭建安装时往往会遇到各种问题。顺手写个博客记录一下，也希望能帮到一些初学者。目前，我搭建的kubernetes dashboard版本是1.10.1.搭建之前我们首先要有一套k8s集群环境。搭建k8s环境有空再写博客，另外还需要准备以下东西。\n<!--more-->\n\n 1. 从github上下载kubernetes dashboard的安装yaml文件，github地址在[此](https://github.com/kubernetes/dashboard)，yaml文件在[此](https://raw.githubusercontent.com/kubernetes/dashboard/v1.10.1/src/deploy/recommended/kubernetes-dashboard.yaml)\n 2. 默认安装dashboard的时候，会需要**heapster**服务，yaml文件的地址在[此](https://github.com/kubernetes-retired/heapster)，依据README安装即可；\n 3. 还需要**metrics**，地址在[此](https://github.com/kubernetes-incubator/metrics-server)，依据README安装即可；\n 4. 所需各类镜像如是局域网环境，需提前下载好，通过docker save压缩成tar包，再copy到局域网后docker load加载。\n\n## 搭建步骤\n创建dashboard各服务。将dashboard service改为Nodeport方便我们测试连接\n![在这里插入图片描述](https://img-blog.csdnimg.cn/2019091917002441.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0N1aV9DdWlfNjY2,size_16,color_FFFFFF,t_70)\n然后依次创建heapster、metrics服务。然后我们访问集群任一节点https://Ip:Nodeport url。得到如下界面：\n![在这里插入图片描述](https://img-blog.csdnimg.cn/20190919170322147.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0N1aV9DdWlfNjY2,size_16,color_FFFFFF,t_70)\n我们看到访问需要token。我们需要一个用户授予admin权限。通过以下yaml文件来创建：\n\n```\napiVersion: v1\nkind: ServiceAccount\nmetadata:\n  name: admin-user\n  namespace: kube-system\n\n---\napiVersion: rbac.authorization.k8s.io/v1\nkind: ClusterRoleBinding\nmetadata:\n  name: admin-user\nroleRef:\n  apiGroup: rbac.authorization.k8s.io\n  kind: ClusterRole\n  name: cluster-admin\nsubjects:\n- kind: ServiceAccount\n  name: admin-user\n  namespace: kube-system\n```\n我们创建了一个名为admin-user的SA，通过ClusterRoleBinding绑定名为cluster-admin的ClusterRole。\n\n```\nkubectl get secret -n kube-system|grep admin-token\n获取secret名字\nkubectl get secret “secret的名字” -o jsonpath={.data.token} -n kube-system |base64 -d\n```\n获得一个base64字符串，粘贴到网页中。\n**切记，请使用火狐浏览器，我使用google和IE都无法进入页面**\n\n","slug":"自己动手搭建kubernetes dashboard界面","published":1,"date":"2020-04-05T03:06:43.064Z","updated":"2020-04-05T03:06:43.064Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck8x0luvg000a2otvngnik51e","content":"<h1 id=\"自己动手搭建kubernetes-dashboard界面\"><a href=\"#自己动手搭建kubernetes-dashboard界面\" class=\"headerlink\" title=\"自己动手搭建kubernetes dashboard界面\"></a>自己动手搭建kubernetes dashboard界面</h1><p>kubernetes官方提供了一套实用的dashboard界面。但是，入学者按照github上搭建安装时往往会遇到各种问题。顺手写个博客记录一下，也希望能帮到一些初学者。</p>\n<h2 id=\"搭建前准备\"><a href=\"#搭建前准备\" class=\"headerlink\" title=\"搭建前准备\"></a>搭建前准备</h2><p>kubernetes官方提供了一套实用的dashboard界面。但是，入学者按照github上搭建安装时往往会遇到各种问题。顺手写个博客记录一下，也希望能帮到一些初学者。目前，我搭建的kubernetes dashboard版本是1.10.1.搭建之前我们首先要有一套k8s集群环境。搭建k8s环境有空再写博客，另外还需要准备以下东西。</p>\n<a id=\"more\"></a>\n\n<ol>\n<li>从github上下载kubernetes dashboard的安装yaml文件，github地址在<a href=\"https://github.com/kubernetes/dashboard\" target=\"_blank\" rel=\"noopener\">此</a>，yaml文件在<a href=\"https://raw.githubusercontent.com/kubernetes/dashboard/v1.10.1/src/deploy/recommended/kubernetes-dashboard.yaml\" target=\"_blank\" rel=\"noopener\">此</a></li>\n<li>默认安装dashboard的时候，会需要<strong>heapster</strong>服务，yaml文件的地址在<a href=\"https://github.com/kubernetes-retired/heapster\" target=\"_blank\" rel=\"noopener\">此</a>，依据README安装即可；</li>\n<li>还需要<strong>metrics</strong>，地址在<a href=\"https://github.com/kubernetes-incubator/metrics-server\" target=\"_blank\" rel=\"noopener\">此</a>，依据README安装即可；</li>\n<li>所需各类镜像如是局域网环境，需提前下载好，通过docker save压缩成tar包，再copy到局域网后docker load加载。</li>\n</ol>\n<h2 id=\"搭建步骤\"><a href=\"#搭建步骤\" class=\"headerlink\" title=\"搭建步骤\"></a>搭建步骤</h2><p>创建dashboard各服务。将dashboard service改为Nodeport方便我们测试连接<br><img src=\"https://img-blog.csdnimg.cn/2019091917002441.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0N1aV9DdWlfNjY2,size_16,color_FFFFFF,t_70\" alt=\"在这里插入图片描述\"><br>然后依次创建heapster、metrics服务。然后我们访问集群任一节点<a href=\"https://Ip:Nodeport\" target=\"_blank\" rel=\"noopener\">https://Ip:Nodeport</a> url。得到如下界面：<br><img src=\"https://img-blog.csdnimg.cn/20190919170322147.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0N1aV9DdWlfNjY2,size_16,color_FFFFFF,t_70\" alt=\"在这里插入图片描述\"><br>我们看到访问需要token。我们需要一个用户授予admin权限。通过以下yaml文件来创建：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">apiVersion: v1</span><br><span class=\"line\">kind: ServiceAccount</span><br><span class=\"line\">metadata:</span><br><span class=\"line\">  name: admin-user</span><br><span class=\"line\">  namespace: kube-system</span><br><span class=\"line\"></span><br><span class=\"line\">---</span><br><span class=\"line\">apiVersion: rbac.authorization.k8s.io/v1</span><br><span class=\"line\">kind: ClusterRoleBinding</span><br><span class=\"line\">metadata:</span><br><span class=\"line\">  name: admin-user</span><br><span class=\"line\">roleRef:</span><br><span class=\"line\">  apiGroup: rbac.authorization.k8s.io</span><br><span class=\"line\">  kind: ClusterRole</span><br><span class=\"line\">  name: cluster-admin</span><br><span class=\"line\">subjects:</span><br><span class=\"line\">- kind: ServiceAccount</span><br><span class=\"line\">  name: admin-user</span><br><span class=\"line\">  namespace: kube-system</span><br></pre></td></tr></table></figure>\n\n<p>我们创建了一个名为admin-user的SA，通过ClusterRoleBinding绑定名为cluster-admin的ClusterRole。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">kubectl get secret -n kube-system|grep admin-token</span><br><span class=\"line\">获取secret名字</span><br><span class=\"line\">kubectl get secret “secret的名字” -o jsonpath=&#123;.data.token&#125; -n kube-system |base64 -d</span><br></pre></td></tr></table></figure>\n\n<p>获得一个base64字符串，粘贴到网页中。<br><strong>切记，请使用火狐浏览器，我使用google和IE都无法进入页面</strong></p>\n","site":{"data":{}},"excerpt":"<h1 id=\"自己动手搭建kubernetes-dashboard界面\"><a href=\"#自己动手搭建kubernetes-dashboard界面\" class=\"headerlink\" title=\"自己动手搭建kubernetes dashboard界面\"></a>自己动手搭建kubernetes dashboard界面</h1><p>kubernetes官方提供了一套实用的dashboard界面。但是，入学者按照github上搭建安装时往往会遇到各种问题。顺手写个博客记录一下，也希望能帮到一些初学者。</p>\n<h2 id=\"搭建前准备\"><a href=\"#搭建前准备\" class=\"headerlink\" title=\"搭建前准备\"></a>搭建前准备</h2><p>kubernetes官方提供了一套实用的dashboard界面。但是，入学者按照github上搭建安装时往往会遇到各种问题。顺手写个博客记录一下，也希望能帮到一些初学者。目前，我搭建的kubernetes dashboard版本是1.10.1.搭建之前我们首先要有一套k8s集群环境。搭建k8s环境有空再写博客，另外还需要准备以下东西。</p>","more":"<ol>\n<li>从github上下载kubernetes dashboard的安装yaml文件，github地址在<a href=\"https://github.com/kubernetes/dashboard\" target=\"_blank\" rel=\"noopener\">此</a>，yaml文件在<a href=\"https://raw.githubusercontent.com/kubernetes/dashboard/v1.10.1/src/deploy/recommended/kubernetes-dashboard.yaml\" target=\"_blank\" rel=\"noopener\">此</a></li>\n<li>默认安装dashboard的时候，会需要<strong>heapster</strong>服务，yaml文件的地址在<a href=\"https://github.com/kubernetes-retired/heapster\" target=\"_blank\" rel=\"noopener\">此</a>，依据README安装即可；</li>\n<li>还需要<strong>metrics</strong>，地址在<a href=\"https://github.com/kubernetes-incubator/metrics-server\" target=\"_blank\" rel=\"noopener\">此</a>，依据README安装即可；</li>\n<li>所需各类镜像如是局域网环境，需提前下载好，通过docker save压缩成tar包，再copy到局域网后docker load加载。</li>\n</ol>\n<h2 id=\"搭建步骤\"><a href=\"#搭建步骤\" class=\"headerlink\" title=\"搭建步骤\"></a>搭建步骤</h2><p>创建dashboard各服务。将dashboard service改为Nodeport方便我们测试连接<br><img src=\"https://img-blog.csdnimg.cn/2019091917002441.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0N1aV9DdWlfNjY2,size_16,color_FFFFFF,t_70\" alt=\"在这里插入图片描述\"><br>然后依次创建heapster、metrics服务。然后我们访问集群任一节点<a href=\"https://Ip:Nodeport\" target=\"_blank\" rel=\"noopener\">https://Ip:Nodeport</a> url。得到如下界面：<br><img src=\"https://img-blog.csdnimg.cn/20190919170322147.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0N1aV9DdWlfNjY2,size_16,color_FFFFFF,t_70\" alt=\"在这里插入图片描述\"><br>我们看到访问需要token。我们需要一个用户授予admin权限。通过以下yaml文件来创建：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">apiVersion: v1</span><br><span class=\"line\">kind: ServiceAccount</span><br><span class=\"line\">metadata:</span><br><span class=\"line\">  name: admin-user</span><br><span class=\"line\">  namespace: kube-system</span><br><span class=\"line\"></span><br><span class=\"line\">---</span><br><span class=\"line\">apiVersion: rbac.authorization.k8s.io/v1</span><br><span class=\"line\">kind: ClusterRoleBinding</span><br><span class=\"line\">metadata:</span><br><span class=\"line\">  name: admin-user</span><br><span class=\"line\">roleRef:</span><br><span class=\"line\">  apiGroup: rbac.authorization.k8s.io</span><br><span class=\"line\">  kind: ClusterRole</span><br><span class=\"line\">  name: cluster-admin</span><br><span class=\"line\">subjects:</span><br><span class=\"line\">- kind: ServiceAccount</span><br><span class=\"line\">  name: admin-user</span><br><span class=\"line\">  namespace: kube-system</span><br></pre></td></tr></table></figure>\n\n<p>我们创建了一个名为admin-user的SA，通过ClusterRoleBinding绑定名为cluster-admin的ClusterRole。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">kubectl get secret -n kube-system|grep admin-token</span><br><span class=\"line\">获取secret名字</span><br><span class=\"line\">kubectl get secret “secret的名字” -o jsonpath=&#123;.data.token&#125; -n kube-system |base64 -d</span><br></pre></td></tr></table></figure>\n\n<p>获得一个base64字符串，粘贴到网页中。<br><strong>切记，请使用火狐浏览器，我使用google和IE都无法进入页面</strong></p>"},{"title":"自己动手搭建Harbor镜像仓库","_content":"\n## 自己动手搭建Harbor镜像仓库\n近期Harbor v1.9 正式面市，该版本称得上是目前功能最多的版本之一，新版本增加了多项优秀功能。\n - Webhook。项目管理员现在可以通过 Webhook 的通知机制，将 Harbor 的项目与技术栈的其余部分连接在一起，简化持续集成和开发过程。\n - 配额。项目管理员可以通过配额限制项目所含 tag 的数目及项目可占用的存储容量（全局和个体），有助于对资源使用加以控制\n - Tag 保留。Harbor 的存储中可能会迅速累积起大量镜像的文件，现在，项目管理员可以利用新的 Tag 保留功能更好地管理镜像生命周期并优化存储分配。\n - CVE 例外策略。该功能允许项目管理员创建一个 CVE 白名单，允许某些镜像在有限的时间段内运行，而不管是否具有特定 CVE 安全漏洞。\n - 内容复制的改进。新版本的 Harbor 可实现与大多数主流云提供商 Registry 的无缝双向复制，满足客户的众多需求和用例。\n\n 下载地址：\n - 官方的[安装文档](https://github.com/goharbor/harbor/blob/master/docs/installation_guide.md)讲的很详细，这里我们推荐使用离线安装，虽然安装包比较大\n - 离线安装包下载地址[添加链接描述](https://storage.googleapis.com/harbor-releases/release-1.9.0/harbor-offline-installer-v1.9.1.tgz)\n## 离线安装HTTP Harbor\n安装之前先安装docker-compose\n我们下载完安装包以后`tar xvf harbor-offline-installer-<version>.tgz`解压缩，可以看到里边有两个安装脚本prepare.sh和install.sh以及harbor.yml。然后修改harbor.yml中配置参数：\n - 将hostname改为自己的ip\n - 将data_volume改为自己想存放的路径\n - database此参数可以修改为自己的数据库地址，也可以不改harbor会自己创建harbor-db容器\n - http:port可以修改harbor仓库的端口号\n\n配置完参数后我们就可以`./install.sh`来安装harbor了。当然这时也可以通过传入参数来配置，我们可以使用`./install.sh --with-chartmuseum`来使我们的harbor可以管理存储chart。执行指令完成后我们可以看到docker-compose已经为我们启动了一些列容器\n![在这里插入图片描述](https://img-blog.csdnimg.cn/20191024175314747.jpg?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0N1aV9DdWlfNjY2,size_16,color_FFFFFF,t_70)\n\nHarbor还可以管理其他的镜像仓库，我们可以配置同步策略（手动或者定时），实现Harbor仓库和其他镜像仓库的交互同步。\n\n 1. 新建目标![在这里插入图片描述](https://img-blog.csdnimg.cn/2019102418014919.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0N1aV9DdWlfNjY2,size_16,color_FFFFFF,t_70)\n 2. 编辑目标![在这里插入图片描述](https://img-blog.csdnimg.cn/20191024180231806.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0N1aV9DdWlfNjY2,size_16,color_FFFFFF,t_70)\n 3. 新建规则![在这里插入图片描述](https://img-blog.csdnimg.cn/20191024180304870.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0N1aV9DdWlfNjY2,size_16,color_FFFFFF,t_70)\n## 向Harbor批量导入docker镜像\n这里我们参考rancher的方法，rancher提供了一个自动化脚本，可以批量导入多个docker image。首先我们要将要导入的docker image打成一个tgz包，打包脚本如下：\n\n```\n#!/bin/bashIMAGES_LIST=($(docker images | sed '1d' | awk '{print $1\":\"$2}'))\ndocker save ${IMAGES_LIST[*]} -o all-images.tar.gz\ndocker images | sed '1d' | awk '{print $1\":\"$2}' >> ./all-images.txt\n```\nrancher脚本下载[地址](https://github.com/rancher/rancher/releases/download/v2.3.1/rancher-load-images.sh)。推送image到远端Harbor指令如下：`./rancher-load-images.sh   -l  all-images.txt   -i  all-images.tar.gz   -r  172.23.5.71:80/library  #仓库地址以及具体的项目`\n","source":"_posts/自己动手搭建Harbor镜像仓库.md","raw":"---\ntitle: 自己动手搭建Harbor镜像仓库\ncategories: Kubernetes\n---\n\n## 自己动手搭建Harbor镜像仓库\n近期Harbor v1.9 正式面市，该版本称得上是目前功能最多的版本之一，新版本增加了多项优秀功能。\n - Webhook。项目管理员现在可以通过 Webhook 的通知机制，将 Harbor 的项目与技术栈的其余部分连接在一起，简化持续集成和开发过程。\n - 配额。项目管理员可以通过配额限制项目所含 tag 的数目及项目可占用的存储容量（全局和个体），有助于对资源使用加以控制\n - Tag 保留。Harbor 的存储中可能会迅速累积起大量镜像的文件，现在，项目管理员可以利用新的 Tag 保留功能更好地管理镜像生命周期并优化存储分配。\n - CVE 例外策略。该功能允许项目管理员创建一个 CVE 白名单，允许某些镜像在有限的时间段内运行，而不管是否具有特定 CVE 安全漏洞。\n - 内容复制的改进。新版本的 Harbor 可实现与大多数主流云提供商 Registry 的无缝双向复制，满足客户的众多需求和用例。\n\n 下载地址：\n - 官方的[安装文档](https://github.com/goharbor/harbor/blob/master/docs/installation_guide.md)讲的很详细，这里我们推荐使用离线安装，虽然安装包比较大\n - 离线安装包下载地址[添加链接描述](https://storage.googleapis.com/harbor-releases/release-1.9.0/harbor-offline-installer-v1.9.1.tgz)\n## 离线安装HTTP Harbor\n安装之前先安装docker-compose\n我们下载完安装包以后`tar xvf harbor-offline-installer-<version>.tgz`解压缩，可以看到里边有两个安装脚本prepare.sh和install.sh以及harbor.yml。然后修改harbor.yml中配置参数：\n - 将hostname改为自己的ip\n - 将data_volume改为自己想存放的路径\n - database此参数可以修改为自己的数据库地址，也可以不改harbor会自己创建harbor-db容器\n - http:port可以修改harbor仓库的端口号\n\n配置完参数后我们就可以`./install.sh`来安装harbor了。当然这时也可以通过传入参数来配置，我们可以使用`./install.sh --with-chartmuseum`来使我们的harbor可以管理存储chart。执行指令完成后我们可以看到docker-compose已经为我们启动了一些列容器\n![在这里插入图片描述](https://img-blog.csdnimg.cn/20191024175314747.jpg?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0N1aV9DdWlfNjY2,size_16,color_FFFFFF,t_70)\n\nHarbor还可以管理其他的镜像仓库，我们可以配置同步策略（手动或者定时），实现Harbor仓库和其他镜像仓库的交互同步。\n\n 1. 新建目标![在这里插入图片描述](https://img-blog.csdnimg.cn/2019102418014919.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0N1aV9DdWlfNjY2,size_16,color_FFFFFF,t_70)\n 2. 编辑目标![在这里插入图片描述](https://img-blog.csdnimg.cn/20191024180231806.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0N1aV9DdWlfNjY2,size_16,color_FFFFFF,t_70)\n 3. 新建规则![在这里插入图片描述](https://img-blog.csdnimg.cn/20191024180304870.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0N1aV9DdWlfNjY2,size_16,color_FFFFFF,t_70)\n## 向Harbor批量导入docker镜像\n这里我们参考rancher的方法，rancher提供了一个自动化脚本，可以批量导入多个docker image。首先我们要将要导入的docker image打成一个tgz包，打包脚本如下：\n\n```\n#!/bin/bashIMAGES_LIST=($(docker images | sed '1d' | awk '{print $1\":\"$2}'))\ndocker save ${IMAGES_LIST[*]} -o all-images.tar.gz\ndocker images | sed '1d' | awk '{print $1\":\"$2}' >> ./all-images.txt\n```\nrancher脚本下载[地址](https://github.com/rancher/rancher/releases/download/v2.3.1/rancher-load-images.sh)。推送image到远端Harbor指令如下：`./rancher-load-images.sh   -l  all-images.txt   -i  all-images.tar.gz   -r  172.23.5.71:80/library  #仓库地址以及具体的项目`\n","slug":"自己动手搭建Harbor镜像仓库","published":1,"date":"2020-04-05T03:06:43.064Z","updated":"2020-04-05T03:06:43.064Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck8x0luvj000d2otvy4f696jh","content":"<h2 id=\"自己动手搭建Harbor镜像仓库\"><a href=\"#自己动手搭建Harbor镜像仓库\" class=\"headerlink\" title=\"自己动手搭建Harbor镜像仓库\"></a>自己动手搭建Harbor镜像仓库</h2><p>近期Harbor v1.9 正式面市，该版本称得上是目前功能最多的版本之一，新版本增加了多项优秀功能。</p>\n<ul>\n<li><p>Webhook。项目管理员现在可以通过 Webhook 的通知机制，将 Harbor 的项目与技术栈的其余部分连接在一起，简化持续集成和开发过程。</p>\n</li>\n<li><p>配额。项目管理员可以通过配额限制项目所含 tag 的数目及项目可占用的存储容量（全局和个体），有助于对资源使用加以控制</p>\n</li>\n<li><p>Tag 保留。Harbor 的存储中可能会迅速累积起大量镜像的文件，现在，项目管理员可以利用新的 Tag 保留功能更好地管理镜像生命周期并优化存储分配。</p>\n</li>\n<li><p>CVE 例外策略。该功能允许项目管理员创建一个 CVE 白名单，允许某些镜像在有限的时间段内运行，而不管是否具有特定 CVE 安全漏洞。</p>\n</li>\n<li><p>内容复制的改进。新版本的 Harbor 可实现与大多数主流云提供商 Registry 的无缝双向复制，满足客户的众多需求和用例。</p>\n<p>下载地址：</p>\n</li>\n<li><p>官方的<a href=\"https://github.com/goharbor/harbor/blob/master/docs/installation_guide.md\" target=\"_blank\" rel=\"noopener\">安装文档</a>讲的很详细，这里我们推荐使用离线安装，虽然安装包比较大</p>\n</li>\n<li><p>离线安装包下载地址<a href=\"https://storage.googleapis.com/harbor-releases/release-1.9.0/harbor-offline-installer-v1.9.1.tgz\" target=\"_blank\" rel=\"noopener\">添加链接描述</a></p>\n<h2 id=\"离线安装HTTP-Harbor\"><a href=\"#离线安装HTTP-Harbor\" class=\"headerlink\" title=\"离线安装HTTP Harbor\"></a>离线安装HTTP Harbor</h2><p>安装之前先安装docker-compose<br>我们下载完安装包以后<code>tar xvf harbor-offline-installer-&lt;version&gt;.tgz</code>解压缩，可以看到里边有两个安装脚本prepare.sh和install.sh以及harbor.yml。然后修改harbor.yml中配置参数：</p>\n</li>\n<li><p>将hostname改为自己的ip</p>\n</li>\n<li><p>将data_volume改为自己想存放的路径</p>\n</li>\n<li><p>database此参数可以修改为自己的数据库地址，也可以不改harbor会自己创建harbor-db容器</p>\n</li>\n<li><p>http:port可以修改harbor仓库的端口号</p>\n</li>\n</ul>\n<p>配置完参数后我们就可以<code>./install.sh</code>来安装harbor了。当然这时也可以通过传入参数来配置，我们可以使用<code>./install.sh --with-chartmuseum</code>来使我们的harbor可以管理存储chart。执行指令完成后我们可以看到docker-compose已经为我们启动了一些列容器<br><img src=\"https://img-blog.csdnimg.cn/20191024175314747.jpg?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0N1aV9DdWlfNjY2,size_16,color_FFFFFF,t_70\" alt=\"在这里插入图片描述\"></p>\n<p>Harbor还可以管理其他的镜像仓库，我们可以配置同步策略（手动或者定时），实现Harbor仓库和其他镜像仓库的交互同步。</p>\n<ol>\n<li>新建目标<img src=\"https://img-blog.csdnimg.cn/2019102418014919.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0N1aV9DdWlfNjY2,size_16,color_FFFFFF,t_70\" alt=\"在这里插入图片描述\"></li>\n<li>编辑目标<img src=\"https://img-blog.csdnimg.cn/20191024180231806.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0N1aV9DdWlfNjY2,size_16,color_FFFFFF,t_70\" alt=\"在这里插入图片描述\"></li>\n<li>新建规则<img src=\"https://img-blog.csdnimg.cn/20191024180304870.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0N1aV9DdWlfNjY2,size_16,color_FFFFFF,t_70\" alt=\"在这里插入图片描述\"><h2 id=\"向Harbor批量导入docker镜像\"><a href=\"#向Harbor批量导入docker镜像\" class=\"headerlink\" title=\"向Harbor批量导入docker镜像\"></a>向Harbor批量导入docker镜像</h2>这里我们参考rancher的方法，rancher提供了一个自动化脚本，可以批量导入多个docker image。首先我们要将要导入的docker image打成一个tgz包，打包脚本如下：</li>\n</ol>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">#!/bin/bashIMAGES_LIST=($(docker images | sed &apos;1d&apos; | awk &apos;&#123;print $1&quot;:&quot;$2&#125;&apos;))</span><br><span class=\"line\">docker save $&#123;IMAGES_LIST[*]&#125; -o all-images.tar.gz</span><br><span class=\"line\">docker images | sed &apos;1d&apos; | awk &apos;&#123;print $1&quot;:&quot;$2&#125;&apos; &gt;&gt; ./all-images.txt</span><br></pre></td></tr></table></figure>\n\n<p>rancher脚本下载<a href=\"https://github.com/rancher/rancher/releases/download/v2.3.1/rancher-load-images.sh\" target=\"_blank\" rel=\"noopener\">地址</a>。推送image到远端Harbor指令如下：<code>./rancher-load-images.sh   -l  all-images.txt   -i  all-images.tar.gz   -r  172.23.5.71:80/library  #仓库地址以及具体的项目</code></p>\n","site":{"data":{}},"excerpt":"","more":"<h2 id=\"自己动手搭建Harbor镜像仓库\"><a href=\"#自己动手搭建Harbor镜像仓库\" class=\"headerlink\" title=\"自己动手搭建Harbor镜像仓库\"></a>自己动手搭建Harbor镜像仓库</h2><p>近期Harbor v1.9 正式面市，该版本称得上是目前功能最多的版本之一，新版本增加了多项优秀功能。</p>\n<ul>\n<li><p>Webhook。项目管理员现在可以通过 Webhook 的通知机制，将 Harbor 的项目与技术栈的其余部分连接在一起，简化持续集成和开发过程。</p>\n</li>\n<li><p>配额。项目管理员可以通过配额限制项目所含 tag 的数目及项目可占用的存储容量（全局和个体），有助于对资源使用加以控制</p>\n</li>\n<li><p>Tag 保留。Harbor 的存储中可能会迅速累积起大量镜像的文件，现在，项目管理员可以利用新的 Tag 保留功能更好地管理镜像生命周期并优化存储分配。</p>\n</li>\n<li><p>CVE 例外策略。该功能允许项目管理员创建一个 CVE 白名单，允许某些镜像在有限的时间段内运行，而不管是否具有特定 CVE 安全漏洞。</p>\n</li>\n<li><p>内容复制的改进。新版本的 Harbor 可实现与大多数主流云提供商 Registry 的无缝双向复制，满足客户的众多需求和用例。</p>\n<p>下载地址：</p>\n</li>\n<li><p>官方的<a href=\"https://github.com/goharbor/harbor/blob/master/docs/installation_guide.md\" target=\"_blank\" rel=\"noopener\">安装文档</a>讲的很详细，这里我们推荐使用离线安装，虽然安装包比较大</p>\n</li>\n<li><p>离线安装包下载地址<a href=\"https://storage.googleapis.com/harbor-releases/release-1.9.0/harbor-offline-installer-v1.9.1.tgz\" target=\"_blank\" rel=\"noopener\">添加链接描述</a></p>\n<h2 id=\"离线安装HTTP-Harbor\"><a href=\"#离线安装HTTP-Harbor\" class=\"headerlink\" title=\"离线安装HTTP Harbor\"></a>离线安装HTTP Harbor</h2><p>安装之前先安装docker-compose<br>我们下载完安装包以后<code>tar xvf harbor-offline-installer-&lt;version&gt;.tgz</code>解压缩，可以看到里边有两个安装脚本prepare.sh和install.sh以及harbor.yml。然后修改harbor.yml中配置参数：</p>\n</li>\n<li><p>将hostname改为自己的ip</p>\n</li>\n<li><p>将data_volume改为自己想存放的路径</p>\n</li>\n<li><p>database此参数可以修改为自己的数据库地址，也可以不改harbor会自己创建harbor-db容器</p>\n</li>\n<li><p>http:port可以修改harbor仓库的端口号</p>\n</li>\n</ul>\n<p>配置完参数后我们就可以<code>./install.sh</code>来安装harbor了。当然这时也可以通过传入参数来配置，我们可以使用<code>./install.sh --with-chartmuseum</code>来使我们的harbor可以管理存储chart。执行指令完成后我们可以看到docker-compose已经为我们启动了一些列容器<br><img src=\"https://img-blog.csdnimg.cn/20191024175314747.jpg?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0N1aV9DdWlfNjY2,size_16,color_FFFFFF,t_70\" alt=\"在这里插入图片描述\"></p>\n<p>Harbor还可以管理其他的镜像仓库，我们可以配置同步策略（手动或者定时），实现Harbor仓库和其他镜像仓库的交互同步。</p>\n<ol>\n<li>新建目标<img src=\"https://img-blog.csdnimg.cn/2019102418014919.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0N1aV9DdWlfNjY2,size_16,color_FFFFFF,t_70\" alt=\"在这里插入图片描述\"></li>\n<li>编辑目标<img src=\"https://img-blog.csdnimg.cn/20191024180231806.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0N1aV9DdWlfNjY2,size_16,color_FFFFFF,t_70\" alt=\"在这里插入图片描述\"></li>\n<li>新建规则<img src=\"https://img-blog.csdnimg.cn/20191024180304870.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0N1aV9DdWlfNjY2,size_16,color_FFFFFF,t_70\" alt=\"在这里插入图片描述\"><h2 id=\"向Harbor批量导入docker镜像\"><a href=\"#向Harbor批量导入docker镜像\" class=\"headerlink\" title=\"向Harbor批量导入docker镜像\"></a>向Harbor批量导入docker镜像</h2>这里我们参考rancher的方法，rancher提供了一个自动化脚本，可以批量导入多个docker image。首先我们要将要导入的docker image打成一个tgz包，打包脚本如下：</li>\n</ol>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">#!/bin/bashIMAGES_LIST=($(docker images | sed &apos;1d&apos; | awk &apos;&#123;print $1&quot;:&quot;$2&#125;&apos;))</span><br><span class=\"line\">docker save $&#123;IMAGES_LIST[*]&#125; -o all-images.tar.gz</span><br><span class=\"line\">docker images | sed &apos;1d&apos; | awk &apos;&#123;print $1&quot;:&quot;$2&#125;&apos; &gt;&gt; ./all-images.txt</span><br></pre></td></tr></table></figure>\n\n<p>rancher脚本下载<a href=\"https://github.com/rancher/rancher/releases/download/v2.3.1/rancher-load-images.sh\" target=\"_blank\" rel=\"noopener\">地址</a>。推送image到远端Harbor指令如下：<code>./rancher-load-images.sh   -l  all-images.txt   -i  all-images.tar.gz   -r  172.23.5.71:80/library  #仓库地址以及具体的项目</code></p>\n"},{"title":"读书人要有读书人的样子","_content":"\n## 励学篇【作者】宋真宗 【朝代】宋\n\n富家不用买良田，书中自有千钟粟。\n安居不用架高楼，书中自有黄金屋。\n娶妻莫恨无良媒，书中自有颜如玉。\n出门莫恨无人随，书中车马多如簇。\n男儿欲遂平生志，五经勤向窗前读。\n\n\n## 陋室铭【作者】刘禹锡 【朝代】唐\n\n\n山不在高，有仙则名。水不在深，有龙则灵。斯是陋室，惟吾德馨。苔痕上阶绿，草色入帘青。谈笑有鸿儒，往来无白丁。可以调素琴，阅金经。无丝竹之乱耳，无案牍之劳形。南阳诸葛庐，西蜀子云亭。孔子云：何陋之有？\n\n![在这里插入图片描述](https://img-blog.csdnimg.cn/20191011153729603.jpg?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0N1aV9DdWlfNjY2,size_16,color_FFFFFF,t_70)","source":"_posts/山不在高.md","raw":"---\ntitle: 读书人要有读书人的样子\ntags: \n  - 山不在高\n  - 随笔\n---\n\n## 励学篇【作者】宋真宗 【朝代】宋\n\n富家不用买良田，书中自有千钟粟。\n安居不用架高楼，书中自有黄金屋。\n娶妻莫恨无良媒，书中自有颜如玉。\n出门莫恨无人随，书中车马多如簇。\n男儿欲遂平生志，五经勤向窗前读。\n\n\n## 陋室铭【作者】刘禹锡 【朝代】唐\n\n\n山不在高，有仙则名。水不在深，有龙则灵。斯是陋室，惟吾德馨。苔痕上阶绿，草色入帘青。谈笑有鸿儒，往来无白丁。可以调素琴，阅金经。无丝竹之乱耳，无案牍之劳形。南阳诸葛庐，西蜀子云亭。孔子云：何陋之有？\n\n![在这里插入图片描述](https://img-blog.csdnimg.cn/20191011153729603.jpg?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0N1aV9DdWlfNjY2,size_16,color_FFFFFF,t_70)","slug":"山不在高","published":1,"date":"2020-04-05T03:06:43.063Z","updated":"2020-04-05T03:06:43.064Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck8x0luvm000e2otvzn3jzv1g","content":"<h2 id=\"励学篇【作者】宋真宗-【朝代】宋\"><a href=\"#励学篇【作者】宋真宗-【朝代】宋\" class=\"headerlink\" title=\"励学篇【作者】宋真宗 【朝代】宋\"></a>励学篇【作者】宋真宗 【朝代】宋</h2><p>富家不用买良田，书中自有千钟粟。<br>安居不用架高楼，书中自有黄金屋。<br>娶妻莫恨无良媒，书中自有颜如玉。<br>出门莫恨无人随，书中车马多如簇。<br>男儿欲遂平生志，五经勤向窗前读。</p>\n<h2 id=\"陋室铭【作者】刘禹锡-【朝代】唐\"><a href=\"#陋室铭【作者】刘禹锡-【朝代】唐\" class=\"headerlink\" title=\"陋室铭【作者】刘禹锡 【朝代】唐\"></a>陋室铭【作者】刘禹锡 【朝代】唐</h2><p>山不在高，有仙则名。水不在深，有龙则灵。斯是陋室，惟吾德馨。苔痕上阶绿，草色入帘青。谈笑有鸿儒，往来无白丁。可以调素琴，阅金经。无丝竹之乱耳，无案牍之劳形。南阳诸葛庐，西蜀子云亭。孔子云：何陋之有？</p>\n<p><img src=\"https://img-blog.csdnimg.cn/20191011153729603.jpg?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0N1aV9DdWlfNjY2,size_16,color_FFFFFF,t_70\" alt=\"在这里插入图片描述\"></p>\n","site":{"data":{}},"excerpt":"","more":"<h2 id=\"励学篇【作者】宋真宗-【朝代】宋\"><a href=\"#励学篇【作者】宋真宗-【朝代】宋\" class=\"headerlink\" title=\"励学篇【作者】宋真宗 【朝代】宋\"></a>励学篇【作者】宋真宗 【朝代】宋</h2><p>富家不用买良田，书中自有千钟粟。<br>安居不用架高楼，书中自有黄金屋。<br>娶妻莫恨无良媒，书中自有颜如玉。<br>出门莫恨无人随，书中车马多如簇。<br>男儿欲遂平生志，五经勤向窗前读。</p>\n<h2 id=\"陋室铭【作者】刘禹锡-【朝代】唐\"><a href=\"#陋室铭【作者】刘禹锡-【朝代】唐\" class=\"headerlink\" title=\"陋室铭【作者】刘禹锡 【朝代】唐\"></a>陋室铭【作者】刘禹锡 【朝代】唐</h2><p>山不在高，有仙则名。水不在深，有龙则灵。斯是陋室，惟吾德馨。苔痕上阶绿，草色入帘青。谈笑有鸿儒，往来无白丁。可以调素琴，阅金经。无丝竹之乱耳，无案牍之劳形。南阳诸葛庐，西蜀子云亭。孔子云：何陋之有？</p>\n<p><img src=\"https://img-blog.csdnimg.cn/20191011153729603.jpg?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0N1aV9DdWlfNjY2,size_16,color_FFFFFF,t_70\" alt=\"在这里插入图片描述\"></p>\n"}],"PostAsset":[],"PostCategory":[{"post_id":"ck8x0luv000002otvzp5lsh3x","category_id":"ck8x0luv900042otv1nd6c9hj","_id":"ck8x0luvi000b2otv6vzru65l"},{"post_id":"ck8x0luv600022otvo347yzg8","category_id":"ck8x0luve00082otvqqnbhra4","_id":"ck8x0luvo000f2otvdzdt0bjg"},{"post_id":"ck8x0luvj000d2otvy4f696jh","category_id":"ck8x0luvi000c2otvhni32lzd","_id":"ck8x0luvr000i2otv1pn1eiti"},{"post_id":"ck8x0luvb00052otvndj0q6ke","category_id":"ck8x0luvi000c2otvhni32lzd","_id":"ck8x0luvs000k2otv1u34qm24"},{"post_id":"ck8x0luvc00062otv5c7eebpv","category_id":"ck8x0luvi000c2otvhni32lzd","_id":"ck8x0luvu000n2otvx22qx0fp"},{"post_id":"ck8x0luvd00072otv31bqe9qn","category_id":"ck8x0luvi000c2otvhni32lzd","_id":"ck8x0luvv000p2otv5bbafp19"},{"post_id":"ck8x0luvf00092otv28woz5a9","category_id":"ck8x0luvi000c2otvhni32lzd","_id":"ck8x0luvw000s2otv39w4wlo2"},{"post_id":"ck8x0luvg000a2otvngnik51e","category_id":"ck8x0luvi000c2otvhni32lzd","_id":"ck8x0luvx000t2otvyl9t9li8"}],"PostTag":[{"post_id":"ck8x0luvm000e2otvzn3jzv1g","tag_id":"ck8x0luvq000h2otvmlsvo8mf","_id":"ck8x0luvv000q2otvztye4jh2"},{"post_id":"ck8x0luvm000e2otvzn3jzv1g","tag_id":"ck8x0luvt000l2otvrr1t1w4u","_id":"ck8x0luvw000r2otvn2xb18ce"}],"Tag":[{"name":"山不在高","_id":"ck8x0luvq000h2otvmlsvo8mf"},{"name":"随笔","_id":"ck8x0luvt000l2otvrr1t1w4u"}]}}